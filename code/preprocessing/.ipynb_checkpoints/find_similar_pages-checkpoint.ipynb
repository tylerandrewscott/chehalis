{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Most Similar Non-Example Pages to Administrative Forms\n",
    "\n",
    "This notebook uses the Donut model to find pages in the non-examples folder that are most similar to the administrative forms in the examples folder.\n",
    "\n",
    "## Approach:\n",
    "1. Extract visual embeddings from the Donut encoder for all example form pages\n",
    "2. Extract embeddings for all non-example pages\n",
    "3. Compute similarity scores and find the most similar non-example page\n",
    "4. Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Define Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "BASE_PATH = Path('/Users/admin-tascott/Documents/GitHub/chehalis')\n",
    "EXAMPLE_FORMS_PATH = BASE_PATH / 'data' / 'raw' / '_exampleforms'\n",
    "NON_EXAMPLES_PATH = BASE_PATH / 'data' / 'raw' / '_nonexamples'\n",
    "\n",
    "# Check if trained model exists, otherwise use base model\n",
    "MODEL_DIR = \"./form_classifier_model\"\n",
    "if os.path.exists(MODEL_DIR):\n",
    "    print(f\"Loading trained model from {MODEL_DIR}\")\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR)\n",
    "    processor = DonutProcessor.from_pretrained(MODEL_DIR)\n",
    "else:\n",
    "    print(\"Loading base Donut model\")\n",
    "    MODEL_NAME = \"naver-clova-ix/donut-base\"\n",
    "    processor = DonutProcessor.from_pretrained(MODEL_NAME)\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PDF Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_images(pdf_path: Path, dpi: int = 200) -> List[Image.Image]:\n",
    "    \"\"\"Convert PDF to list of PIL Images\"\"\"\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=dpi)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {pdf_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def preprocess_image_for_donut(image: Image.Image, size: Tuple[int, int] = (1280, 960)) -> Image.Image:\n",
    "    \"\"\"Preprocess image for Donut model\"\"\"\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    image.thumbnail(size, Image.Resampling.LANCZOS)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Embeddings Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(image: Image.Image, model, processor, device):\n",
    "    \"\"\"\n",
    "    Extract visual embeddings from Donut encoder\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings\n",
    "    \"\"\"\n",
    "    # Preprocess image\n",
    "    image = preprocess_image_for_donut(image)\n",
    "    \n",
    "    # Get pixel values\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = model.encoder(pixel_values)\n",
    "        \n",
    "        # Use the pooled output or mean of last hidden states\n",
    "        if hasattr(encoder_outputs, 'pooler_output') and encoder_outputs.pooler_output is not None:\n",
    "            embeddings = encoder_outputs.pooler_output\n",
    "        else:\n",
    "            # Mean pool the last hidden states\n",
    "            embeddings = encoder_outputs.last_hidden_state.mean(dim=1)\n",
    "        \n",
    "        embeddings = embeddings.cpu().numpy()\n",
    "    \n",
    "    return embeddings[0]  # Return first (and only) embedding in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process All Example Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for all example form pages\n",
    "example_embeddings = []\n",
    "example_metadata = []\n",
    "\n",
    "print(\"Processing example forms...\")\n",
    "pdf_files = list(EXAMPLE_FORMS_PATH.glob('*.pdf'))\n",
    "\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Example PDFs\"):\n",
    "    images = pdf_to_images(pdf_path)\n",
    "    for page_num, image in enumerate(images):\n",
    "        embedding = extract_embeddings(image, model, processor, device)\n",
    "        example_embeddings.append(embedding)\n",
    "        example_metadata.append({\n",
    "            'file_path': str(pdf_path),\n",
    "            'filename': pdf_path.name,\n",
    "            'page_num': page_num + 1,\n",
    "            'total_pages': len(images)\n",
    "        })\n",
    "\n",
    "example_embeddings = np.array(example_embeddings)\n",
    "print(f\"\\nExtracted embeddings for {len(example_embeddings)} example form pages\")\n",
    "print(f\"Embedding shape: {example_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process All Non-Example Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings for all non-example pages\n",
    "non_example_embeddings = []\n",
    "non_example_metadata = []\n",
    "non_example_images = []  # Store for visualization\n",
    "\n",
    "print(\"\\nProcessing non-example documents...\")\n",
    "pdf_files = list(NON_EXAMPLES_PATH.glob('*.pdf'))\n",
    "\n",
    "# Limit number of PDFs for memory management (adjust as needed)\n",
    "max_pdfs = 50  # Process first 50 PDFs\n",
    "pdf_files = pdf_files[:max_pdfs]\n",
    "\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Non-example PDFs\"):\n",
    "    images = pdf_to_images(pdf_path)\n",
    "    for page_num, image in enumerate(images):\n",
    "        embedding = extract_embeddings(image, model, processor, device)\n",
    "        non_example_embeddings.append(embedding)\n",
    "        non_example_metadata.append({\n",
    "            'file_path': str(pdf_path),\n",
    "            'filename': pdf_path.name,\n",
    "            'page_num': page_num + 1,\n",
    "            'total_pages': len(images)\n",
    "        })\n",
    "        # Store resized image for visualization\n",
    "        non_example_images.append(preprocess_image_for_donut(image))\n",
    "\n",
    "non_example_embeddings = np.array(non_example_embeddings)\n",
    "print(f\"\\nExtracted embeddings for {len(non_example_embeddings)} non-example pages\")\n",
    "print(f\"Embedding shape: {non_example_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compute Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between all example and non-example pages\n",
    "print(\"\\nComputing similarity scores...\")\n",
    "similarity_matrix = cosine_similarity(non_example_embeddings, example_embeddings)\n",
    "\n",
    "# Find the maximum similarity for each non-example page\n",
    "max_similarities = similarity_matrix.max(axis=1)\n",
    "most_similar_example_idx = similarity_matrix.argmax(axis=1)\n",
    "\n",
    "# Find the overall most similar non-example page\n",
    "most_similar_idx = max_similarities.argmax()\n",
    "most_similar_score = max_similarities[most_similar_idx]\n",
    "most_similar_example = most_similar_example_idx[most_similar_idx]\n",
    "\n",
    "print(f\"\\nMost similar non-example page:\")\n",
    "print(f\"  File: {non_example_metadata[most_similar_idx]['filename']}\")\n",
    "print(f\"  Page: {non_example_metadata[most_similar_idx]['page_num']}\")\n",
    "print(f\"  Similarity score: {most_similar_score:.4f}\")\n",
    "print(f\"  Most similar to example: {example_metadata[most_similar_example]['filename']}, page {example_metadata[most_similar_example]['page_num']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Find Top K Most Similar Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top K most similar non-example pages\n",
    "K = 10\n",
    "top_k_indices = np.argsort(max_similarities)[-K:][::-1]\n",
    "\n",
    "print(f\"\\nTop {K} most similar non-example pages:\")\n",
    "results = []\n",
    "\n",
    "for rank, idx in enumerate(top_k_indices):\n",
    "    metadata = non_example_metadata[idx]\n",
    "    similar_example_idx = most_similar_example_idx[idx]\n",
    "    similar_example = example_metadata[similar_example_idx]\n",
    "    \n",
    "    result = {\n",
    "        'rank': rank + 1,\n",
    "        'filename': metadata['filename'],\n",
    "        'page': metadata['page_num'],\n",
    "        'similarity_score': max_similarities[idx],\n",
    "        'similar_to_example': similar_example['filename'],\n",
    "        'similar_to_page': similar_example['page_num']\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"\\n{rank + 1}. File: {metadata['filename']}, Page: {metadata['page_num']}\")\n",
    "    print(f\"   Similarity: {max_similarities[idx]:.4f}\")\n",
    "    print(f\"   Most similar to: {similar_example['filename']}, page {similar_example['page_num']}\")\n",
    "\n",
    "# Create DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Most Similar Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 5 most similar non-example pages\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "fig.suptitle('Top 5 Most Similar Non-Example Pages', fontsize=16)\n",
    "\n",
    "for i, idx in enumerate(top_k_indices[:5]):\n",
    "    # Non-example page\n",
    "    ax_non = axes[0, i]\n",
    "    ax_non.imshow(non_example_images[idx])\n",
    "    ax_non.set_title(f\"Non-Example\\n{non_example_metadata[idx]['filename']}\\nPage {non_example_metadata[idx]['page_num']}\\nScore: {max_similarities[idx]:.3f}\")\n",
    "    ax_non.axis('off')\n",
    "    \n",
    "    # Most similar example page\n",
    "    similar_example_idx = most_similar_example_idx[idx]\n",
    "    example_meta = example_metadata[similar_example_idx]\n",
    "    \n",
    "    # Load the example image for visualization\n",
    "    example_pdf_path = Path(example_meta['file_path'])\n",
    "    example_images = pdf_to_images(example_pdf_path)\n",
    "    example_image = preprocess_image_for_donut(example_images[example_meta['page_num'] - 1])\n",
    "    \n",
    "    ax_ex = axes[1, i]\n",
    "    ax_ex.imshow(example_image)\n",
    "    ax_ex.set_title(f\"Similar Example\\n{example_meta['filename']}\\nPage {example_meta['page_num']}\")\n",
    "    ax_ex.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analyze Similarity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of similarity scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(max_similarities, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(x=most_similar_score, color='red', linestyle='--', label=f'Most similar: {most_similar_score:.3f}')\n",
    "plt.xlabel('Maximum Cosine Similarity Score')\n",
    "plt.ylabel('Number of Non-Example Pages')\n",
    "plt.title('Distribution of Similarity Scores\\n(Non-Example Pages vs Most Similar Example Form)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nSimilarity Statistics:\")\n",
    "print(f\"Mean similarity: {max_similarities.mean():.4f}\")\n",
    "print(f\"Std deviation: {max_similarities.std():.4f}\")\n",
    "print(f\"Min similarity: {max_similarities.min():.4f}\")\n",
    "print(f\"Max similarity: {max_similarities.max():.4f}\")\n",
    "print(f\"\\nPages with similarity > 0.9: {(max_similarities > 0.9).sum()}\")\n",
    "print(f\"Pages with similarity > 0.8: {(max_similarities > 0.8).sum()}\")\n",
    "print(f\"Pages with similarity > 0.7: {(max_similarities > 0.7).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results to CSV\n",
    "all_results = []\n",
    "\n",
    "for idx, (score, example_idx) in enumerate(zip(max_similarities, most_similar_example_idx)):\n",
    "    metadata = non_example_metadata[idx]\n",
    "    similar_example = example_metadata[example_idx]\n",
    "    \n",
    "    all_results.append({\n",
    "        'non_example_file': metadata['filename'],\n",
    "        'non_example_page': metadata['page_num'],\n",
    "        'non_example_total_pages': metadata['total_pages'],\n",
    "        'similarity_score': score,\n",
    "        'most_similar_example_file': similar_example['filename'],\n",
    "        'most_similar_example_page': similar_example['page_num']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('similarity_score', ascending=False)\n",
    "results_df.to_csv('similarity_results.csv', index=False)\n",
    "\n",
    "print(f\"\\nResults saved to similarity_results.csv\")\n",
    "print(f\"\\nTop 10 most similar pages:\")\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Identify Potential Misclassified Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pages with very high similarity might be misclassified\n",
    "threshold = 0.85  # Adjust based on your needs\n",
    "potential_misclassified = results_df[results_df['similarity_score'] > threshold]\n",
    "\n",
    "print(f\"\\nPotential misclassified pages (similarity > {threshold}):\")\n",
    "print(f\"Found {len(potential_misclassified)} pages\")\n",
    "\n",
    "if len(potential_misclassified) > 0:\n",
    "    print(\"\\nThese non-example pages are very similar to the administrative forms:\")\n",
    "    for _, row in potential_misclassified.iterrows():\n",
    "        print(f\"\\n- File: {row['non_example_file']}, Page: {row['non_example_page']}\")\n",
    "        print(f\"  Similarity: {row['similarity_score']:.4f}\")\n",
    "        print(f\"  Similar to: {row['most_similar_example_file']}, page {row['most_similar_example_page']}\")\n",
    "    \n",
    "    # Save potential misclassified pages\n",
    "    potential_misclassified.to_csv('potential_misclassified_pages.csv', index=False)\n",
    "    print(\"\\nSaved to potential_misclassified_pages.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Notes\n",
    "\n",
    "This notebook helps identify:\n",
    "\n",
    "1. **Most Similar Pages**: Which pages in the non-examples are most visually similar to the administrative forms\n",
    "2. **Potential Misclassifications**: Pages with very high similarity scores might actually be administrative forms that were incorrectly placed in the non-examples folder\n",
    "3. **Similarity Distribution**: Understanding how similar non-form pages are to form pages helps set classification thresholds\n",
    "\n",
    "### Next Steps:\n",
    "- Review pages with high similarity scores (>0.85) to check if they're actually administrative forms\n",
    "- Use the similarity threshold to improve the classifier's decision boundary\n",
    "- Consider adding highly similar non-forms as hard negative examples in training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}