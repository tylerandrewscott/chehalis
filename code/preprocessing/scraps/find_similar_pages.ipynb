{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Most Similar Non-Example Pages to Administrative Forms\n",
    "\n",
    "This notebook uses the Donut model to find pages in the non-examples folder that are most similar to the administrative forms in the examples folder.\n",
    "\n",
    "## Approach:\n",
    "1. Extract visual embeddings from the Donut encoder for all example form pages\n",
    "2. Extract embeddings for all non-example pages\n",
    "3. Compute similarity scores and find the most similar non-example page\n",
    "4. Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set tokenizers parallelism to false to avoid fork warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Define paths\nBASE_PATH = Path('/Users/admin-tascott/Documents/GitHub/chehalis')\nEXAMPLE_FORMS_PATH = BASE_PATH / 'data' / 'raw' / '_exampleforms'\nNON_EXAMPLES_PATH = BASE_PATH / 'data' / 'raw' / '_nonexamples'\n\n# Model selection - Change to CLIP\nMODEL_TYPE = \"clip\"  # Options: \"clip\", \"donut\"\n\n# Load appropriate model based on selection\nif MODEL_TYPE == \"clip\":\n    from transformers import CLIPProcessor, CLIPModel\n    print(\"Loading CLIP model\")\n    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n    # Use vision model only for embeddings\n    model = model.vision_model.to(device)\nelif MODEL_TYPE == \"donut\":\n    # Check if trained model exists, otherwise use base model\n    MODEL_DIR = \"./form_classifier_model\"\n    if os.path.exists(MODEL_DIR):\n        print(f\"Loading trained Donut model from {MODEL_DIR}\")\n        model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR)\n        processor = DonutProcessor.from_pretrained(MODEL_DIR)\n    else:\n        print(\"Loading base Donut model\")\n        MODEL_NAME = \"naver-clova-ix/donut-base\"\n        processor = DonutProcessor.from_pretrained(MODEL_NAME)\n        model = VisionEncoderDecoderModel.from_pretrained(MODEL_NAME)\n    # Use encoder only for embeddings\n    model = model.encoder.to(device)\n\nmodel.eval()  # Set to evaluation mode\nprint(f\"Model loaded successfully: {MODEL_TYPE}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def pdf_to_images(pdf_path: Path, dpi: int = 200) -> List[Image.Image]:\n    \"\"\"Convert PDF to list of PIL Images\"\"\"\n    try:\n        images = convert_from_path(pdf_path, dpi=dpi)\n        return images\n    except Exception as e:\n        print(f\"Error converting {pdf_path}: {e}\")\n        return []\n\ndef preprocess_image_for_model(image: Image.Image, model_type: str = \"clip\") -> Image.Image:\n    \"\"\"Preprocess image based on model type\"\"\"\n    if image.mode != 'RGB':\n        image = image.convert('RGB')\n    \n    if model_type == \"clip\":\n        # CLIP expects 224x224 images\n        image.thumbnail((224, 224), Image.Resampling.LANCZOS)\n    else:  # donut\n        # Donut expects larger images\n        image.thumbnail((1280, 960), Image.Resampling.LANCZOS)\n    \n    return image"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "def extract_embeddings(image: Image.Image, model, processor, device, model_type: str = \"clip\"):\n    \"\"\"\n    Extract visual embeddings from model\n    \n    Returns:\n        numpy array of embeddings\n    \"\"\"\n    # Preprocess image\n    image = preprocess_image_for_model(image, model_type)\n    \n    # Get pixel values\n    inputs = processor(images=image, return_tensors=\"pt\")\n    pixel_values = inputs.pixel_values.to(device)\n    \n    with torch.no_grad():\n        if model_type == \"clip\":\n            # For CLIP, we already have the vision model\n            outputs = model(pixel_values=pixel_values)\n        else:  # donut\n            # For Donut encoder\n            outputs = model(pixel_values)\n        \n        # Extract embeddings\n        if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:\n            embeddings = outputs.pooler_output\n        elif hasattr(outputs, 'last_hidden_state'):\n            # Mean pool the last hidden states\n            embeddings = outputs.last_hidden_state.mean(dim=1)\n        else:\n            # For some models, outputs might be a tuple\n            embeddings = outputs[0].mean(dim=1) if isinstance(outputs, tuple) else outputs\n        \n        embeddings = embeddings.cpu().numpy()\n    \n    return embeddings[0]  # Return first (and only) embedding in batch"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract embeddings for all example form pages\nexample_embeddings = []\nexample_metadata = []\n\nprint(\"Processing example forms...\")\npdf_files = list(EXAMPLE_FORMS_PATH.glob('*.pdf'))\n\nfor pdf_path in tqdm(pdf_files, desc=\"Example PDFs\"):\n    images = pdf_to_images(pdf_path)\n    for page_num, image in enumerate(images):\n        embedding = extract_embeddings(image, model, processor, device, MODEL_TYPE)\n        example_embeddings.append(embedding)\n        example_metadata.append({\n            'file_path': str(pdf_path),\n            'filename': pdf_path.name,\n            'page_num': page_num + 1,\n            'total_pages': len(images)\n        })\n\nexample_embeddings = np.array(example_embeddings)\nprint(f\"\\nExtracted embeddings for {len(example_embeddings)} example form pages\")\nprint(f\"Embedding shape: {example_embeddings.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Extract embeddings for all non-example pages\nnon_example_embeddings = []\nnon_example_metadata = []\nnon_example_images = []  # Store for visualization\n\nprint(\"\\nProcessing non-example documents...\")\npdf_files = list(NON_EXAMPLES_PATH.glob('*.pdf'))\n\n# Limit number of PDFs for memory management (adjust as needed)\nmax_pdfs = 50  # Process first 50 PDFs\npdf_files = pdf_files[:max_pdfs]\n\nfor pdf_path in tqdm(pdf_files, desc=\"Non-example PDFs\"):\n    images = pdf_to_images(pdf_path)\n    for page_num, image in enumerate(images):\n        embedding = extract_embeddings(image, model, processor, device, MODEL_TYPE)\n        non_example_embeddings.append(embedding)\n        non_example_metadata.append({\n            'file_path': str(pdf_path),\n            'filename': pdf_path.name,\n            'page_num': page_num + 1,\n            'total_pages': len(images)\n        })\n        # Store resized image for visualization\n        non_example_images.append(preprocess_image_for_model(image, MODEL_TYPE))\n\nnon_example_embeddings = np.array(non_example_embeddings)\nprint(f\"\\nExtracted embeddings for {len(non_example_embeddings)} non-example pages\")\nprint(f\"Embedding shape: {non_example_embeddings.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(image: Image.Image, model, processor, device):\n",
    "    \"\"\"\n",
    "    Extract visual embeddings from Donut encoder\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of embeddings\n",
    "    \"\"\"\n",
    "    # Preprocess image\n",
    "    image = preprocess_image_for_donut(image)\n",
    "    \n",
    "    # Get pixel values\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = model.encoder(pixel_values)\n",
    "        \n",
    "        # Use the pooled output or mean of last hidden states\n",
    "        if hasattr(encoder_outputs, 'pooler_output') and encoder_outputs.pooler_output is not None:\n",
    "            embeddings = encoder_outputs.pooler_output\n",
    "        else:\n",
    "            # Mean pool the last hidden states\n",
    "            embeddings = encoder_outputs.last_hidden_state.mean(dim=1)\n",
    "        \n",
    "        embeddings = embeddings.cpu().numpy()\n",
    "    \n",
    "    return embeddings[0]  # Return first (and only) embedding in batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process All Example Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize top 5 most similar non-example pages\nfig, axes = plt.subplots(2, 5, figsize=(20, 10))\nfig.suptitle('Top 5 Most Similar Non-Example Pages', fontsize=16)\n\nfor i, idx in enumerate(top_k_indices[:5]):\n    # Non-example page\n    ax_non = axes[0, i]\n    ax_non.imshow(non_example_images[idx])\n    ax_non.set_title(f\"Non-Example\\n{non_example_metadata[idx]['filename']}\\nPage {non_example_metadata[idx]['page_num']}\\nScore: {max_similarities[idx]:.3f}\")\n    ax_non.axis('off')\n    \n    # Most similar example page\n    similar_example_idx = most_similar_example_idx[idx]\n    example_meta = example_metadata[similar_example_idx]\n    \n    # Load the example image for visualization\n    example_pdf_path = Path(example_meta['file_path'])\n    example_images = pdf_to_images(example_pdf_path)\n    example_image = preprocess_image_for_model(example_images[example_meta['page_num'] - 1], MODEL_TYPE)\n    \n    ax_ex = axes[1, i]\n    ax_ex.imshow(example_image)\n    ax_ex.set_title(f\"Similar Example\\n{example_meta['filename']}\\nPage {example_meta['page_num']}\")\n    ax_ex.axis('off')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process All Non-Example Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing non-example documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Non-example PDFs: 100%|██████████████████████| 50/50 [1:36:16<00:00, 115.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted embeddings for 1073 non-example pages\n",
      "Embedding shape: (1073, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings for all non-example pages\n",
    "non_example_embeddings = []\n",
    "non_example_metadata = []\n",
    "non_example_images = []  # Store for visualization\n",
    "\n",
    "print(\"\\nProcessing non-example documents...\")\n",
    "pdf_files = list(NON_EXAMPLES_PATH.glob('*.pdf'))\n",
    "\n",
    "# Limit number of PDFs for memory management (adjust as needed)\n",
    "max_pdfs = 50  # Process first 50 PDFs\n",
    "pdf_files = pdf_files[:max_pdfs]\n",
    "\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Non-example PDFs\"):\n",
    "    images = pdf_to_images(pdf_path)\n",
    "    for page_num, image in enumerate(images):\n",
    "        embedding = extract_embeddings(image, model, processor, device)\n",
    "        non_example_embeddings.append(embedding)\n",
    "        non_example_metadata.append({\n",
    "            'file_path': str(pdf_path),\n",
    "            'filename': pdf_path.name,\n",
    "            'page_num': page_num + 1,\n",
    "            'total_pages': len(images)\n",
    "        })\n",
    "        # Store resized image for visualization\n",
    "        non_example_images.append(preprocess_image_for_donut(image))\n",
    "\n",
    "non_example_embeddings = np.array(non_example_embeddings)\n",
    "print(f\"\\nExtracted embeddings for {len(non_example_embeddings)} non-example pages\")\n",
    "print(f\"Embedding shape: {non_example_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compute Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing similarity scores...\n",
      "\n",
      "Most similar non-example page:\n",
      "  File: 739-000.pdf\n",
      "  Page: 15\n",
      "  Similarity score: 0.9985\n",
      "  Most similar to example: 747-000.pdf, page 2\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between all example and non-example pages\n",
    "print(\"\\nComputing similarity scores...\")\n",
    "similarity_matrix = cosine_similarity(non_example_embeddings, example_embeddings)\n",
    "\n",
    "# Find the maximum similarity for each non-example page\n",
    "max_similarities = similarity_matrix.max(axis=1)\n",
    "most_similar_example_idx = similarity_matrix.argmax(axis=1)\n",
    "\n",
    "# Find the overall most similar non-example page\n",
    "most_similar_idx = max_similarities.argmax()\n",
    "most_similar_score = max_similarities[most_similar_idx]\n",
    "most_similar_example = most_similar_example_idx[most_similar_idx]\n",
    "\n",
    "print(f\"\\nMost similar non-example page:\")\n",
    "print(f\"  File: {non_example_metadata[most_similar_idx]['filename']}\")\n",
    "print(f\"  Page: {non_example_metadata[most_similar_idx]['page_num']}\")\n",
    "print(f\"  Similarity score: {most_similar_score:.4f}\")\n",
    "print(f\"  Most similar to example: {example_metadata[most_similar_example]['filename']}, page {example_metadata[most_similar_example]['page_num']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Find Top K Most Similar Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most similar non-example pages:\n",
      "\n",
      "1. File: 739-000.pdf, Page: 15\n",
      "   Similarity: 0.9985\n",
      "   Most similar to: 747-000.pdf, page 2\n",
      "\n",
      "2. File: 1197-000.pdf, Page: 1\n",
      "   Similarity: 0.9936\n",
      "   Most similar to: 739-000.pdf, page 1\n",
      "\n",
      "3. File: 25581-000.pdf, Page: 20\n",
      "   Similarity: 0.9933\n",
      "   Most similar to: 1050-002.pdf, page 1\n",
      "\n",
      "4. File: 1197-000.pdf, Page: 5\n",
      "   Similarity: 0.9928\n",
      "   Most similar to: 730-000.pdf, page 1\n",
      "\n",
      "5. File: 25581-000.pdf, Page: 21\n",
      "   Similarity: 0.9923\n",
      "   Most similar to: 719-000.pdf, page 1\n",
      "\n",
      "6. File: 1197-000.pdf, Page: 4\n",
      "   Similarity: 0.9920\n",
      "   Most similar to: 719-000.pdf, page 1\n",
      "\n",
      "7. File: 104473-000.pdf, Page: 34\n",
      "   Similarity: 0.9919\n",
      "   Most similar to: 9697-000.pdf, page 1\n",
      "\n",
      "8. File: 25581-000.pdf, Page: 11\n",
      "   Similarity: 0.9916\n",
      "   Most similar to: 751-000.pdf, page 1\n",
      "\n",
      "9. File: 732-001.pdf, Page: 14\n",
      "   Similarity: 0.9910\n",
      "   Most similar to: 1064-000.pdf, page 1\n",
      "\n",
      "10. File: F1-9-DCS-43810SAS-001.pdf, Page: 4\n",
      "   Similarity: 0.9909\n",
      "   Most similar to: 1021-000.pdf, page 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>similar_to_example</th>\n",
       "      <th>similar_to_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>739-000.pdf</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998489</td>\n",
       "      <td>747-000.pdf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1197-000.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993603</td>\n",
       "      <td>739-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>20</td>\n",
       "      <td>0.993346</td>\n",
       "      <td>1050-002.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1197-000.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.992799</td>\n",
       "      <td>730-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>21</td>\n",
       "      <td>0.992268</td>\n",
       "      <td>719-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1197-000.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>0.992050</td>\n",
       "      <td>719-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>104473-000.pdf</td>\n",
       "      <td>34</td>\n",
       "      <td>0.991850</td>\n",
       "      <td>9697-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>11</td>\n",
       "      <td>0.991611</td>\n",
       "      <td>751-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>732-001.pdf</td>\n",
       "      <td>14</td>\n",
       "      <td>0.990955</td>\n",
       "      <td>1064-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>F1-9-DCS-43810SAS-001.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>1021-000.pdf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                   filename  page  similarity_score similar_to_example  \\\n",
       "0     1                739-000.pdf    15          0.998489        747-000.pdf   \n",
       "1     2               1197-000.pdf     1          0.993603        739-000.pdf   \n",
       "2     3              25581-000.pdf    20          0.993346       1050-002.pdf   \n",
       "3     4               1197-000.pdf     5          0.992799        730-000.pdf   \n",
       "4     5              25581-000.pdf    21          0.992268        719-000.pdf   \n",
       "5     6               1197-000.pdf     4          0.992050        719-000.pdf   \n",
       "6     7             104473-000.pdf    34          0.991850       9697-000.pdf   \n",
       "7     8              25581-000.pdf    11          0.991611        751-000.pdf   \n",
       "8     9                732-001.pdf    14          0.990955       1064-000.pdf   \n",
       "9    10  F1-9-DCS-43810SAS-001.pdf     4          0.990906       1021-000.pdf   \n",
       "\n",
       "   similar_to_page  \n",
       "0                2  \n",
       "1                1  \n",
       "2                1  \n",
       "3                1  \n",
       "4                1  \n",
       "5                1  \n",
       "6                1  \n",
       "7                1  \n",
       "8                1  \n",
       "9                1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top K most similar non-example pages\n",
    "K = 10\n",
    "top_k_indices = np.argsort(max_similarities)[-K:][::-1]\n",
    "\n",
    "print(f\"\\nTop {K} most similar non-example pages:\")\n",
    "results = []\n",
    "\n",
    "for rank, idx in enumerate(top_k_indices):\n",
    "    metadata = non_example_metadata[idx]\n",
    "    similar_example_idx = most_similar_example_idx[idx]\n",
    "    similar_example = example_metadata[similar_example_idx]\n",
    "    \n",
    "    result = {\n",
    "        'rank': rank + 1,\n",
    "        'filename': metadata['filename'],\n",
    "        'page': metadata['page_num'],\n",
    "        'similarity_score': max_similarities[idx],\n",
    "        'similar_to_example': similar_example['filename'],\n",
    "        'similar_to_page': similar_example['page_num']\n",
    "    }\n",
    "    results.append(result)\n",
    "    \n",
    "    print(f\"\\n{rank + 1}. File: {metadata['filename']}, Page: {metadata['page_num']}\")\n",
    "    print(f\"   Similarity: {max_similarities[idx]:.4f}\")\n",
    "    print(f\"   Most similar to: {similar_example['filename']}, page {similar_example['page_num']}\")\n",
    "\n",
    "# Create DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Most Similar Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top 5 most similar non-example pages\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 10))\n",
    "fig.suptitle('Top 5 Most Similar Non-Example Pages', fontsize=16)\n",
    "\n",
    "for i, idx in enumerate(top_k_indices[:5]):\n",
    "    # Non-example page\n",
    "    ax_non = axes[0, i]\n",
    "    ax_non.imshow(non_example_images[idx])\n",
    "    ax_non.set_title(f\"Non-Example\\n{non_example_metadata[idx]['filename']}\\nPage {non_example_metadata[idx]['page_num']}\\nScore: {max_similarities[idx]:.3f}\")\n",
    "    ax_non.axis('off')\n",
    "    \n",
    "    # Most similar example page\n",
    "    similar_example_idx = most_similar_example_idx[idx]\n",
    "    example_meta = example_metadata[similar_example_idx]\n",
    "    \n",
    "    # Load the example image for visualization\n",
    "    example_pdf_path = Path(example_meta['file_path'])\n",
    "    example_images = pdf_to_images(example_pdf_path)\n",
    "    example_image = preprocess_image_for_donut(example_images[example_meta['page_num'] - 1])\n",
    "    \n",
    "    ax_ex = axes[1, i]\n",
    "    ax_ex.imshow(example_image)\n",
    "    ax_ex.set_title(f\"Similar Example\\n{example_meta['filename']}\\nPage {example_meta['page_num']}\")\n",
    "    ax_ex.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Analyze Similarity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of similarity scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(max_similarities, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.axvline(x=most_similar_score, color='red', linestyle='--', label=f'Most similar: {most_similar_score:.3f}')\n",
    "plt.xlabel('Maximum Cosine Similarity Score')\n",
    "plt.ylabel('Number of Non-Example Pages')\n",
    "plt.title('Distribution of Similarity Scores\\n(Non-Example Pages vs Most Similar Example Form)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\nSimilarity Statistics:\")\n",
    "print(f\"Mean similarity: {max_similarities.mean():.4f}\")\n",
    "print(f\"Std deviation: {max_similarities.std():.4f}\")\n",
    "print(f\"Min similarity: {max_similarities.min():.4f}\")\n",
    "print(f\"Max similarity: {max_similarities.max():.4f}\")\n",
    "print(f\"\\nPages with similarity > 0.9: {(max_similarities > 0.9).sum()}\")\n",
    "print(f\"Pages with similarity > 0.8: {(max_similarities > 0.8).sum()}\")\n",
    "print(f\"Pages with similarity > 0.7: {(max_similarities > 0.7).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed results to CSV\n",
    "all_results = []\n",
    "\n",
    "for idx, (score, example_idx) in enumerate(zip(max_similarities, most_similar_example_idx)):\n",
    "    metadata = non_example_metadata[idx]\n",
    "    similar_example = example_metadata[example_idx]\n",
    "    \n",
    "    all_results.append({\n",
    "        'non_example_file': metadata['filename'],\n",
    "        'non_example_page': metadata['page_num'],\n",
    "        'non_example_total_pages': metadata['total_pages'],\n",
    "        'similarity_score': score,\n",
    "        'most_similar_example_file': similar_example['filename'],\n",
    "        'most_similar_example_page': similar_example['page_num']\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('similarity_score', ascending=False)\n",
    "results_df.to_csv('similarity_results.csv', index=False)\n",
    "\n",
    "print(f\"\\nResults saved to similarity_results.csv\")\n",
    "print(f\"\\nTop 10 most similar pages:\")\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Identify Potential Misclassified Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pages with very high similarity might be misclassified\n",
    "threshold = 0.85  # Adjust based on your needs\n",
    "potential_misclassified = results_df[results_df['similarity_score'] > threshold]\n",
    "\n",
    "print(f\"\\nPotential misclassified pages (similarity > {threshold}):\")\n",
    "print(f\"Found {len(potential_misclassified)} pages\")\n",
    "\n",
    "if len(potential_misclassified) > 0:\n",
    "    print(\"\\nThese non-example pages are very similar to the administrative forms:\")\n",
    "    for _, row in potential_misclassified.iterrows():\n",
    "        print(f\"\\n- File: {row['non_example_file']}, Page: {row['non_example_page']}\")\n",
    "        print(f\"  Similarity: {row['similarity_score']:.4f}\")\n",
    "        print(f\"  Similar to: {row['most_similar_example_file']}, page {row['most_similar_example_page']}\")\n",
    "    \n",
    "    # Save potential misclassified pages\n",
    "    potential_misclassified.to_csv('potential_misclassified_pages.csv', index=False)\n",
    "    print(\"\\nSaved to potential_misclassified_pages.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Notes\n",
    "\n",
    "This notebook helps identify:\n",
    "\n",
    "1. **Most Similar Pages**: Which pages in the non-examples are most visually similar to the administrative forms\n",
    "2. **Potential Misclassifications**: Pages with very high similarity scores might actually be administrative forms that were incorrectly placed in the non-examples folder\n",
    "3. **Similarity Distribution**: Understanding how similar non-form pages are to form pages helps set classification thresholds\n",
    "\n",
    "### Next Steps:\n",
    "- Review pages with high similarity scores (>0.85) to check if they're actually administrative forms\n",
    "- Use the similarity threshold to improve the classifier's decision boundary\n",
    "- Consider adding highly similar non-forms as hard negative examples in training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}