{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Administrative Form Classifier with Parallel Processing\n",
    "\n",
    "This notebook implements a zero-shot classifier that identifies administrative forms using embedding similarity, with multiprocessing support for efficient large-scale processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Available CPU cores: 10\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup and imports\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# IMPORTANT: For parallel processing in Jupyter, we use concurrent.futures instead of multiprocessing.Pool\n",
    "# This avoids the \"Can't get attribute\" error that occurs with multiprocessing in notebooks\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For parallel processing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# Model imports\n",
    "from transformers import (\n",
    "    DonutProcessor, \n",
    "    VisionEncoderDecoderModel,\n",
    "    CLIPProcessor, \n",
    "    CLIPModel,\n",
    "    AutoImageProcessor, \n",
    "    AutoModel\n",
    ")\n",
    "\n",
    "# Check device and cores\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Available CPU cores: {cpu_count()}\")\n",
    "\n",
    "# Import cpu_count\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2. Configuration\nBASE_PATH = Path('/Users/admin-tascott/Documents/GitHub/chehalis')\nEXAMPLE_FORMS_PATH = BASE_PATH / 'data' / 'raw' / '_exampleforms'\nNON_EXAMPLES_PATH = BASE_PATH / 'data' / 'raw' / '_nonexamples'\n\n# Model selection\nMODEL_TYPE = \"clip\"  # Options: \"donut\", \"clip\", \"dinov2\"\n\n# Processing parameters\nIMAGE_DPI = 150\nBATCH_SIZE = 8\nSIMILARITY_THRESHOLD = 0.85\n\n# Parallel processing parameters\n# NOTE: In Jupyter, we use ThreadPoolExecutor instead of ProcessPoolExecutor\n# Threads share memory so they can use the same model instance\nUSE_MULTIPROCESSING = True  # This will use threading, not true multiprocessing\nN_WORKERS = min(cpu_count() - 1, 8)  # Limit to 8 threads max\nMAX_PDFS_PER_WORKER = 100\n\n# Output paths\nEMBEDDINGS_CACHE_PATH = BASE_PATH / 'code' / 'preprocessing' / 'cached_embeddings'\nEMBEDDINGS_CACHE_PATH.mkdir(exist_ok=True)\n\nprint(f\"Will use {N_WORKERS} threads for parallel processing\")"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP model\n",
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# 3. Load model\n",
    "def load_model(model_type: str):\n",
    "    \"\"\"Load the specified model for embedding extraction\"\"\"\n",
    "    \n",
    "    if model_type == \"donut\":\n",
    "        MODEL_DIR = \"./form_classifier_model\"\n",
    "        if os.path.exists(MODEL_DIR):\n",
    "            print(f\"Loading fine-tuned Donut model from {MODEL_DIR}\")\n",
    "            model = VisionEncoderDecoderModel.from_pretrained(MODEL_DIR)\n",
    "            processor = DonutProcessor.from_pretrained(MODEL_DIR)\n",
    "        else:\n",
    "            print(\"Loading base Donut model\")\n",
    "            model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "            processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "        return model.encoder.to(device), processor\n",
    "    \n",
    "    elif model_type == \"clip\":\n",
    "        print(\"Loading CLIP model\")\n",
    "        model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        return model.vision_model.to(device), processor\n",
    "    \n",
    "    elif model_type == \"dinov2\":\n",
    "        print(\"Loading DINOv2 model\")\n",
    "        processor = AutoImageProcessor.from_pretrained('facebook/dinov2-base')\n",
    "        model = AutoModel.from_pretrained('facebook/dinov2-base')\n",
    "        return model.to(device), processor\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "# Load the selected model\n",
    "model, processor = load_model(MODEL_TYPE)\n",
    "model.eval()\n",
    "print(f\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Basic helper functions\n",
    "def pdf_to_images(pdf_path: Path, dpi: int = IMAGE_DPI) -> List[Image.Image]:\n",
    "    \"\"\"Convert PDF to list of PIL Images\"\"\"\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path, dpi=dpi)\n",
    "        return images\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting {pdf_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def preprocess_image(image: Image.Image, model_type: str) -> Image.Image:\n",
    "    \"\"\"Preprocess image based on model requirements\"\"\"\n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    \n",
    "    if model_type == \"donut\":\n",
    "        image.thumbnail((1280, 960), Image.Resampling.LANCZOS)\n",
    "    else:\n",
    "        image.thumbnail((224, 224), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Embedding extraction functions\n",
    "@torch.no_grad()\n",
    "def extract_embeddings(images: List[Image.Image], model, processor, model_type: str, \n",
    "                      batch_size: int = BATCH_SIZE) -> np.ndarray:\n",
    "    \"\"\"Extract embeddings for a list of images\"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_images = images[i:i+batch_size]\n",
    "        batch_images = [preprocess_image(img, model_type) for img in batch_images]\n",
    "        \n",
    "        if model_type in [\"donut\", \"clip\"]:\n",
    "            inputs = processor(images=batch_images, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**inputs)\n",
    "        else:  # dinov2\n",
    "            inputs = processor(images=batch_images, return_tensors=\"pt\").to(device)\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:\n",
    "            batch_embeddings = outputs.pooler_output\n",
    "        elif hasattr(outputs, 'last_hidden_state'):\n",
    "            batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        else:\n",
    "            batch_embeddings = outputs[0].mean(dim=1)\n",
    "        \n",
    "        embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_embedding_single(image: Image.Image, model, processor, model_type: str) -> np.ndarray:\n",
    "    \"\"\"Extract embedding for a single image\"\"\"\n",
    "    image = preprocess_image(image, model_type)\n",
    "    \n",
    "    if model_type in [\"donut\", \"clip\"]:\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "    else:  # dinov2\n",
    "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:\n",
    "        embedding = outputs.pooler_output\n",
    "    elif hasattr(outputs, 'last_hidden_state'):\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    else:\n",
    "        embedding = outputs[0].mean(dim=1)\n",
    "    \n",
    "    return embedding.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 6. Parallel processing functions\n# For Jupyter, we'll use ThreadPoolExecutor which works better than ProcessPoolExecutor\n\nfrom concurrent.futures import ThreadPoolExecutor\nimport threading\n\n# Global lock for thread-safe operations\nprint_lock = threading.Lock()\n\ndef process_pdf_threaded(pdf_path: Path, model, processor, model_type: str) -> Dict:\n    \"\"\"Process a single PDF in a thread\"\"\"\n    results = {\n        'filename': pdf_path.name,\n        'path': str(pdf_path),\n        'embeddings': [],\n        'page_numbers': [],\n        'error': None\n    }\n    \n    try:\n        # Convert PDF to images\n        images = pdf_to_images(pdf_path, dpi=IMAGE_DPI)\n        \n        if not images:\n            results['error'] = \"Failed to convert PDF\"\n            return results\n        \n        # Process each page\n        for page_num, image in enumerate(images, 1):\n            try:\n                # Extract embedding using the main process model\n                embedding = extract_embedding_single(image, model, processor, model_type)\n                results['embeddings'].append(embedding)\n                results['page_numbers'].append(page_num)\n                \n            except Exception as e:\n                with print_lock:\n                    print(f\"Error processing page {page_num} of {pdf_path.name}: {e}\")\n        \n        results['num_pages'] = len(images)\n        \n    except Exception as e:\n        results['error'] = str(e)\n        with print_lock:\n            print(f\"Error processing {pdf_path.name}: {e}\")\n    \n    return results\n\ndef process_pdfs_parallel(pdf_files: List[Path], model_type: str, n_workers: int = None) -> List[Dict]:\n    \"\"\"Process multiple PDFs in parallel using ThreadPoolExecutor\"\"\"\n    \n    if n_workers is None:\n        n_workers = min(N_WORKERS, 8)  # Limit threads to avoid overwhelming the system\n    \n    print(f\"\\nProcessing {len(pdf_files)} PDFs using {n_workers} threads...\")\n    start_time = time.time()\n    \n    results = []\n    \n    # Use ThreadPoolExecutor for parallel processing\n    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n        # Submit all tasks\n        future_to_pdf = {\n            executor.submit(process_pdf_threaded, pdf_path, model, processor, model_type): pdf_path \n            for pdf_path in pdf_files\n        }\n        \n        # Process completed tasks with progress bar\n        for future in tqdm(as_completed(future_to_pdf), total=len(pdf_files), desc=\"Processing PDFs\"):\n            pdf_path = future_to_pdf[future]\n            try:\n                result = future.result()\n                results.append(result)\n            except Exception as e:\n                print(f\"Error processing {pdf_path.name}: {e}\")\n                results.append({\n                    'filename': pdf_path.name,\n                    'path': str(pdf_path),\n                    'embeddings': [],\n                    'page_numbers': [],\n                    'error': str(e)\n                })\n    \n    elapsed = time.time() - start_time\n    print(f\"Processed {len(pdf_files)} PDFs in {elapsed:.1f} seconds\")\n    print(f\"Average: {elapsed/len(pdf_files):.2f} seconds per PDF\")\n    \n    # Sort results to match input order\n    results_dict = {r['filename']: r for r in results}\n    sorted_results = [results_dict[pdf.name] for pdf in pdf_files if pdf.name in results_dict]\n    \n    return sorted_results\n\n# Alternative: Simple batch processing without multiprocessing\ndef process_pdfs_batch(pdf_files: List[Path], model_type: str, batch_size: int = 10) -> List[Dict]:\n    \"\"\"Process PDFs in batches (no parallelism, but memory efficient)\"\"\"\n    \n    print(f\"\\nProcessing {len(pdf_files)} PDFs in batches of {batch_size}...\")\n    start_time = time.time()\n    \n    all_results = []\n    \n    for i in range(0, len(pdf_files), batch_size):\n        batch = pdf_files[i:i+batch_size]\n        print(f\"\\nProcessing batch {i//batch_size + 1}/{(len(pdf_files) + batch_size - 1)//batch_size}\")\n        \n        for pdf_path in tqdm(batch, desc=\"Current batch\"):\n            result = {\n                'filename': pdf_path.name,\n                'path': str(pdf_path),\n                'embeddings': [],\n                'page_numbers': [],\n                'error': None\n            }\n            \n            try:\n                images = pdf_to_images(pdf_path)\n                if images:\n                    embeddings = extract_embeddings(images, model, processor, model_type)\n                    for j, embedding in enumerate(embeddings):\n                        result['embeddings'].append(embedding)\n                        result['page_numbers'].append(j + 1)\n                    result['num_pages'] = len(images)\n                else:\n                    result['error'] = \"Failed to convert PDF\"\n            except Exception as e:\n                result['error'] = str(e)\n                print(f\"Error processing {pdf_path.name}: {e}\")\n            \n            all_results.append(result)\n    \n    elapsed = time.time() - start_time\n    print(f\"\\nProcessed {len(pdf_files)} PDFs in {elapsed:.1f} seconds\")\n    print(f\"Average: {elapsed/len(pdf_files):.2f} seconds per PDF\")\n    \n    return all_results"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached reference embeddings from /Users/admin-tascott/Documents/GitHub/chehalis/code/preprocessing/cached_embeddings/clip_reference_embeddings.pkl\n",
      "\n",
      "Reference set contains 111 form pages\n",
      "Embedding dimension: 768\n"
     ]
    }
   ],
   "source": [
    "# 7. Build reference embeddings\n",
    "cache_file = EMBEDDINGS_CACHE_PATH / f\"{MODEL_TYPE}_reference_embeddings.pkl\"\n",
    "\n",
    "if cache_file.exists():\n",
    "    print(f\"Loading cached reference embeddings from {cache_file}\")\n",
    "    with open(cache_file, 'rb') as f:\n",
    "        cache_data = pickle.load(f)\n",
    "        reference_embeddings = cache_data['embeddings']\n",
    "        reference_metadata = cache_data['metadata']\n",
    "else:\n",
    "    print(\"Building reference embeddings from example forms...\")\n",
    "    pdf_files = list(EXAMPLE_FORMS_PATH.glob('*.pdf'))\n",
    "    print(f\"Processing {len(pdf_files)} example form PDFs\")\n",
    "    \n",
    "    if USE_MULTIPROCESSING and len(pdf_files) > 10:\n",
    "        # Use parallel processing\n",
    "        print(\"Using parallel processing for reference embeddings...\")\n",
    "        results = process_pdfs_parallel(pdf_files, MODEL_TYPE, N_WORKERS)\n",
    "        \n",
    "        reference_embeddings = []\n",
    "        reference_metadata = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['error']:\n",
    "                print(f\"Skipping {result['filename']} due to error: {result['error']}\")\n",
    "                continue\n",
    "            \n",
    "            for embedding, page_num in zip(result['embeddings'], result['page_numbers']):\n",
    "                reference_embeddings.append(embedding)\n",
    "                reference_metadata.append({\n",
    "                    'file_path': result['path'],\n",
    "                    'filename': result['filename'],\n",
    "                    'page_num': page_num,\n",
    "                    'total_pages': result['num_pages']\n",
    "                })\n",
    "    else:\n",
    "        # Use sequential processing\n",
    "        reference_embeddings = []\n",
    "        reference_metadata = []\n",
    "        \n",
    "        for pdf_path in tqdm(pdf_files, desc=\"Processing example forms\"):\n",
    "            images = pdf_to_images(pdf_path)\n",
    "            if images:\n",
    "                embeddings = extract_embeddings(images, model, processor, MODEL_TYPE)\n",
    "                for i, embedding in enumerate(embeddings):\n",
    "                    reference_embeddings.append(embedding)\n",
    "                    reference_metadata.append({\n",
    "                        'file_path': str(pdf_path),\n",
    "                        'filename': pdf_path.name,\n",
    "                        'page_num': i + 1,\n",
    "                        'total_pages': len(images)\n",
    "                    })\n",
    "    \n",
    "    reference_embeddings = np.array(reference_embeddings)\n",
    "    \n",
    "    # Cache the embeddings\n",
    "    print(f\"Caching reference embeddings to {cache_file}\")\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'embeddings': reference_embeddings,\n",
    "            'metadata': reference_metadata,\n",
    "            'model_type': MODEL_TYPE\n",
    "        }, f)\n",
    "\n",
    "print(f\"\\nReference set contains {len(reference_embeddings)} form pages\")\n",
    "print(f\"Embedding dimension: {reference_embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference prototype shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "# 8. Similarity computation functions\n",
    "reference_prototype = reference_embeddings.mean(axis=0)\n",
    "print(f\"Reference prototype shape: {reference_prototype.shape}\")\n",
    "\n",
    "def compute_similarity_to_prototype(embedding: np.ndarray, prototype: np.ndarray) -> float:\n",
    "    \"\"\"Compute cosine similarity to prototype\"\"\"\n",
    "    return cosine_similarity(embedding.reshape(1, -1), prototype.reshape(1, -1))[0, 0]\n",
    "\n",
    "def compute_similarity_to_references(embedding: np.ndarray, references: np.ndarray, \n",
    "                                   method: str = 'max') -> float:\n",
    "    \"\"\"Compute similarity to reference set\"\"\"\n",
    "    similarities = cosine_similarity(embedding.reshape(1, -1), references)[0]\n",
    "    \n",
    "    if method == 'max':\n",
    "        return similarities.max()\n",
    "    elif method == 'mean':\n",
    "        return similarities.mean()\n",
    "    elif method == 'top_k':\n",
    "        k = min(5, len(similarities))\n",
    "        return np.sort(similarities)[-k:].mean()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Classification functions\n",
    "def classify_pdf_zero_shot(pdf_path: Path, \n",
    "                          model, \n",
    "                          processor,\n",
    "                          model_type: str,\n",
    "                          reference_embeddings: np.ndarray,\n",
    "                          reference_prototype: np.ndarray,\n",
    "                          threshold: float = SIMILARITY_THRESHOLD,\n",
    "                          use_prototype: bool = True) -> Dict:\n",
    "    \"\"\"Classify pages in a PDF using zero-shot similarity matching\"\"\"\n",
    "    results = {\n",
    "        'filename': pdf_path.name,\n",
    "        'contains_form': False,\n",
    "        'form_pages': [],\n",
    "        'page_scores': [],\n",
    "        'max_similarity': 0.0,\n",
    "        'error': None\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        images = pdf_to_images(pdf_path)\n",
    "        if not images:\n",
    "            results['error'] = \"Failed to convert PDF\"\n",
    "            return results\n",
    "        \n",
    "        for page_num, image in enumerate(images, 1):\n",
    "            embedding = extract_embedding_single(image, model, processor, model_type)\n",
    "            \n",
    "            if use_prototype:\n",
    "                similarity = compute_similarity_to_prototype(embedding, reference_prototype)\n",
    "            else:\n",
    "                similarity = compute_similarity_to_references(embedding, reference_embeddings, method='max')\n",
    "            \n",
    "            results['page_scores'].append({\n",
    "                'page': page_num,\n",
    "                'similarity': float(similarity)\n",
    "            })\n",
    "            \n",
    "            if similarity >= threshold:\n",
    "                results['form_pages'].append(page_num)\n",
    "                results['contains_form'] = True\n",
    "            \n",
    "            results['max_similarity'] = max(results['max_similarity'], similarity)\n",
    "        \n",
    "        results['total_pages'] = len(images)\n",
    "        \n",
    "    except Exception as e:\n",
    "        results['error'] = str(e)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def classify_pdf_batch_parallel(pdf_paths: List[Path],\n",
    "                               reference_embeddings: np.ndarray,\n",
    "                               reference_prototype: np.ndarray,\n",
    "                               model_type: str,\n",
    "                               threshold: float = SIMILARITY_THRESHOLD,\n",
    "                               use_prototype: bool = True,\n",
    "                               n_workers: int = None) -> List[Dict]:\n",
    "    \"\"\"Classify a batch of PDFs in parallel\"\"\"\n",
    "    \n",
    "    # Extract embeddings in parallel\n",
    "    embedding_results = process_pdfs_parallel(pdf_paths, model_type, n_workers)\n",
    "    \n",
    "    # Classify based on embeddings\n",
    "    classification_results = []\n",
    "    \n",
    "    for result in embedding_results:\n",
    "        if result['error']:\n",
    "            classification_results.append({\n",
    "                'filename': result['filename'],\n",
    "                'contains_form': False,\n",
    "                'form_pages': [],\n",
    "                'page_scores': [],\n",
    "                'max_similarity': 0.0,\n",
    "                'error': result['error']\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        form_pages = []\n",
    "        page_scores = []\n",
    "        max_similarity = 0.0\n",
    "        \n",
    "        for embedding, page_num in zip(result['embeddings'], result['page_numbers']):\n",
    "            if use_prototype:\n",
    "                similarity = compute_similarity_to_prototype(embedding, reference_prototype)\n",
    "            else:\n",
    "                similarity = compute_similarity_to_references(embedding, reference_embeddings, method='max')\n",
    "            \n",
    "            page_scores.append({\n",
    "                'page': page_num,\n",
    "                'similarity': float(similarity)\n",
    "            })\n",
    "            \n",
    "            if similarity >= threshold:\n",
    "                form_pages.append(page_num)\n",
    "            \n",
    "            max_similarity = max(max_similarity, similarity)\n",
    "        \n",
    "        classification_results.append({\n",
    "            'filename': result['filename'],\n",
    "            'contains_form': len(form_pages) > 0,\n",
    "            'form_pages': form_pages,\n",
    "            'page_scores': page_scores,\n",
    "            'max_similarity': max_similarity,\n",
    "            'total_pages': result.get('num_pages', len(result['embeddings'])),\n",
    "            'error': None\n",
    "        })\n",
    "    \n",
    "    return classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on known examples to tune threshold...\n",
      "\n",
      "Computing self-similarity for positive examples...\n",
      "\n",
      "Testing on non-examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing non-examples: 100%|█████████████████████████████████████████████████████████████████████████████████████| 20/20 [02:12<00:00,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Positive scores - Mean: 0.982, Std: 0.014\n",
      "Negative scores - Mean: 0.649, Std: 0.058\n",
      "\n",
      "Selected optimal threshold: 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Threshold tuning\n",
    "print(\"Testing on known examples to tune threshold...\")\n",
    "\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "\n",
    "# Test on subset of examples\n",
    "print(\"\\nComputing self-similarity for positive examples...\")\n",
    "for i in range(min(50, len(reference_embeddings))):\n",
    "    embedding = reference_embeddings[i]\n",
    "    other_embeddings = np.delete(reference_embeddings, i, axis=0)\n",
    "    similarity = compute_similarity_to_references(embedding, other_embeddings, method='max')\n",
    "    positive_scores.append(similarity)\n",
    "\n",
    "# Test on non-examples\n",
    "print(\"\\nTesting on non-examples...\")\n",
    "non_example_files = list(NON_EXAMPLES_PATH.glob('*.pdf'))[:20]\n",
    "\n",
    "for pdf_path in tqdm(non_example_files, desc=\"Processing non-examples\"):\n",
    "    result = classify_pdf_zero_shot(\n",
    "        pdf_path, model, processor, MODEL_TYPE,\n",
    "        reference_embeddings, reference_prototype,\n",
    "        threshold=0.0,\n",
    "        use_prototype=False\n",
    "    )\n",
    "    \n",
    "    if result['page_scores']:\n",
    "        for page_score in result['page_scores']:\n",
    "            negative_scores.append(page_score['similarity'])\n",
    "\n",
    "# Analyze scores\n",
    "positive_scores = np.array(positive_scores)\n",
    "negative_scores = np.array(negative_scores)\n",
    "\n",
    "print(f\"\\nPositive scores - Mean: {positive_scores.mean():.3f}, Std: {positive_scores.std():.3f}\")\n",
    "print(f\"Negative scores - Mean: {negative_scores.mean():.3f}, Std: {negative_scores.std():.3f}\")\n",
    "\n",
    "# Find optimal threshold\n",
    "gap_threshold = (positive_scores.min() + negative_scores.max()) / 2\n",
    "percentile_threshold = np.percentile(negative_scores, 99)\n",
    "OPTIMAL_THRESHOLD = max(gap_threshold, percentile_threshold)\n",
    "print(f\"\\nSelected optimal threshold: {OPTIMAL_THRESHOLD:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Batch processing function\n",
    "def process_document_folder(folder_path: Path,\n",
    "                          model,\n",
    "                          processor,\n",
    "                          model_type: str,\n",
    "                          reference_embeddings: np.ndarray,\n",
    "                          reference_prototype: np.ndarray,\n",
    "                          threshold: float,\n",
    "                          output_file: str = 'zero_shot_results.csv',\n",
    "                          max_files: Optional[int] = None,\n",
    "                          use_prototype: bool = True,\n",
    "                          use_parallel: bool = None) -> pd.DataFrame:\n",
    "    \"\"\"Process all PDFs in a folder using zero-shot classification\"\"\"\n",
    "    \n",
    "    if use_parallel is None:\n",
    "        use_parallel = USE_MULTIPROCESSING\n",
    "    \n",
    "    results = []\n",
    "    pdf_files = list(folder_path.glob('*.pdf'))\n",
    "    \n",
    "    if max_files:\n",
    "        pdf_files = pdf_files[:max_files]\n",
    "    \n",
    "    print(f\"Processing {len(pdf_files)} PDF files...\")\n",
    "    \n",
    "    if use_parallel and len(pdf_files) > 10:\n",
    "        # Use parallel processing\n",
    "        print(f\"Using parallel processing with {N_WORKERS} workers...\")\n",
    "        batch_size = min(MAX_PDFS_PER_WORKER * N_WORKERS, len(pdf_files))\n",
    "        \n",
    "        for i in range(0, len(pdf_files), batch_size):\n",
    "            batch_files = pdf_files[i:i+batch_size]\n",
    "            print(f\"\\nProcessing batch {i//batch_size + 1}/{(len(pdf_files) + batch_size - 1)//batch_size}\")\n",
    "            \n",
    "            batch_results = classify_pdf_batch_parallel(\n",
    "                batch_files,\n",
    "                reference_embeddings,\n",
    "                reference_prototype,\n",
    "                model_type,\n",
    "                threshold=threshold,\n",
    "                use_prototype=use_prototype,\n",
    "                n_workers=N_WORKERS\n",
    "            )\n",
    "            \n",
    "            for result in batch_results:\n",
    "                results.append({\n",
    "                    'filename': result['filename'],\n",
    "                    'contains_form': result['contains_form'],\n",
    "                    'form_pages': ','.join(map(str, result['form_pages'])),\n",
    "                    'num_form_pages': len(result['form_pages']),\n",
    "                    'total_pages': result.get('total_pages', 0),\n",
    "                    'max_similarity': result['max_similarity'],\n",
    "                    'error': result['error']\n",
    "                })\n",
    "    else:\n",
    "        # Use sequential processing\n",
    "        print(\"Using sequential processing...\")\n",
    "        for pdf_path in tqdm(pdf_files):\n",
    "            result = classify_pdf_zero_shot(\n",
    "                pdf_path, model, processor, model_type,\n",
    "                reference_embeddings, reference_prototype,\n",
    "                threshold=threshold,\n",
    "                use_prototype=use_prototype\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'filename': result['filename'],\n",
    "                'contains_form': result['contains_form'],\n",
    "                'form_pages': ','.join(map(str, result['form_pages'])),\n",
    "                'num_form_pages': len(result['form_pages']),\n",
    "                'total_pages': result.get('total_pages', 0),\n",
    "                'max_similarity': result['max_similarity'],\n",
    "                'error': result['error']\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame and save\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nResults saved to {output_file}\")\n",
    "    print(f\"Total documents processed: {len(df_results)}\")\n",
    "    print(f\"Documents with forms: {df_results['contains_form'].sum()}\")\n",
    "    print(f\"Documents without forms: {(~df_results['contains_form']).sum()}\")\n",
    "    print(f\"Processing errors: {df_results['error'].notna().sum()}\")\n",
    "    \n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on sample documents...\n",
      "Processing 50 PDF files...\n",
      "Using parallel processing with 9 workers...\n",
      "\n",
      "Processing batch 1/1\n",
      "\n",
      "Processing 50 PDFs using 9 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|                                                                                                      | 0/50 [00:00<?, ?it/s]Process SpawnProcess-7330:\n",
      "Process SpawnProcess-7327:\n",
      "Process SpawnProcess-7324:\n",
      "Process SpawnProcess-7326:\n",
      "Process SpawnProcess-7329:\n",
      "Process SpawnProcess-7325:\n",
      "Process SpawnProcess-7328:\n",
      "Process SpawnProcess-7323:\n",
      "Process SpawnProcess-7331:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.11/concurrent/futures/process.py\", line 249, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_pdf_worker' on <module '__main__' (built-in)>\n",
      "Processing PDFs: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 356.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing 25581-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 0000000000000000000062223-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 1197-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 67419-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 104473-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-10-FSSA-DDRS-495-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-8-FSSA-DMHA-564-003.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 104303-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-43810SAS-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-UNION2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-43810SAS-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-HUNTINGTON2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-8-FSSA-DMHA-564-002.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-ADAMS2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-STJOSEPH2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-2-DCS-MARIONMS-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-CLINTON2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-FSSA-DFR-405-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 781-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-CLAY2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-FSSA-DMHA-573-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-8-FSSA-DMHA-564-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-10-FSSA-DFR-705-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 104324-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-FSSA-DFR-668-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-6-FSSA-DCS-504-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-FSSA-DFR-404-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 739-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 764-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 706-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-10-FSSA-DFR-704-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 799-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 730-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-10-FSSA-DMHA-572-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 752-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-0-DCS-GRANT2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-BROWN2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-7-FSSA-DFR-532-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 104324-002.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-FSSA-DFR-406-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-0-DCS-DELAWARE2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 759-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-10-FSSA-DFR-706-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-10-FSSA-DDRS-496-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-FSSA-DMHA-569-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-FSSA-DMHA-569-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing 732-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-6-FSSA-DDRS-516-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-9-DCS-STEUBEN2-000.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Error processing F1-0-DCS-NEWTON2-001.pdf: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Processed 50 PDFs in 0.3 seconds\n",
      "Average: 0.01 seconds per PDF\n",
      "\n",
      "Results saved to zero_shot_test_results.csv\n",
      "Total documents processed: 50\n",
      "Documents with forms: 0\n",
      "Documents without forms: 50\n",
      "Processing errors: 50\n",
      "\n",
      "Sample results:\n",
      "                            filename  contains_form form_pages  \\\n",
      "0                      25581-000.pdf          False              \n",
      "1  0000000000000000000062223-001.pdf          False              \n",
      "2                       1197-000.pdf          False              \n",
      "3                      67419-000.pdf          False              \n",
      "4                     104473-000.pdf          False              \n",
      "5        F1-10-FSSA-DDRS-495-000.pdf          False              \n",
      "6         F1-8-FSSA-DMHA-564-003.pdf          False              \n",
      "7                     104303-001.pdf          False              \n",
      "8          F1-9-DCS-43810SAS-001.pdf          False              \n",
      "9            F1-9-DCS-UNION2-000.pdf          False              \n",
      "\n",
      "   num_form_pages  total_pages  max_similarity  \\\n",
      "0               0            0             0.0   \n",
      "1               0            0             0.0   \n",
      "2               0            0             0.0   \n",
      "3               0            0             0.0   \n",
      "4               0            0             0.0   \n",
      "5               0            0             0.0   \n",
      "6               0            0             0.0   \n",
      "7               0            0             0.0   \n",
      "8               0            0             0.0   \n",
      "9               0            0             0.0   \n",
      "\n",
      "                                               error  \n",
      "0  A process in the process pool was terminated a...  \n",
      "1  A process in the process pool was terminated a...  \n",
      "2  A process in the process pool was terminated a...  \n",
      "3  A process in the process pool was terminated a...  \n",
      "4  A process in the process pool was terminated a...  \n",
      "5  A process in the process pool was terminated a...  \n",
      "6  A process in the process pool was terminated a...  \n",
      "7  A process in the process pool was terminated a...  \n",
      "8  A process in the process pool was terminated a...  \n",
      "9  A process in the process pool was terminated a...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. Test classification\n",
    "print(\"Testing on sample documents...\")\n",
    "\n",
    "test_results = process_document_folder(\n",
    "    NON_EXAMPLES_PATH,\n",
    "    model,\n",
    "    processor,\n",
    "    MODEL_TYPE,\n",
    "    reference_embeddings,\n",
    "    reference_prototype,\n",
    "    threshold=OPTIMAL_THRESHOLD,\n",
    "    output_file='zero_shot_test_results.csv',\n",
    "    max_files=50,\n",
    "    use_prototype=False\n",
    ")\n",
    "\n",
    "print(\"\\nSample results:\")\n",
    "print(test_results.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Performance comparison (Sequential vs Parallel)\n",
    "print(\"\\nPerformance Comparison: Sequential vs Parallel Processing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_files = list(NON_EXAMPLES_PATH.glob('*.pdf'))[:20]\n",
    "\n",
    "if len(test_files) >= 10:\n",
    "    # Sequential processing\n",
    "    print(\"\\n1. Sequential Processing:\")\n",
    "    start_time = time.time()\n",
    "    seq_results = process_document_folder(\n",
    "        NON_EXAMPLES_PATH,\n",
    "        model,\n",
    "        processor,\n",
    "        MODEL_TYPE,\n",
    "        reference_embeddings,\n",
    "        reference_prototype,\n",
    "        threshold=OPTIMAL_THRESHOLD,\n",
    "        output_file='sequential_test.csv',\n",
    "        max_files=20,\n",
    "        use_prototype=False,\n",
    "        use_parallel=False\n",
    "    )\n",
    "    seq_time = time.time() - start_time\n",
    "    print(f\"Sequential time: {seq_time:.1f} seconds\")\n",
    "    \n",
    "    # Parallel processing\n",
    "    print(\"\\n2. Parallel Processing:\")\n",
    "    start_time = time.time()\n",
    "    par_results = process_document_folder(\n",
    "        NON_EXAMPLES_PATH,\n",
    "        model,\n",
    "        processor,\n",
    "        MODEL_TYPE,\n",
    "        reference_embeddings,\n",
    "        reference_prototype,\n",
    "        threshold=OPTIMAL_THRESHOLD,\n",
    "        output_file='parallel_test.csv',\n",
    "        max_files=20,\n",
    "        use_prototype=False,\n",
    "        use_parallel=True\n",
    "    )\n",
    "    par_time = time.time() - start_time\n",
    "    print(f\"Parallel time: {par_time:.1f} seconds\")\n",
    "    \n",
    "    # Results\n",
    "    speedup = seq_time / par_time\n",
    "    print(f\"\\nSpeedup: {speedup:.1f}x faster with {N_WORKERS} workers\")\n",
    "    print(f\"\\nEstimated time for 190k documents:\")\n",
    "    print(f\"Sequential: {190000 * seq_time / len(test_files) / 3600:.1f} hours\")\n",
    "    print(f\"Parallel: {190000 * par_time / len(test_files) / 3600:.1f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Process full corpus (example code)\n",
    "print(\"\\nExample code for processing full corpus:\")\n",
    "print(\"\"\"\n",
    "# To process your full 190k corpus:\n",
    "CORPUS_PATH = BASE_PATH / 'data' / 'raw' / 'all_contracts'\n",
    "\n",
    "results_df = process_document_folder(\n",
    "    CORPUS_PATH,\n",
    "    model,\n",
    "    processor,\n",
    "    MODEL_TYPE,\n",
    "    reference_embeddings,\n",
    "    reference_prototype,\n",
    "    threshold=OPTIMAL_THRESHOLD,\n",
    "    output_file='full_corpus_results.csv',\n",
    "    use_prototype=False,  # Use full reference set for better accuracy\n",
    "    use_parallel=True     # Use parallel processing\n",
    ")\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}