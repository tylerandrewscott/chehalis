{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c3ea9bcb-dbf8-4241-a25c-b3beeee40e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# URL of the website\n",
    "url = \"https://secure.in.gov/apps/idoa/contractsearch/api/contracts/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351effe-f0cb-4575-81df-e87973083a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "wvabzfj3x1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for incremental update\n",
    "def load_existing_contracts(filepath):\n",
    "    \"\"\"Load existing contracts and return both data and set of existing records (as tuples)\"\"\"\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # Create a set of tuples representing unique records\n",
    "            # Using key fields that together identify a unique record\n",
    "            existing_records = set()\n",
    "            for record in data:\n",
    "                if isinstance(record, dict):\n",
    "                    # Create a tuple of key fields that uniquely identify a record\n",
    "                    record_tuple = (\n",
    "                        record.get('id'),\n",
    "                        record.get('pdfUrl'),\n",
    "                        record.get('actionType'),\n",
    "                        record.get('vendorName'),\n",
    "                        record.get('amount'),\n",
    "                        record.get('startDate'),\n",
    "                        record.get('endDate')\n",
    "                    )\n",
    "                    existing_records.add(record_tuple)\n",
    "            \n",
    "            print(f\"Successfully loaded {len(data)} records from {filepath}\")\n",
    "            print(f\"Found {len(existing_records)} unique records\")\n",
    "            return data, existing_records\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error reading JSON file: {e}\")\n",
    "            print(\"File may be corrupted. Returning empty data.\")\n",
    "            return [], set()\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error reading file: {e}\")\n",
    "            return [], set()\n",
    "    else:\n",
    "        print(f\"File {filepath} does not exist. Will create new file.\")\n",
    "        return [], set()\n",
    "\n",
    "def get_record_tuple(record):\n",
    "    \"\"\"Convert a record dict to a tuple for comparison\"\"\"\n",
    "    return (\n",
    "        record.get('id'),\n",
    "        record.get('pdfUrl'),\n",
    "        record.get('actionType'),\n",
    "        record.get('vendorName'),\n",
    "        record.get('amount'),\n",
    "        record.get('startDate'),\n",
    "        record.get('endDate')\n",
    "    )\n",
    "\n",
    "def scrape_all_new_records(url, existing_records, contract_type_flags=None, page_size=1000):\n",
    "    \"\"\"\n",
    "    Scrape all pages and collect only new records that don't exist in the dataset.\n",
    "    \"\"\"\n",
    "    new_records = []\n",
    "    page = 1\n",
    "    \n",
    "    # Get first page to determine total pages\n",
    "    payload = {\n",
    "        \"pageNumber\": page,\n",
    "        \"pageSize\": page_size\n",
    "    }\n",
    "    \n",
    "    if contract_type_flags is not None:\n",
    "        payload[\"contractTypeFlags\"] = contract_type_flags\n",
    "    \n",
    "    # Make initial request\n",
    "    resp = requests.post(url, json=payload)\n",
    "    if resp.status_code != 200:\n",
    "        print(f\"Error: {resp.status_code}\")\n",
    "        return new_records\n",
    "    \n",
    "    js_result = resp.json()\n",
    "    pagination = js_result.get('pagination', {})\n",
    "    total_pages = pagination.get('totalPages', 0)\n",
    "    \n",
    "    print(f\"Total pages to scan: {total_pages}\")\n",
    "    \n",
    "    # Process all pages\n",
    "    while page <= total_pages:\n",
    "        if page > 1:  # We already have page 1 data\n",
    "            payload[\"pageNumber\"] = page\n",
    "            resp = requests.post(url, json=payload)\n",
    "            if resp.status_code != 200:\n",
    "                print(f\"Error on page {page}: {resp.status_code}\")\n",
    "                page += 1\n",
    "                continue\n",
    "            js_result = resp.json()\n",
    "        \n",
    "        results = js_result.get('results', [])\n",
    "        \n",
    "        # Check each record\n",
    "        new_on_page = 0\n",
    "        for record in results:\n",
    "            record_tuple = get_record_tuple(record)\n",
    "            if record_tuple not in existing_records:\n",
    "                new_records.append(record)\n",
    "                new_on_page += 1\n",
    "        \n",
    "        print(f\"Page {page}/{total_pages}: Found {new_on_page} new records\")\n",
    "        \n",
    "        page += 1\n",
    "        if page <= total_pages:\n",
    "            time.sleep(0.25)  # Rate limiting\n",
    "    \n",
    "    print(f\"\\nTotal new records found: {len(new_records)}\")\n",
    "    return new_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ogxfyvb2t4q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Set CLOBBER = True to scrape everything and overwrite existing file\n",
    "# Set CLOBBER = False to only scrape until existing IDs are found and combine with existing data\n",
    "CLOBBER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "q66jpob308h",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_contracts(url, contract_type_flags=None, start_date='2000-01-01T00:00:00.0000000', page_size=1000):\n",
    "    \"\"\"Scrape all contracts from the start date\"\"\"\n",
    "    # Build initial request\n",
    "    payload = {\n",
    "        \"pageNumber\": 1,\n",
    "        \"pageSize\": page_size,\n",
    "        \"startDate\": start_date\n",
    "    }\n",
    "    \n",
    "    if contract_type_flags is not None:\n",
    "        payload[\"contractTypeFlags\"] = contract_type_flags\n",
    "    \n",
    "    # Get first page\n",
    "    resp = requests.post(url, json=payload)\n",
    "    js_result = resp.json()\n",
    "    paginate = js_result['pagination']\n",
    "    total_pages = paginate['totalPages']\n",
    "    all_records = js_result['results']\n",
    "    \n",
    "    print(f\"Total pages to scrape: {total_pages}\")\n",
    "    \n",
    "    # Get remaining pages\n",
    "    for p in range(2, total_pages + 1):\n",
    "        print(f\"Processing page {p}/{total_pages}\")\n",
    "        payload[\"pageNumber\"] = p\n",
    "        resp = requests.post(url, json=payload)\n",
    "        js_result = resp.json()\n",
    "        all_records.extend(js_result['results'])\n",
    "        time.sleep(0.25)\n",
    "    \n",
    "    return all_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "681f4a0b-f300-4ca1-8f2c-0fd6e3d5412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 181000 records from ../../data/raw/indiana_contracts.json\n",
      "Found 180445 unique records\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Correct usage:\n",
    "filepath = '../../data/raw/indiana_contracts.json'\n",
    "data, existing_ids = load_existing_contracts(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "jzb0ihh0739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 181000 records from ../../data/raw/indiana_contracts.json\n",
      "Found 180445 unique records\n",
      "\n",
      "First contract structure:\n",
      "Keys: ['actionType', 'agencyName', 'amendment', 'amount', 'businessUnit', 'contractTypeFlags', 'id', 'endDate', 'pdfUrl', 'startDate', 'vendorName', 'zipCode', 'approvals']\n",
      "\n",
      "Example record:\n",
      "ID: A70-5-2020\n",
      "PDF URL: https://contracts.idoa.in.gov/idoacontractsweb/PUBLIC/10778-001.pdf\n",
      "Vendor: GENESIS SYSTEMS INC\n",
      "Amount: N/A\n"
     ]
    }
   ],
   "source": [
    "# Example: How to use load_existing_contracts function correctly\n",
    "# The function returns a tuple: (data, existing_urls)\n",
    "\n",
    "# Correct usage:\n",
    "filepath = '../../data/raw/indiana_contracts.json'\n",
    "data, existing_urls = load_existing_contracts(filepath)\n",
    "\n",
    "# If you want to inspect the data structure:\n",
    "if data:\n",
    "    print(\"\\nFirst contract structure:\")\n",
    "    print(f\"Keys: {list(data[0].keys())}\")\n",
    "    print(f\"\\nExample record:\")\n",
    "    print(f\"ID: {data[0].get('id')}\")\n",
    "    print(f\"PDF URL: {data[0].get('pdfUrl')}\")\n",
    "    print(f\"Vendor: {data[0].get('vendorName')}\")\n",
    "    print(f\"Amount: ${data[0].get('amount'):,.2f}\" if data[0].get('amount') else \"Amount: N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30b9f706-fd25-4d7d-9e16-792792bc3a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental mode: Scanning for new contracts across all pages...\n",
      "Successfully loaded 181000 records from ../../data/raw/indiana_contracts.json\n",
      "Found 180445 unique records\n",
      "Scanning all pages for new contracts...\n",
      "Total pages to scan: 194\n",
      "Page 1/194: Found 5 new records\n",
      "Page 2/194: Found 29 new records\n",
      "Page 3/194: Found 69 new records\n",
      "Page 4/194: Found 200 new records\n",
      "Page 5/194: Found 3 new records\n",
      "Page 6/194: Found 1 new records\n",
      "Page 7/194: Found 3 new records\n",
      "Page 8/194: Found 110 new records\n",
      "Page 9/194: Found 8 new records\n",
      "Page 10/194: Found 19 new records\n",
      "Page 11/194: Found 7 new records\n",
      "Page 12/194: Found 31 new records\n",
      "Page 13/194: Found 232 new records\n",
      "Page 14/194: Found 435 new records\n",
      "Page 15/194: Found 142 new records\n",
      "Page 16/194: Found 70 new records\n",
      "Page 17/194: Found 19 new records\n",
      "Page 18/194: Found 28 new records\n",
      "Page 19/194: Found 21 new records\n",
      "Page 20/194: Found 20 new records\n",
      "Page 21/194: Found 46 new records\n",
      "Page 22/194: Found 88 new records\n",
      "Page 23/194: Found 70 new records\n",
      "Page 24/194: Found 252 new records\n",
      "Page 25/194: Found 192 new records\n",
      "Page 26/194: Found 308 new records\n",
      "Page 27/194: Found 2 new records\n",
      "Page 28/194: Found 3 new records\n",
      "Page 29/194: Found 10 new records\n",
      "Page 30/194: Found 201 new records\n",
      "Page 31/194: Found 15 new records\n",
      "Page 32/194: Found 5 new records\n",
      "Page 33/194: Found 6 new records\n",
      "Page 34/194: Found 7 new records\n",
      "Page 35/194: Found 12 new records\n",
      "Page 36/194: Found 60 new records\n",
      "Page 37/194: Found 143 new records\n",
      "Page 38/194: Found 7 new records\n",
      "Page 39/194: Found 10 new records\n",
      "Page 40/194: Found 87 new records\n",
      "Page 41/194: Found 40 new records\n",
      "Page 42/194: Found 74 new records\n",
      "Page 43/194: Found 47 new records\n",
      "Page 44/194: Found 34 new records\n",
      "Page 45/194: Found 82 new records\n",
      "Page 46/194: Found 604 new records\n",
      "Page 47/194: Found 5 new records\n",
      "Page 48/194: Found 5 new records\n",
      "Page 49/194: Found 0 new records\n",
      "Page 50/194: Found 1 new records\n",
      "Page 51/194: Found 12 new records\n",
      "Page 52/194: Found 5 new records\n",
      "Page 53/194: Found 13 new records\n",
      "Page 54/194: Found 13 new records\n",
      "Page 55/194: Found 6 new records\n",
      "Page 56/194: Found 41 new records\n",
      "Page 57/194: Found 60 new records\n",
      "Page 58/194: Found 449 new records\n",
      "Page 59/194: Found 148 new records\n",
      "Page 60/194: Found 7 new records\n",
      "Page 61/194: Found 5 new records\n",
      "Page 62/194: Found 14 new records\n",
      "Page 63/194: Found 5 new records\n",
      "Page 64/194: Found 3 new records\n",
      "Page 65/194: Found 9 new records\n",
      "Page 66/194: Found 18 new records\n",
      "Page 67/194: Found 15 new records\n",
      "Page 68/194: Found 9 new records\n",
      "Page 69/194: Found 42 new records\n",
      "Page 70/194: Found 187 new records\n",
      "Page 71/194: Found 307 new records\n",
      "Page 72/194: Found 781 new records\n",
      "Page 73/194: Found 10 new records\n",
      "Page 74/194: Found 4 new records\n",
      "Page 75/194: Found 172 new records\n",
      "Page 76/194: Found 36 new records\n",
      "Page 77/194: Found 7 new records\n",
      "Page 78/194: Found 189 new records\n",
      "Page 79/194: Found 26 new records\n",
      "Page 80/194: Found 39 new records\n",
      "Page 81/194: Found 180 new records\n",
      "Page 82/194: Found 12 new records\n",
      "Page 83/194: Found 74 new records\n",
      "Page 84/194: Found 130 new records\n",
      "Page 85/194: Found 38 new records\n",
      "Page 86/194: Found 51 new records\n",
      "Page 87/194: Found 38 new records\n",
      "Page 88/194: Found 66 new records\n",
      "Page 89/194: Found 462 new records\n",
      "Page 90/194: Found 9 new records\n",
      "Page 91/194: Found 6 new records\n",
      "Page 92/194: Found 89 new records\n",
      "Page 93/194: Found 3 new records\n",
      "Page 94/194: Found 1 new records\n",
      "Page 95/194: Found 0 new records\n",
      "Page 96/194: Found 0 new records\n",
      "Page 97/194: Found 5 new records\n",
      "Page 98/194: Found 17 new records\n",
      "Page 99/194: Found 33 new records\n",
      "Page 100/194: Found 83 new records\n",
      "Page 101/194: Found 113 new records\n",
      "Page 102/194: Found 702 new records\n",
      "Page 103/194: Found 105 new records\n",
      "Page 104/194: Found 87 new records\n",
      "Page 105/194: Found 14 new records\n",
      "Page 106/194: Found 3 new records\n",
      "Page 107/194: Found 3 new records\n",
      "Page 108/194: Found 1 new records\n",
      "Page 109/194: Found 7 new records\n",
      "Page 110/194: Found 8 new records\n",
      "Page 111/194: Found 6 new records\n",
      "Page 112/194: Found 7 new records\n",
      "Page 113/194: Found 4 new records\n",
      "Page 114/194: Found 10 new records\n",
      "Page 115/194: Found 2 new records\n",
      "Page 116/194: Found 6 new records\n",
      "Page 117/194: Found 15 new records\n",
      "Page 118/194: Found 4 new records\n",
      "Page 119/194: Found 16 new records\n",
      "Page 120/194: Found 19 new records\n",
      "Page 121/194: Found 26 new records\n",
      "Page 122/194: Found 71 new records\n",
      "Page 123/194: Found 114 new records\n",
      "Page 124/194: Found 152 new records\n",
      "Page 125/194: Found 546 new records\n",
      "Page 126/194: Found 373 new records\n",
      "Page 127/194: Found 114 new records\n",
      "Page 128/194: Found 45 new records\n",
      "Page 129/194: Found 20 new records\n",
      "Page 130/194: Found 6 new records\n",
      "Page 131/194: Found 6 new records\n",
      "Page 132/194: Found 2 new records\n",
      "Page 133/194: Found 62 new records\n",
      "Page 134/194: Found 220 new records\n",
      "Page 135/194: Found 68 new records\n",
      "Page 136/194: Found 212 new records\n",
      "Page 137/194: Found 7 new records\n",
      "Page 138/194: Found 8 new records\n",
      "Page 139/194: Found 7 new records\n",
      "Page 140/194: Found 11 new records\n",
      "Page 141/194: Found 11 new records\n",
      "Page 142/194: Found 28 new records\n",
      "Page 143/194: Found 20 new records\n",
      "Page 144/194: Found 40 new records\n",
      "Page 145/194: Found 193 new records\n",
      "Page 146/194: Found 303 new records\n",
      "Page 147/194: Found 628 new records\n",
      "Page 148/194: Found 19 new records\n",
      "Page 149/194: Found 59 new records\n",
      "Page 150/194: Found 122 new records\n",
      "Page 151/194: Found 46 new records\n",
      "Page 152/194: Found 80 new records\n",
      "Page 153/194: Found 21 new records\n",
      "Page 154/194: Found 8 new records\n",
      "Page 155/194: Found 97 new records\n",
      "Page 156/194: Found 34 new records\n",
      "Page 157/194: Found 5 new records\n",
      "Page 158/194: Found 4 new records\n",
      "Page 159/194: Found 11 new records\n",
      "Page 160/194: Found 3 new records\n",
      "Page 161/194: Found 4 new records\n",
      "Page 162/194: Found 0 new records\n",
      "Page 163/194: Found 3 new records\n",
      "Page 164/194: Found 1 new records\n",
      "Page 165/194: Found 4 new records\n",
      "Page 166/194: Found 7 new records\n",
      "Page 167/194: Found 8 new records\n",
      "Page 168/194: Found 7 new records\n",
      "Page 169/194: Found 5 new records\n",
      "Page 170/194: Found 10 new records\n",
      "Page 171/194: Found 46 new records\n",
      "Page 172/194: Found 16 new records\n",
      "Page 173/194: Found 15 new records\n",
      "Page 174/194: Found 48 new records\n",
      "Page 175/194: Found 99 new records\n",
      "Page 176/194: Found 199 new records\n",
      "Page 177/194: Found 119 new records\n",
      "Page 178/194: Found 160 new records\n",
      "Page 179/194: Found 64 new records\n",
      "Page 180/194: Found 92 new records\n",
      "Page 181/194: Found 88 new records\n",
      "Page 182/194: Found 92 new records\n",
      "Page 183/194: Found 47 new records\n",
      "Page 184/194: Found 101 new records\n",
      "Page 185/194: Found 119 new records\n",
      "Page 186/194: Found 133 new records\n",
      "Page 187/194: Found 99 new records\n",
      "Page 188/194: Found 158 new records\n",
      "Page 189/194: Found 280 new records\n",
      "Page 190/194: Found 118 new records\n",
      "Page 191/194: Found 597 new records\n",
      "Page 192/194: Found 1000 new records\n",
      "Page 193/194: Found 387 new records\n",
      "Page 194/194: Found 134 new records\n",
      "\n",
      "Total new records found: 16991\n",
      "Found 16991 new contracts\n",
      "Total contracts after update: 197991\n"
     ]
    }
   ],
   "source": [
    "# Update all contracts\n",
    "all_contracts_file = '../../data/raw/indiana_contracts.json'\n",
    "\n",
    "if CLOBBER:\n",
    "    print(\"CLOBBER mode: Scraping all contracts and overwriting existing file...\")\n",
    "    all_data = scrape_all_contracts(url)\n",
    "    print(f\"Scraped {len(all_data)} total contracts\")\n",
    "    \n",
    "    # Save all data (overwrite)\n",
    "    with open(all_contracts_file, 'w') as write_file:\n",
    "        json.dump(all_data, write_file)\n",
    "        \n",
    "    print(f\"Saved {len(all_data)} contracts (overwrote existing file)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Incremental mode: Scanning for new contracts across all pages...\")\n",
    "    \n",
    "    # Load existing data\n",
    "    existing_data, existing_records = load_existing_contracts(all_contracts_file)\n",
    "    \n",
    "    # Scrape all pages looking for new records\n",
    "    if existing_records:\n",
    "        print(\"Scanning all pages for new contracts...\")\n",
    "        new_records = scrape_all_new_records(url, existing_records)\n",
    "        print(f\"Found {len(new_records)} new contracts\")\n",
    "        \n",
    "        # Combine new and existing data (new records first)\n",
    "        updated_data = new_records + existing_data\n",
    "        \n",
    "        # Save updated data\n",
    "        with open(all_contracts_file, 'w') as write_file:\n",
    "            json.dump(updated_data, write_file)\n",
    "            \n",
    "        print(f\"Total contracts after update: {len(updated_data)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No existing data found. Performing full scrape...\")\n",
    "        all_data = scrape_all_contracts(url)\n",
    "        \n",
    "        # Save all data\n",
    "        with open(all_contracts_file, 'w') as write_file:\n",
    "            json.dump(all_data, write_file)\n",
    "            \n",
    "        print(f\"Saved {len(all_data)} contracts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad2bb240-61d8-464b-a91e-b627e0f33fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incremental mode: Scanning for new professional services contracts across all pages...\n",
      "Successfully loaded 30000 records from ../../data/raw/indiana_prof_services_contracts.json\n",
      "Found 29998 unique records\n",
      "Scanning all pages for new professional services contracts...\n",
      "Total pages to scan: 35\n",
      "Page 1/35: Found 313 new records\n",
      "Page 2/35: Found 88 new records\n",
      "Page 3/35: Found 125 new records\n",
      "Page 4/35: Found 24 new records\n",
      "Page 5/35: Found 18 new records\n",
      "Page 6/35: Found 594 new records\n",
      "Page 7/35: Found 164 new records\n",
      "Page 8/35: Found 408 new records\n",
      "Page 9/35: Found 130 new records\n",
      "Page 10/35: Found 5 new records\n",
      "Page 11/35: Found 194 new records\n",
      "Page 12/35: Found 30 new records\n",
      "Page 13/35: Found 82 new records\n",
      "Page 14/35: Found 54 new records\n",
      "Page 15/35: Found 122 new records\n",
      "Page 16/35: Found 137 new records\n",
      "Page 17/35: Found 72 new records\n",
      "Page 18/35: Found 166 new records\n",
      "Page 19/35: Found 115 new records\n",
      "Page 20/35: Found 46 new records\n",
      "Page 21/35: Found 0 new records\n",
      "Page 22/35: Found 185 new records\n",
      "Page 23/35: Found 175 new records\n",
      "Page 24/35: Found 92 new records\n",
      "Page 25/35: Found 233 new records\n",
      "Page 26/35: Found 124 new records\n",
      "Page 27/35: Found 278 new records\n",
      "Page 28/35: Found 85 new records\n",
      "Page 29/35: Found 142 new records\n",
      "Page 30/35: Found 3 new records\n",
      "Page 31/35: Found 0 new records\n",
      "Page 32/35: Found 0 new records\n",
      "Page 33/35: Found 0 new records\n",
      "Page 34/35: Found 316 new records\n",
      "Page 35/35: Found 37 new records\n",
      "\n",
      "Total new records found: 4557\n",
      "Found 4557 new professional services contracts\n",
      "Total professional services contracts after update: 34557\n"
     ]
    }
   ],
   "source": [
    "# Update professional services contracts\n",
    "prof_services_file = '../../data/raw/indiana_prof_services_contracts.json'\n",
    "\n",
    "# Contract type flags\n",
    "# 128 = professional services\n",
    "contract_type_flags = 128\n",
    "\n",
    "if CLOBBER:\n",
    "    print(\"CLOBBER mode: Scraping all professional services contracts and overwriting existing file...\")\n",
    "    all_data = scrape_all_contracts(url, contract_type_flags=contract_type_flags)\n",
    "    print(f\"Scraped {len(all_data)} total professional services contracts\")\n",
    "    \n",
    "    # Save all data (overwrite)\n",
    "    with open(prof_services_file, 'w') as write_file:\n",
    "        json.dump(all_data, write_file)\n",
    "        \n",
    "    print(f\"Saved {len(all_data)} professional services contracts (overwrote existing file)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Incremental mode: Scanning for new professional services contracts across all pages...\")\n",
    "    \n",
    "    # Load existing data\n",
    "    existing_data, existing_records = load_existing_contracts(prof_services_file)\n",
    "    \n",
    "    # Scrape all pages looking for new records\n",
    "    if existing_records:\n",
    "        print(\"Scanning all pages for new professional services contracts...\")\n",
    "        new_records = scrape_all_new_records(url, existing_records, contract_type_flags=contract_type_flags)\n",
    "        print(f\"Found {len(new_records)} new professional services contracts\")\n",
    "        \n",
    "        # Combine new and existing data (new records first)\n",
    "        updated_data = new_records + existing_data\n",
    "        \n",
    "        # Save updated data\n",
    "        with open(prof_services_file, 'w') as write_file:\n",
    "            json.dump(updated_data, write_file)\n",
    "            \n",
    "        print(f\"Total professional services contracts after update: {len(updated_data)}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No existing data found. Performing full scrape...\")\n",
    "        all_data = scrape_all_contracts(url, contract_type_flags=contract_type_flags)\n",
    "        \n",
    "        # Save all data\n",
    "        with open(prof_services_file, 'w') as write_file:\n",
    "            json.dump(all_data, write_file)\n",
    "            \n",
    "        print(f\"Saved {len(all_data)} professional services contracts\")\n",
    "\n",
    "# Other contract type flags for reference:\n",
    "# 0 = all\n",
    "# 1 = attorney\n",
    "# 4 = grant\n",
    "# 8 = lease\n",
    "# 64 = MOU\n",
    "# 128 = professional services"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
