{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Government Contract Processing - DeepSeek Vision with Simple Prompt\n",
    "\n",
    "This notebook uses DeepSeek Vision-Language Model with your specified prompt:\n",
    "\n",
    "```\n",
    "This image is contract form.\n",
    "Provide a detailed breakdown of the form's information.\n",
    "For elements that are a set of checkboxes, return the name of the checked box as the value.\n",
    "Provide the results as a json file.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"model_name\": \"deepseek-ai/deepseek-vl-7b-chat\",\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"max_tokens\": 2048,\n",
    "    \"temperature\": 0.1,\n",
    "    \"cache_dir\": \"./deepseek_cache\",\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG[\"cache_dir\"], exist_ok=True)\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDeepSeekProcessor:\n",
    "    \"\"\"Simple DeepSeek processor with your specific prompt\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        \n",
    "        # Your exact prompt\n",
    "        self.prompt = \"\"\"This image is contract form.\n",
    "Provide a detailed breakdown of the form's information.\n",
    "For elements that are a set of checkboxes, return the name of the checked box as the value.\n",
    "Provide the results as a json file.\"\"\"\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load DeepSeek model\"\"\"\n",
    "        if self.model is not None:\n",
    "            return\n",
    "            \n",
    "        print(\"Loading DeepSeek Vision model...\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            CONFIG[\"model_name\"],\n",
    "            cache_dir=CONFIG[\"cache_dir\"],\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            CONFIG[\"model_name\"],\n",
    "            cache_dir=CONFIG[\"cache_dir\"],\n",
    "            torch_dtype=torch.float16 if CONFIG[\"device\"] == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\" if CONFIG[\"device\"] == \"cuda\" else None,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        if CONFIG[\"device\"] == \"cpu\":\n",
    "            self.model = self.model.to(CONFIG[\"device\"])\n",
    "        \n",
    "        self.model.eval()\n",
    "        print(\"‚úì Model loaded successfully\")\n",
    "    \n",
    "    def prepare_image(self, image: Image.Image) -> str:\n",
    "        \"\"\"Convert image to base64\"\"\"\n",
    "        # Resize if too large\n",
    "        max_size = 1024\n",
    "        if max(image.size) > max_size:\n",
    "            ratio = max_size / max(image.size)\n",
    "            new_size = tuple(int(dim * ratio) for dim in image.size)\n",
    "            image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        return base64.b64encode(buffered.getvalue()).decode()\n",
    "    \n",
    "    def process_image(self, image: Image.Image) -> Dict:\n",
    "        \"\"\"Process single image with DeepSeek\"\"\"\n",
    "        try:\n",
    "            # Prepare image\n",
    "            image_b64 = self.prepare_image(image)\n",
    "            \n",
    "            # Create conversation\n",
    "            conversation = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": self.prompt},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/png;base64,{image_b64}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }]\n",
    "            \n",
    "            # Generate\n",
    "            inputs = self.tokenizer.apply_chat_template(\n",
    "                conversation,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(CONFIG[\"device\"])\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs,\n",
    "                    max_new_tokens=CONFIG[\"max_tokens\"],\n",
    "                    temperature=CONFIG[\"temperature\"],\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            response = self.tokenizer.decode(\n",
    "                outputs[0][inputs.shape[1]:],\n",
    "                skip_special_tokens=True\n",
    "            ).strip()\n",
    "            \n",
    "            return self.parse_response(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e), \"raw_response\": \"\"}\n",
    "    \n",
    "    def parse_response(self, response: str) -> Dict:\n",
    "        \"\"\"Parse JSON from model response\"\"\"\n",
    "        try:\n",
    "            # Try to find JSON in response\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                return json.loads(json_match.group(0))\n",
    "            return json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            return {\"raw_response\": response, \"parse_error\": \"Could not parse JSON\"}\n",
    "    \n",
    "    def process_document(self, file_path: str) -> Dict:\n",
    "        \"\"\"Process document (PDF or image)\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        result = {\n",
    "            \"filename\": os.path.basename(file_path),\n",
    "            \"status\": \"processing\",\n",
    "            \"processing_time\": 0,\n",
    "            \"extracted_data\": {},\n",
    "            \"raw_response\": \"\",\n",
    "            \"error\": None\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Load model if needed\n",
    "            if self.model is None:\n",
    "                self.load_model()\n",
    "            \n",
    "            # Load image(s)\n",
    "            if file_path.lower().endswith('.pdf'):\n",
    "                images = pdf2image.convert_from_path(file_path, dpi=300, first_page=1, last_page=3)\n",
    "            else:\n",
    "                images = [Image.open(file_path)]\n",
    "            \n",
    "            if not images:\n",
    "                raise ValueError(\"No images found\")\n",
    "            \n",
    "            # Process first page (can extend to multiple pages)\n",
    "            print(f\"Processing {result['filename']}...\")\n",
    "            extracted = self.process_image(images[0])\n",
    "            \n",
    "            result.update({\n",
    "                \"status\": \"success\",\n",
    "                \"processing_time\": time.time() - start_time,\n",
    "                \"extracted_data\": extracted,\n",
    "                \"raw_response\": extracted.get(\"raw_response\", \"\")\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            result.update({\n",
    "                \"status\": \"failed\",\n",
    "                \"error\": str(e),\n",
    "                \"processing_time\": time.time() - start_time\n",
    "            })\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize processor\n",
    "processor = SimpleDeepSeekProcessor()\n",
    "print(\"‚úì SimpleDeepSeekProcessor initialized\")\n",
    "print(f\"üìù Prompt: {processor.prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on single document\n",
    "def test_document(file_path: str):\n",
    "    \"\"\"Test processing on single document\"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ùå File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üîÑ Testing DeepSeek on: {file_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    result = processor.process_document(file_path)\n",
    "    \n",
    "    print(f\"Status: {result['status']}\")\n",
    "    print(f\"Processing time: {result['processing_time']:.2f}s\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(\"\\nüìã Extracted Data:\")\n",
    "        if 'parse_error' in result['extracted_data']:\n",
    "            print(\"‚ö†Ô∏è JSON parsing failed\")\n",
    "            print(f\"Raw response: {result['extracted_data']['raw_response'][:300]}...\")\n",
    "        else:\n",
    "            print(json.dumps(result['extracted_data'], indent=2))\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {result['error']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test file path\n",
    "sample_file = \"../../data/raw/_exampleforms/83501-000.pdf\"\n",
    "\n",
    "print(\"üí° Ready to test!\")\n",
    "print(\"Uncomment the line below to test:\")\n",
    "print(\"# test_result = test_document(sample_file)\")\n",
    "\n",
    "# Uncomment to test:\n",
    "# test_result = test_document(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing\n",
    "def process_directory(input_dir: str) -> pd.DataFrame:\n",
    "    \"\"\"Process all documents in directory\"\"\"\n",
    "    \n",
    "    # Find files\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg')):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(f\"‚ùå No files found in {input_dir}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"üìÅ Found {len(file_paths)} files\")\n",
    "    print(f\"‚è±Ô∏è Estimated time: {len(file_paths) * 2:.0f} minutes\")\n",
    "    \n",
    "    # Process files\n",
    "    results = []\n",
    "    \n",
    "    for file_path in tqdm(file_paths, desc=\"Processing contracts\"):\n",
    "        result = processor.process_document(file_path)\n",
    "        results.append(result)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Summary\n",
    "    successful = (df['status'] == 'success').sum()\n",
    "    print(f\"\\nüìä Results: {successful}/{len(df)} successful ({successful/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Directory to process\n",
    "INPUT_DIR = \"../../data/raw/_exampleforms\"\n",
    "\n",
    "print(f\"Ready to process directory: {INPUT_DIR}\")\n",
    "print(\"Uncomment to start batch processing:\")\n",
    "print(\"# df_results = process_directory(INPUT_DIR)\")\n",
    "\n",
    "# Uncomment to process:\n",
    "# df_results = process_directory(INPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "def export_results(df: pd.DataFrame, output_dir: str = \"./results\"):\n",
    "    \"\"\"Export results to files\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No results to export\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Export to CSV\n",
    "    csv_path = os.path.join(output_dir, \"deepseek_simple_results.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"‚úì Exported to CSV: {csv_path}\")\n",
    "    \n",
    "    # Export extracted data as separate JSON files\n",
    "    json_dir = os.path.join(output_dir, \"extracted_json\")\n",
    "    os.makedirs(json_dir, exist_ok=True)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if row['status'] == 'success' and 'parse_error' not in row['extracted_data']:\n",
    "            filename = os.path.splitext(row['filename'])[0] + '.json'\n",
    "            json_path = os.path.join(json_dir, filename)\n",
    "            \n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(row['extracted_data'], f, indent=2)\n",
    "    \n",
    "    print(f\"‚úì Exported JSON files to: {json_dir}\")\n",
    "    \n",
    "    # Summary report\n",
    "    successful = df[df['status'] == 'success']\n",
    "    avg_time = successful['processing_time'].mean() if not successful.empty else 0\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"summary.txt\"), 'w') as f:\n",
    "        f.write(f\"DeepSeek Simple Processing Summary\\n\")\n",
    "        f.write(f\"Total files: {len(df)}\\n\")\n",
    "        f.write(f\"Successful: {len(successful)}\\n\")\n",
    "        f.write(f\"Success rate: {len(successful)/len(df)*100:.1f}%\\n\")\n",
    "        f.write(f\"Average time: {avg_time:.1f}s\\n\")\n",
    "        f.write(f\"\\nPrompt used:\\n{processor.prompt}\\n\")\n",
    "    \n",
    "    print(f\"‚úì Summary saved to: {os.path.join(output_dir, 'summary.txt')}\")\n",
    "\n",
    "print(\"üìÅ Export functions ready\")\n",
    "print(\"Use: export_results(df_results) after processing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}