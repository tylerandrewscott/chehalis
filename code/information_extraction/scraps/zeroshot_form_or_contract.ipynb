{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8178717-d0ad-4a83-818a-a1e4b24dabb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 193450 PDF files to process\n"
     ]
    }
   ],
   "source": [
    "# Set environment variable to avoid tokenizer warnings\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for PDF handling\n",
    "from pdf2image import convert_from_path\n",
    "import shutil\n",
    "\n",
    "# Initialize the zero-shot classifier (for initial exploration)\n",
    "checkpoint = \"openai/clip-vit-large-patch14\"\n",
    "detector = pipeline(model=checkpoint, task=\"zero-shot-image-classification\")\n",
    "\n",
    "# Paths\n",
    "pdf_dir = \"../../data/raw/_contracts/\"\n",
    "formpage_dir = \"../../data/raw/_formpage/\"\n",
    "\n",
    "# Create formpage directory if it doesn't exist\n",
    "os.makedirs(formpage_dir, exist_ok=True)\n",
    "\n",
    "# Get list of PDF files\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith('.pdf')]\n",
    "\n",
    "print(f\"Found {len(pdf_files)} PDF files to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "jrwcybsa3eh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP for visual form detection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on mps!\n",
      "\n",
      "Loading 32 example forms from ../../data/raw/_exampleforms/...\n",
      "  Loaded: 25581-000.pdf\n",
      "  Loaded: 99171-000.pdf\n",
      "  Loaded: 13924-002.pdf\n",
      "  Loaded: 1197-000.pdf\n",
      "  Loaded: 67419-000.pdf\n",
      "  Loaded: H286-20-001-000.pdf\n",
      "  Loaded: F1-10-FSSA-DDRS-495-000.pdf\n",
      "  Loaded: SCM63182-001.pdf\n",
      "  Loaded: 87458-000.pdf\n",
      "  Loaded: 87552-000.pdf\n",
      "  Loaded: 83501-000.pdf\n",
      "  Loaded: SCM63182-002.pdf\n",
      "  Loaded: 3341-000.pdf\n",
      "  Loaded: 83844-000.pdf\n",
      "  Loaded: 88087-000.pdf\n",
      "  Loaded: 83502-000.pdf\n",
      "  Loaded: 83987-000.pdf\n",
      "  Loaded: 9697-000.pdf\n",
      "  Loaded: PCI-12-3045-001.pdf\n",
      "  Loaded: F1-9-FSSA-DMHA-569-000.pdf\n",
      "  Loaded: 3328-000.pdf\n",
      "  Loaded: PCI-19-2041-001.pdf\n",
      "  Loaded: 9693-000.pdf\n",
      "  Loaded: 3370-000.pdf\n",
      "  Loaded: F1-9-FSSADFR-402-000.pdf\n",
      "  Loaded: 83796-000.pdf\n",
      "  Loaded: 85211-000.pdf\n",
      "  Loaded: 9699-000.pdf\n",
      "  Loaded: H28-4-12-001.pdf\n",
      "  Loaded: 9691-001.pdf\n",
      "  Loaded: 85212-000.pdf\n",
      "  Loaded: 87462-001.pdf\n",
      "Successfully loaded 32 example forms\n"
     ]
    }
   ],
   "source": [
    "# Use latest CLIP for pure visual form detection\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load latest CLIP model for visual feature extraction\n",
    "print(\"Loading CLIP for visual form detection...\")\n",
    "# Using the larger, more recent CLIP model\n",
    "model_name = \"openai/clip-vit-large-patch14-336\"  # Higher resolution variant\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "clip_model = clip_model.to(device)\n",
    "clip_model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully on {device}!\")\n",
    "\n",
    "# Path to example forms\n",
    "example_forms_dir = \"../../data/raw/_exampleforms/\"\n",
    "\n",
    "# Load example forms (positive examples)\n",
    "example_features = []\n",
    "example_form_paths = []\n",
    "\n",
    "if os.path.exists(example_forms_dir):\n",
    "    example_files = [f for f in os.listdir(example_forms_dir) if f.endswith(('.jpg', '.jpeg', '.png', '.pdf'))]\n",
    "    \n",
    "    print(f\"\\nLoading {len(example_files)} example forms from {example_forms_dir}...\")\n",
    "    \n",
    "    for example_file in example_files:\n",
    "        example_path = os.path.join(example_forms_dir, example_file)\n",
    "        \n",
    "        try:\n",
    "            if example_file.endswith('.pdf'):\n",
    "                pdf = fitz.open(example_path)\n",
    "                page = pdf[0]  # First page only\n",
    "                pix = page.get_pixmap()\n",
    "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "                pdf.close()\n",
    "            else:\n",
    "                img = Image.open(example_path)\n",
    "            \n",
    "            # Extract visual features using CLIP\n",
    "            inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = clip_model.get_image_features(**inputs)\n",
    "                features = features.cpu().numpy()\n",
    "                # Normalize features for better similarity comparison\n",
    "                features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "                example_features.append(features)\n",
    "            \n",
    "            example_form_paths.append(example_file)\n",
    "            print(f\"  Loaded: {example_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {example_file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(example_features)} example forms\")\n",
    "else:\n",
    "    print(f\"No example forms found at {example_forms_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "h88vft41t6k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading negative examples from ../../data/raw/_nonexamples/...\n",
      "  Loaded: 25581-000.pdf (25 pages)\n",
      "  Loaded: 0000000000000000000062223-001.pdf (5 pages)\n",
      "  Loaded: 1197-000.pdf (15 pages)\n",
      "  Loaded: 67419-000.pdf (26 pages)\n",
      "  Loaded: 104473-000.pdf (42 pages)\n",
      "  Loaded: 104303-001.pdf (3 pages)\n",
      "  Loaded: 104324-000.pdf (15 pages)\n",
      "  Loaded: 104324-002.pdf (6 pages)\n",
      "  Loaded: 104468-000.pdf (45 pages)\n",
      "  Loaded: 104428-000.pdf (15 pages)\n",
      "  Loaded: 104306-000.pdf (40 pages)\n",
      "\n",
      "Total features loaded:\n",
      "  Positive examples (forms): 32\n",
      "  Negative examples (non-forms): 237\n"
     ]
    }
   ],
   "source": [
    "# Load negative examples (non-forms) - ALL PAGES\n",
    "nonexample_forms_dir = \"../../data/raw/_nonexamples/\"\n",
    "\n",
    "nonexample_features = []\n",
    "nonexample_paths = []\n",
    "\n",
    "if os.path.exists(nonexample_forms_dir):\n",
    "    nonexample_files = [f for f in os.listdir(nonexample_forms_dir) if f.endswith(('.jpg', '.jpeg', '.png', '.pdf'))]\n",
    "    \n",
    "    print(f\"\\nLoading negative examples from {nonexample_forms_dir}...\")\n",
    "    \n",
    "    for nonexample_file in nonexample_files:\n",
    "        nonexample_path = os.path.join(nonexample_forms_dir, nonexample_file)\n",
    "        \n",
    "        try:\n",
    "            if nonexample_file.endswith('.pdf'):\n",
    "                pdf = fitz.open(nonexample_path)\n",
    "                pages_loaded = 0\n",
    "                \n",
    "                # Load ALL pages from non-examples\n",
    "                for page_num in range(len(pdf)):\n",
    "                    page = pdf[page_num]\n",
    "                    pix = page.get_pixmap()\n",
    "                    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "                    \n",
    "                    # Extract visual features using CLIP\n",
    "                    inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        features = clip_model.get_image_features(**inputs)\n",
    "                        features = features.cpu().numpy()\n",
    "                        # Normalize features\n",
    "                        features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "                        nonexample_features.append(features)\n",
    "                    \n",
    "                    pages_loaded += 1\n",
    "                \n",
    "                pdf.close()\n",
    "                print(f\"  Loaded: {nonexample_file} ({pages_loaded} pages)\")\n",
    "                \n",
    "            else:\n",
    "                img = Image.open(nonexample_path)\n",
    "                \n",
    "                inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    features = clip_model.get_image_features(**inputs)\n",
    "                    features = features.cpu().numpy()\n",
    "                    # Normalize features\n",
    "                    features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "                    nonexample_features.append(features)\n",
    "                \n",
    "                print(f\"  Loaded: {nonexample_file}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {nonexample_file}: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\nTotal features loaded:\")\n",
    "    print(f\"  Positive examples (forms): {len(example_features)}\")\n",
    "    print(f\"  Negative examples (non-forms): {len(nonexample_features)}\")\n",
    "else:\n",
    "    print(f\"No negative examples found at {nonexample_forms_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "kv8f8y0kh6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using all 237 negative examples for comprehensive filtering\n"
     ]
    }
   ],
   "source": [
    "# Using all negative examples without balancing\n",
    "# More negative examples = better filtering of false positives\n",
    "print(f\"\\nUsing all {len(nonexample_features)} negative examples for comprehensive filtering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9qqbxu2j8dl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visual form detection function using CLIP\n",
    "def detect_form_visual_clip(image, clip_model, clip_processor, device,\n",
    "                           positive_features=None, negative_features=None,\n",
    "                           similarity_threshold=0.7, negative_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Pure visual form detection using CLIP features\n",
    "    No text detection or OCR - just visual similarity\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'is_form': False,\n",
    "        'confidence': 0,\n",
    "        'max_positive_similarity': 0,\n",
    "        'max_negative_similarity': 0,\n",
    "        'positive_similarities': [],\n",
    "        'negative_similarities': []\n",
    "    }\n",
    "    \n",
    "    # Extract visual features from current image\n",
    "    try:\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = clip_model.get_image_features(**inputs)\n",
    "            features = features.cpu().numpy()\n",
    "            # Normalize features\n",
    "            features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {e}\")\n",
    "        return result\n",
    "    \n",
    "    # Check similarity to positive examples\n",
    "    if positive_features:\n",
    "        for pos_feat in positive_features:\n",
    "            sim = cosine_similarity(features, pos_feat)[0][0]\n",
    "            result['positive_similarities'].append(sim)\n",
    "        \n",
    "        result['max_positive_similarity'] = max(result['positive_similarities'])\n",
    "        is_like_positive = result['max_positive_similarity'] > similarity_threshold\n",
    "    else:\n",
    "        is_like_positive = False\n",
    "    \n",
    "    # Check similarity to negative examples\n",
    "    if negative_features:\n",
    "        for neg_feat in negative_features:\n",
    "            sim = cosine_similarity(features, neg_feat)[0][0]\n",
    "            result['negative_similarities'].append(sim)\n",
    "        \n",
    "        result['max_negative_similarity'] = max(result['negative_similarities'])\n",
    "        is_not_like_negative = result['max_negative_similarity'] < negative_threshold\n",
    "    else:\n",
    "        is_not_like_negative = True\n",
    "    \n",
    "    # Decision: must be like positive AND not like negative\n",
    "    result['is_form'] = is_like_positive and is_not_like_negative\n",
    "    \n",
    "    # Confidence score\n",
    "    if result['is_form']:\n",
    "        # High positive similarity, low negative similarity\n",
    "        result['confidence'] = result['max_positive_similarity'] * (1 - result['max_negative_similarity'] * 0.5)\n",
    "    else:\n",
    "        result['confidence'] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1fd44yff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_form_with_negatives(image, detector, model, processor, \n",
    "                              positive_features=None, negative_features=None,\n",
    "                              similarity_threshold=0.7, negative_threshold=0.7,\n",
    "                              logic_mode='AND'):\n",
    "    \"\"\"\n",
    "    Advanced form detection using positive and negative examples\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image to analyze\n",
    "        detector: Zero-shot classifier pipeline\n",
    "        model: CLIP model for feature extraction\n",
    "        processor: CLIP processor\n",
    "        positive_features: List of feature vectors from example forms\n",
    "        negative_features: List of feature vectors from non-form examples\n",
    "        similarity_threshold: Min similarity to positive examples\n",
    "        negative_threshold: Max allowed similarity to negative examples\n",
    "        logic_mode: 'AND' or 'OR' for combining conditions\n",
    "    \n",
    "    Returns:\n",
    "        dict with detection results\n",
    "    \"\"\"\n",
    "    # Zero-shot classification\n",
    "    predictions = detector(image, candidate_labels=[\n",
    "        \"Standardized contract document\",\n",
    "        \"Other document\"\n",
    "    ])\n",
    "    \n",
    "    form_score = next(p['score'] for p in predictions if 'form' in p['label'])\n",
    "    prose_score = next(p['score'] for p in predictions if 'prose' in p['label'])\n",
    "    \n",
    "    result = {\n",
    "        'form_score': form_score,\n",
    "        'prose_score': prose_score,\n",
    "        'is_form_zeroshot': form_score > prose_score,\n",
    "        'positive_similarities': [],\n",
    "        'negative_similarities': [],\n",
    "        'max_positive_similarity': 0,\n",
    "        'max_negative_similarity': 0,\n",
    "        'is_form_positive': False,\n",
    "        'is_not_like_negative': True,\n",
    "        'logic_mode': logic_mode\n",
    "    }\n",
    "    \n",
    "    # Extract features from current image if we have examples\n",
    "    if positive_features or negative_features:\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "            image_features = image_features.cpu().numpy()\n",
    "    \n",
    "    # Check similarity to positive examples\n",
    "    if positive_features:\n",
    "        for pos_feat in positive_features:\n",
    "            similarity = cosine_similarity(image_features, pos_feat)[0][0]\n",
    "            result['positive_similarities'].append(similarity)\n",
    "        \n",
    "        result['max_positive_similarity'] = max(result['positive_similarities'])\n",
    "        result['is_form_positive'] = result['max_positive_similarity'] > similarity_threshold\n",
    "    \n",
    "    # Check similarity to negative examples\n",
    "    if negative_features:\n",
    "        for neg_feat in negative_features:\n",
    "            similarity = cosine_similarity(image_features, neg_feat)[0][0]\n",
    "            result['negative_similarities'].append(similarity)\n",
    "        \n",
    "        result['max_negative_similarity'] = max(result['negative_similarities'])\n",
    "        # If too similar to a non-form, it's probably not a form\n",
    "        result['is_not_like_negative'] = result['max_negative_similarity'] < negative_threshold\n",
    "    \n",
    "    # Combined decision logic\n",
    "    if positive_features and negative_features:\n",
    "        # Full contrastive learning: must be like positive AND not like negative\n",
    "        if logic_mode == 'AND':\n",
    "            result['is_form'] = (result['is_form_zeroshot'] and \n",
    "                               result['is_form_positive'] and \n",
    "                               result['is_not_like_negative'])\n",
    "        else:  # OR logic\n",
    "            result['is_form'] = ((result['is_form_zeroshot'] or result['is_form_positive']) \n",
    "                               and result['is_not_like_negative'])\n",
    "        \n",
    "        # Confidence considers all factors\n",
    "        # Higher when similar to positive, lower when similar to negative\n",
    "        positive_contrib = result['max_positive_similarity'] if positive_features else form_score\n",
    "        negative_penalty = result['max_negative_similarity'] if negative_features else 0\n",
    "        result['confidence'] = positive_contrib * (1 - negative_penalty * 0.5)\n",
    "        \n",
    "    elif positive_features:\n",
    "        # Only positive examples\n",
    "        if logic_mode == 'AND':\n",
    "            result['is_form'] = result['is_form_zeroshot'] and result['is_form_positive']\n",
    "        else:\n",
    "            result['is_form'] = result['is_form_zeroshot'] or result['is_form_positive']\n",
    "        result['confidence'] = min(form_score, result['max_positive_similarity'])\n",
    "        \n",
    "    elif negative_features:\n",
    "        # Only negative examples\n",
    "        result['is_form'] = result['is_form_zeroshot'] and result['is_not_like_negative']\n",
    "        result['confidence'] = form_score * (1 - result['max_negative_similarity'] * 0.5)\n",
    "        \n",
    "    else:\n",
    "        # No examples at all\n",
    "        result['is_form'] = result['is_form_zeroshot']\n",
    "        result['confidence'] = form_score\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbra1zif4gj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing with CLIP visual detection:\n",
      "  Positive examples: 32\n",
      "  Negative examples: 237\n",
      "  Similarity threshold: 0.7\n",
      "  Negative threshold: 0.7\n",
      "--------------------------------------------------\n",
      "✗ 25581-000.pdf: No form pages found\n",
      "✗ 99171-000.pdf: No form pages found\n",
      "✗ 13924-002.pdf: No form pages found\n",
      "✗ 0000000000000000000062223-001.pdf: No form pages found\n",
      "✗ 0000000000000000000057475-003.pdf: No form pages found\n",
      "✗ 0000000000000000000061824-000.pdf: No form pages found\n",
      "✗ 1197-000.pdf: No form pages found\n",
      "✗ 67419-000.pdf: No form pages found\n",
      "✗ 0000000000000000000058079-000.pdf: No form pages found\n",
      "✗ 104473-000.pdf: No form pages found\n",
      "\n",
      "--------------------------------------------------\n",
      "CLIP Visual Detection Summary:\n",
      "Total PDFs: 10\n",
      "PDFs with forms: 0\n",
      "\n",
      "Results saved to ../../data/intermediate_products/zeroshot_form_contract_clip.csv\n"
     ]
    }
   ],
   "source": [
    "# Process PDFs with CLIP visual detection\n",
    "results_contrastive = []\n",
    "\n",
    "# Set thresholds\n",
    "SIMILARITY_THRESHOLD = 0.7  # Min similarity to positive examples\n",
    "NEGATIVE_THRESHOLD = 0.7    # Max similarity to negative examples\n",
    "CONFIDENCE_THRESHOLD = 0.90 # Stop early threshold\n",
    "\n",
    "print(f\"\\nProcessing with CLIP visual detection:\")\n",
    "print(f\"  Positive examples: {len(example_features)}\")\n",
    "print(f\"  Negative examples: {len(nonexample_features)}\")\n",
    "print(f\"  Similarity threshold: {SIMILARITY_THRESHOLD}\")\n",
    "print(f\"  Negative threshold: {NEGATIVE_THRESHOLD}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for pdf_file in pdf_files[:10]:  # Test with first 10\n",
    "    try:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        best_form_page = None\n",
    "        best_confidence = 0\n",
    "        best_details = None\n",
    "        \n",
    "        # Check each page\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            # Convert page to image\n",
    "            page = pdf_document[page_num]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # CLIP visual detection\n",
    "            detection = detect_form_visual_clip(\n",
    "                img, clip_model, clip_processor, device,\n",
    "                example_features if example_features else None,\n",
    "                nonexample_features if nonexample_features else None,\n",
    "                SIMILARITY_THRESHOLD, NEGATIVE_THRESHOLD\n",
    "            )\n",
    "            \n",
    "            # If this is a form and has higher confidence than current best\n",
    "            if detection['is_form'] and detection['confidence'] > best_confidence:\n",
    "                best_confidence = detection['confidence']\n",
    "                best_form_page = page_num\n",
    "                best_details = detection\n",
    "                \n",
    "                # Stop early if confidence is very high\n",
    "                if best_confidence > CONFIDENCE_THRESHOLD:\n",
    "                    break\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'file': pdf_file,\n",
    "            'total_pages': len(pdf_document),\n",
    "            'has_form': best_form_page is not None,\n",
    "            'best_form_page': best_form_page + 1 if best_form_page is not None else None,\n",
    "            'best_form_confidence': best_confidence\n",
    "        }\n",
    "        \n",
    "        if best_details:\n",
    "            result['max_positive_sim'] = best_details.get('max_positive_similarity', 0)\n",
    "            result['max_negative_sim'] = best_details.get('max_negative_similarity', 0)\n",
    "        \n",
    "        results_contrastive.append(result)\n",
    "        \n",
    "        # Extract best form page if found\n",
    "        if best_form_page is not None:\n",
    "            # Create a new PDF with just the best form page\n",
    "            output_pdf = fitz.open()\n",
    "            output_pdf.insert_pdf(pdf_document, from_page=best_form_page, to_page=best_form_page)\n",
    "            \n",
    "            # Save to formpage directory\n",
    "            output_path = os.path.join(formpage_dir, pdf_file)\n",
    "            output_pdf.save(output_path)\n",
    "            output_pdf.close()\n",
    "            \n",
    "            print(f\"✓ {pdf_file}: Form on page {best_form_page + 1}\")\n",
    "            print(f\"    Confidence: {best_confidence:.3f}\")\n",
    "            if best_details:\n",
    "                print(f\"    Positive similarity: {best_details.get('max_positive_similarity', 0):.3f}\")\n",
    "                print(f\"    Negative similarity: {best_details.get('max_negative_similarity', 0):.3f}\")\n",
    "        else:\n",
    "            print(f\"✗ {pdf_file}: No form pages found\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {str(e)}\")\n",
    "        results_contrastive.append({\n",
    "            'file': pdf_file,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "results_contrastive_df = pd.DataFrame(results_contrastive)\n",
    "print(\"\\n\" + \"-\" * 50)\n",
    "print(f\"CLIP Visual Detection Summary:\")\n",
    "print(f\"Total PDFs: {len(results_contrastive_df)}\")\n",
    "print(f\"PDFs with forms: {results_contrastive_df['has_form'].sum()}\")\n",
    "\n",
    "# Save results\n",
    "results_contrastive_df.to_csv('../../data/intermediate_products/zeroshot_form_contract_clip.csv', index=False)\n",
    "print(f\"\\nResults saved to ../../data/intermediate_products/zeroshot_form_contract_clip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "tsnvs0whufi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXAMPLE SELECTION HELPER ===\n",
      "\n",
      "Analyzing detection patterns to identify gaps...\n",
      "--------------------------------------------------\n",
      "Processing 0/30...\n",
      "Processing 10/30...\n",
      "Processing 20/30...\n",
      "\n",
      "Analyzed 540 pages from 30 PDFs\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Diagnostic Analysis - Identify what examples would help most\n",
    "print(\"=== EXAMPLE SELECTION HELPER ===\\n\")\n",
    "\n",
    "# First, let's analyze the detection patterns\n",
    "diagnostic_results = []\n",
    "\n",
    "print(\"Analyzing detection patterns to identify gaps...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Sample more files for better diagnosis\n",
    "sample_size = min(30, len(pdf_files))  # Analyze up to 30 files\n",
    "sample_files = pdf_files[:sample_size]\n",
    "\n",
    "for i, pdf_file in enumerate(sample_files):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processing {i}/{sample_size}...\")\n",
    "    \n",
    "    try:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        # Analyze each page\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # Get detection results\n",
    "            detection = detect_form_with_negatives(\n",
    "                img, detector, model, processor,\n",
    "                example_features if example_features else None,\n",
    "                nonexample_features if nonexample_features else None,\n",
    "                SIMILARITY_THRESHOLD, NEGATIVE_THRESHOLD,\n",
    "                'AND'\n",
    "            )\n",
    "            \n",
    "            # Store diagnostic info\n",
    "            diag = {\n",
    "                'file': pdf_file,\n",
    "                'page': page_num + 1,\n",
    "                'form_score': detection['form_score'],\n",
    "                'prose_score': detection['prose_score'],\n",
    "                'max_positive_sim': detection.get('max_positive_similarity', 0),\n",
    "                'max_negative_sim': detection.get('max_negative_similarity', 0),\n",
    "                'is_form_zeroshot': detection['is_form_zeroshot'],\n",
    "                'is_form_positive': detection.get('is_form_positive', False),\n",
    "                'is_not_like_negative': detection.get('is_not_like_negative', True),\n",
    "                'final_decision': detection['is_form'],\n",
    "                'confidence': detection['confidence']\n",
    "            }\n",
    "            diagnostic_results.append(diag)\n",
    "        \n",
    "        pdf_document.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {str(e)}\")\n",
    "\n",
    "# Convert to DataFrame for analysis\n",
    "diag_df = pd.DataFrame(diagnostic_results)\n",
    "\n",
    "print(f\"\\nAnalyzed {len(diag_df)} pages from {sample_size} PDFs\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8dee6d8-20ce-4c59-90c6-0acbc499c743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>page</th>\n",
       "      <th>form_score</th>\n",
       "      <th>prose_score</th>\n",
       "      <th>max_positive_sim</th>\n",
       "      <th>max_negative_sim</th>\n",
       "      <th>is_form_zeroshot</th>\n",
       "      <th>is_form_positive</th>\n",
       "      <th>is_not_like_negative</th>\n",
       "      <th>final_decision</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.985007</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>0.935717</td>\n",
       "      <td>0.597216</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.656304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>2</td>\n",
       "      <td>0.208603</td>\n",
       "      <td>0.791397</td>\n",
       "      <td>0.604241</td>\n",
       "      <td>0.574646</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>3</td>\n",
       "      <td>0.171370</td>\n",
       "      <td>0.828630</td>\n",
       "      <td>0.760405</td>\n",
       "      <td>0.730141</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.482803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>4</td>\n",
       "      <td>0.065456</td>\n",
       "      <td>0.934544</td>\n",
       "      <td>0.759050</td>\n",
       "      <td>0.736878</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.479387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25581-000.pdf</td>\n",
       "      <td>5</td>\n",
       "      <td>0.071361</td>\n",
       "      <td>0.928639</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.702655</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.456307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>23954-000.pdf</td>\n",
       "      <td>13</td>\n",
       "      <td>0.187815</td>\n",
       "      <td>0.812185</td>\n",
       "      <td>0.690877</td>\n",
       "      <td>0.774992</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.423165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>23954-000.pdf</td>\n",
       "      <td>14</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.998074</td>\n",
       "      <td>0.677222</td>\n",
       "      <td>0.771712</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.415912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>23954-000.pdf</td>\n",
       "      <td>15</td>\n",
       "      <td>0.137368</td>\n",
       "      <td>0.862632</td>\n",
       "      <td>0.593657</td>\n",
       "      <td>0.712278</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.382233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>23954-000.pdf</td>\n",
       "      <td>16</td>\n",
       "      <td>0.103761</td>\n",
       "      <td>0.896239</td>\n",
       "      <td>0.720409</td>\n",
       "      <td>0.832327</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>23954-000.pdf</td>\n",
       "      <td>17</td>\n",
       "      <td>0.579978</td>\n",
       "      <td>0.420022</td>\n",
       "      <td>0.751986</td>\n",
       "      <td>0.808182</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.448115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file  page  form_score  prose_score  max_positive_sim  \\\n",
       "0    25581-000.pdf     1    0.985007     0.014993          0.935717   \n",
       "1    25581-000.pdf     2    0.208603     0.791397          0.604241   \n",
       "2    25581-000.pdf     3    0.171370     0.828630          0.760405   \n",
       "3    25581-000.pdf     4    0.065456     0.934544          0.759050   \n",
       "4    25581-000.pdf     5    0.071361     0.928639          0.703448   \n",
       "..             ...   ...         ...          ...               ...   \n",
       "535  23954-000.pdf    13    0.187815     0.812185          0.690877   \n",
       "536  23954-000.pdf    14    0.001926     0.998074          0.677222   \n",
       "537  23954-000.pdf    15    0.137368     0.862632          0.593657   \n",
       "538  23954-000.pdf    16    0.103761     0.896239          0.720409   \n",
       "539  23954-000.pdf    17    0.579978     0.420022          0.751986   \n",
       "\n",
       "     max_negative_sim  is_form_zeroshot  is_form_positive  \\\n",
       "0            0.597216              True              True   \n",
       "1            0.574646             False             False   \n",
       "2            0.730141             False              True   \n",
       "3            0.736878             False              True   \n",
       "4            0.702655             False              True   \n",
       "..                ...               ...               ...   \n",
       "535          0.774992             False             False   \n",
       "536          0.771712             False             False   \n",
       "537          0.712278             False             False   \n",
       "538          0.832327             False              True   \n",
       "539          0.808182              True              True   \n",
       "\n",
       "     is_not_like_negative  final_decision  confidence  \n",
       "0                    True            True    0.656304  \n",
       "1                    True           False    0.430628  \n",
       "2                   False           False    0.482803  \n",
       "3                   False           False    0.479387  \n",
       "4                   False           False    0.456307  \n",
       "..                    ...             ...         ...  \n",
       "535                 False           False    0.423165  \n",
       "536                 False           False    0.415912  \n",
       "537                 False           False    0.382233  \n",
       "538                 False           False    0.420601  \n",
       "539                 False           False    0.448115  \n",
       "\n",
       "[540 rows x 11 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "i79us4rawjc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DETECTION PATTERN ANALYSIS ===\n",
      "\n",
      "1. POTENTIAL MISSED FORMS (Zero-shot detected but no example match):\n",
      "   Found 79 pages\n",
      "   Average similarity to examples: 0.614\n",
      "   These pages have form-like structure but don't match your examples\n",
      "\n",
      "   Top candidates to add as examples:\n",
      "   - 104473-000.pdf, page 34 (form_score: 1.000, similarity: 0.621)\n",
      "   - 104473-000.pdf, page 38 (form_score: 1.000, similarity: 0.625)\n",
      "   - 104473-000.pdf, page 20 (form_score: 0.999, similarity: 0.654)\n",
      "   - 104473-000.pdf, page 40 (form_score: 0.999, similarity: 0.574)\n",
      "   - 104473-000.pdf, page 19 (form_score: 0.998, similarity: 0.649)\n",
      "\n",
      "2. BORDERLINE CASES (Almost matching examples):\n",
      "   Found 203 pages\n",
      "   These are close to the threshold - adding similar examples would help\n",
      "\n",
      "   Top borderline cases:\n",
      "   - 0000000000000000000068702-000.pdf, page 15 (similarity: 0.700)\n",
      "   - 23954-000.pdf, page 7 (similarity: 0.699)\n",
      "   - 39719-000.pdf, page 16 (similarity: 0.699)\n",
      "   - 45703-000.pdf, page 14 (similarity: 0.698)\n",
      "   - 56163-002.pdf, page 2 (similarity: 0.698)\n",
      "\n",
      "3. BLOCKED BY NEGATIVE EXAMPLES:\n",
      "   Found 78 pages\n",
      "   These look like forms but are too similar to non-examples\n",
      "   Consider if your negative examples are too broad\n",
      "\n",
      "=== RECOMMENDATIONS ===\n",
      "\n",
      "1. DIVERSITY GAPS:\n",
      "   - Average similarity to best example: 0.688\n",
      "\n",
      "2. OPTIMAL EXAMPLES TO ADD:\n",
      "   - Add 5 examples from the 'missed forms' list above\n",
      "   - These would expand your example coverage\n",
      "   - Add 2-3 examples from the 'borderline cases'\n",
      "   - These would strengthen detection of edge cases\n",
      "\n",
      "3. THRESHOLD ADJUSTMENTS:\n",
      "   - Consider lowering similarity threshold from 0.7 to 0.6499999999999999\n",
      "   - Consider raising negative threshold from 0.7 to 0.75\n",
      "\n",
      "4. DETAILED DIAGNOSTICS saved to: ../../data/intermediate_products/form_detection_diagnostics.csv\n",
      "   Review this file to manually inspect specific cases\n"
     ]
    }
   ],
   "source": [
    "# Identify patterns in missed forms and false positives\n",
    "print(\"\\n=== DETECTION PATTERN ANALYSIS ===\\n\")\n",
    "\n",
    "# 1. Find pages that zero-shot thinks are forms but don't match examples\n",
    "zeroshot_only = diag_df[\n",
    "    (diag_df['is_form_zeroshot'] == True) & \n",
    "    (diag_df['is_form_positive'] == False) &\n",
    "    (diag_df['max_positive_sim'] > 0)  # Has examples but no match\n",
    "]\n",
    "\n",
    "print(f\"1. POTENTIAL MISSED FORMS (Zero-shot detected but no example match):\")\n",
    "print(f\"   Found {len(zeroshot_only)} pages\")\n",
    "if len(zeroshot_only) > 0:\n",
    "    print(f\"   Average similarity to examples: {zeroshot_only['max_positive_sim'].mean():.3f}\")\n",
    "    print(f\"   These pages have form-like structure but don't match your examples\")\n",
    "    print(f\"\\n   Top candidates to add as examples:\")\n",
    "    top_missed = zeroshot_only.nlargest(5, 'form_score')[['file', 'page', 'form_score', 'max_positive_sim']]\n",
    "    for _, row in top_missed.iterrows():\n",
    "        print(f\"   - {row['file']}, page {row['page']} (form_score: {row['form_score']:.3f}, similarity: {row['max_positive_sim']:.3f})\")\n",
    "\n",
    "# 2. Find borderline cases\n",
    "borderline = diag_df[\n",
    "    (diag_df['max_positive_sim'] > 0.6) & \n",
    "    (diag_df['max_positive_sim'] < 0.7)\n",
    "]\n",
    "\n",
    "print(f\"\\n2. BORDERLINE CASES (Almost matching examples):\")\n",
    "print(f\"   Found {len(borderline)} pages\")\n",
    "if len(borderline) > 0:\n",
    "    print(f\"   These are close to the threshold - adding similar examples would help\")\n",
    "    print(f\"\\n   Top borderline cases:\")\n",
    "    top_borderline = borderline.nlargest(5, 'max_positive_sim')[['file', 'page', 'max_positive_sim', 'form_score']]\n",
    "    for _, row in top_borderline.iterrows():\n",
    "        print(f\"   - {row['file']}, page {row['page']} (similarity: {row['max_positive_sim']:.3f})\")\n",
    "\n",
    "# 3. Find false negatives blocked by negative examples\n",
    "blocked_by_negatives = diag_df[\n",
    "    (diag_df['is_form_zeroshot'] == True) & \n",
    "    (diag_df['is_form_positive'] == True) &\n",
    "    (diag_df['is_not_like_negative'] == False)\n",
    "]\n",
    "\n",
    "print(f\"\\n3. BLOCKED BY NEGATIVE EXAMPLES:\")\n",
    "print(f\"   Found {len(blocked_by_negatives)} pages\")\n",
    "if len(blocked_by_negatives) > 0:\n",
    "    print(f\"   These look like forms but are too similar to non-examples\")\n",
    "    print(f\"   Consider if your negative examples are too broad\")\n",
    "\n",
    "# 4. Summary recommendations\n",
    "print(f\"\\n=== RECOMMENDATIONS ===\")\n",
    "print(f\"\\n1. DIVERSITY GAPS:\")\n",
    "if len(example_features) > 0:\n",
    "    avg_similarity = diag_df[diag_df['max_positive_sim'] > 0]['max_positive_sim'].mean()\n",
    "    print(f\"   - Average similarity to best example: {avg_similarity:.3f}\")\n",
    "    if avg_similarity < 0.5:\n",
    "        print(f\"   - Your examples may not represent the forms in this dataset well\")\n",
    "        print(f\"   - Consider adding more diverse examples\")\n",
    "\n",
    "print(f\"\\n2. OPTIMAL EXAMPLES TO ADD:\")\n",
    "if len(zeroshot_only) > 0:\n",
    "    print(f\"   - Add {min(5, len(zeroshot_only))} examples from the 'missed forms' list above\")\n",
    "    print(f\"   - These would expand your example coverage\")\n",
    "\n",
    "if len(borderline) > 0:\n",
    "    print(f\"   - Add 2-3 examples from the 'borderline cases'\")\n",
    "    print(f\"   - These would strengthen detection of edge cases\")\n",
    "\n",
    "print(f\"\\n3. THRESHOLD ADJUSTMENTS:\")\n",
    "if len(borderline) > len(zeroshot_only):\n",
    "    print(f\"   - Consider lowering similarity threshold from {SIMILARITY_THRESHOLD} to {SIMILARITY_THRESHOLD - 0.05}\")\n",
    "if len(blocked_by_negatives) > 0:\n",
    "    print(f\"   - Consider raising negative threshold from {NEGATIVE_THRESHOLD} to {NEGATIVE_THRESHOLD + 0.05}\")\n",
    "\n",
    "# Save detailed diagnostics\n",
    "diag_df.to_csv('../../data/intermediate_products/form_detection_diagnostics.csv', index=False)\n",
    "print(f\"\\n4. DETAILED DIAGNOSTICS saved to: ../../data/intermediate_products/form_detection_diagnostics.csv\")\n",
    "print(f\"   Review this file to manually inspect specific cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mz3yj22zro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract specific pages for manual review\n",
    "def extract_diagnostic_pages(results_list, output_dir=\"../../data/intermediate_products/diagnostic_pages/\"):\n",
    "    \"\"\"Extract specific pages identified in diagnostics for manual review\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    extracted = []\n",
    "    for item in results_list:\n",
    "        try:\n",
    "            pdf_path = os.path.join(pdf_dir, item['file'])\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "            \n",
    "            # Extract the specific page\n",
    "            page_num = item['page'] - 1  # Convert to 0-based\n",
    "            output_pdf = fitz.open()\n",
    "            output_pdf.insert_pdf(pdf_document, from_page=page_num, to_page=page_num)\n",
    "            \n",
    "            # Save with descriptive name\n",
    "            output_name = f\"{item['file'].replace('.pdf', '')}_page{item['page']}_score{item.get('form_score', 0):.2f}.pdf\"\n",
    "            output_path = os.path.join(output_dir, output_name)\n",
    "            output_pdf.save(output_path)\n",
    "            output_pdf.close()\n",
    "            pdf_document.close()\n",
    "            \n",
    "            extracted.append(output_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting {item['file']} page {item['page']}: {e}\")\n",
    "    \n",
    "    return extracted\n",
    "\n",
    "# Extract the most useful examples\n",
    "print(f\"\\n=== EXTRACTING DIAGNOSTIC PAGES ===\")\n",
    "\n",
    "if len(zeroshot_only) > 0:\n",
    "    print(f\"\\nExtracting top missed forms for review...\")\n",
    "    missed_forms = zeroshot_only.nlargest(min(10, len(zeroshot_only)), 'form_score').to_dict('records')\n",
    "    extracted_missed = extract_diagnostic_pages(missed_forms, \n",
    "                                               \"../../data/intermediate_products/diagnostic_pages/missed_forms/\")\n",
    "    print(f\"Extracted {len(extracted_missed)} missed form candidates\")\n",
    "\n",
    "if len(borderline) > 0:\n",
    "    print(f\"\\nExtracting borderline cases for review...\")\n",
    "    borderline_cases = borderline.nlargest(min(10, len(borderline)), 'max_positive_sim').to_dict('records')\n",
    "    extracted_borderline = extract_diagnostic_pages(borderline_cases,\n",
    "                                                   \"../../data/intermediate_products/diagnostic_pages/borderline/\")\n",
    "    print(f\"Extracted {len(extracted_borderline)} borderline cases\")\n",
    "\n",
    "print(f\"\\n✓ Review these extracted pages to identify which ones are actually forms\")\n",
    "print(f\"✓ Add the true forms to your examples directory\")\n",
    "print(f\"✓ This will improve detection accuracy for similar forms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emqf7mhm7mk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing loop with simplified visual detection\n",
    "print(\"\\n=== SIMPLIFIED VISUAL FORM DETECTION ===\")\n",
    "print(f\"Using {len(example_features)} positive examples\")\n",
    "print(f\"Using {len(nonexample_features)} negative examples\")\n",
    "print(f\"Similarity threshold: {SIMILARITY_THRESHOLD}\")\n",
    "print(f\"Negative threshold: {NEGATIVE_THRESHOLD}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ptgx67im458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDFs with CLIP visual detection\n",
    "results_visual = []\n",
    "\n",
    "# Process a subset of files\n",
    "for pdf_file in pdf_files[:20]:  # Test first 20\n",
    "    try:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        best_form_page = None\n",
    "        best_confidence = 0\n",
    "        page_results = []\n",
    "        \n",
    "        # Check each page\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            \n",
    "            # Convert to image\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # Visual detection with CLIP\n",
    "            detection = detect_form_visual_clip(\n",
    "                img, clip_model, clip_processor, device,\n",
    "                example_features, nonexample_features,\n",
    "                SIMILARITY_THRESHOLD, NEGATIVE_THRESHOLD\n",
    "            )\n",
    "            \n",
    "            page_results.append({\n",
    "                'page': page_num + 1,\n",
    "                'is_form': detection['is_form'],\n",
    "                'confidence': detection['confidence'],\n",
    "                'pos_sim': detection['max_positive_similarity'],\n",
    "                'neg_sim': detection['max_negative_similarity']\n",
    "            })\n",
    "            \n",
    "            # If this is a form with higher confidence than current best\n",
    "            if detection['is_form'] and detection['confidence'] > best_confidence:\n",
    "                best_confidence = detection['confidence']\n",
    "                best_form_page = page_num\n",
    "                \n",
    "                # Stop early if confidence is very high\n",
    "                if best_confidence > CONFIDENCE_THRESHOLD:\n",
    "                    break\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'file': pdf_file,\n",
    "            'total_pages': len(pdf_document),\n",
    "            'has_form': best_form_page is not None,\n",
    "            'form_page': best_form_page + 1 if best_form_page is not None else None,\n",
    "            'confidence': best_confidence,\n",
    "            'page_details': page_results\n",
    "        }\n",
    "        results_visual.append(result)\n",
    "        \n",
    "        # Extract best form page if found\n",
    "        if best_form_page is not None:\n",
    "            output_pdf = fitz.open()\n",
    "            output_pdf.insert_pdf(pdf_document, from_page=best_form_page, to_page=best_form_page)\n",
    "            \n",
    "            output_path = os.path.join(formpage_dir, pdf_file)\n",
    "            output_pdf.save(output_path)\n",
    "            output_pdf.close()\n",
    "            \n",
    "            print(f\"✓ {pdf_file}: Form on page {best_form_page + 1} (conf: {best_confidence:.3f})\")\n",
    "        else:\n",
    "            print(f\"✗ {pdf_file}: No form found\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {str(e)}\")\n",
    "        results_visual.append({\n",
    "            'file': pdf_file,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "results_visual_df = pd.DataFrame(results_visual)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"CLIP Visual Detection Summary:\")\n",
    "print(f\"Total PDFs: {len(results_visual_df)}\")\n",
    "print(f\"Forms found: {results_visual_df['has_form'].sum()}\")\n",
    "\n",
    "# Save results\n",
    "results_visual_df.to_csv('../../data/intermediate_products/clip_visual_detection_results.csv', index=False)\n",
    "print(f\"\\nResults saved to: ../../data/intermediate_products/clip_visual_detection_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r7v3897o7es",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Test detection on the example forms themselves\n",
    "print(\"=== DIAGNOSTIC: Testing detection on example forms ===\")\n",
    "print(\"This should have very high similarity scores...\\n\")\n",
    "\n",
    "if example_features and os.path.exists(example_forms_dir):\n",
    "    # Test first few example forms\n",
    "    test_files = [f for f in os.listdir(example_forms_dir) if f.endswith('.pdf')][:3]\n",
    "    \n",
    "    for test_file in test_files:\n",
    "        print(f\"\\nTesting on example form: {test_file}\")\n",
    "        test_path = os.path.join(example_forms_dir, test_file)\n",
    "        \n",
    "        try:\n",
    "            pdf = fitz.open(test_path)\n",
    "            page = pdf[0]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # Test visual detection with CLIP\n",
    "            result = detect_form_visual_clip(\n",
    "                img, clip_model, clip_processor, device,\n",
    "                example_features, nonexample_features,\n",
    "                SIMILARITY_THRESHOLD, NEGATIVE_THRESHOLD\n",
    "            )\n",
    "            \n",
    "            print(f\"  Visual detection: {result['is_form']}\")\n",
    "            print(f\"  Confidence: {result['confidence']:.3f}\")\n",
    "            print(f\"  Max positive similarity: {result['max_positive_similarity']:.3f}\")\n",
    "            print(f\"  Max negative similarity: {result['max_negative_similarity']:.3f}\")\n",
    "            print(f\"  Is above threshold ({SIMILARITY_THRESHOLD})? {result['max_positive_similarity'] > SIMILARITY_THRESHOLD}\")\n",
    "            print(f\"  Is below negative threshold ({NEGATIVE_THRESHOLD})? {result['max_negative_similarity'] < NEGATIVE_THRESHOLD}\")\n",
    "            \n",
    "            pdf.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tixfvxj6kl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full processing with CLIP visual detection\n",
    "# Uncomment below to process all PDFs (this will take a long time)\n",
    "\n",
    "\"\"\"\n",
    "print(\"\\\\n=== PROCESSING ALL PDFs WITH CLIP VISUAL DETECTION ===\")\n",
    "print(f\"Total PDFs to process: {len(pdf_files)}\")\n",
    "print(\"This may take a while...\")\n",
    "\n",
    "results_all_visual = []\n",
    "processed = 0\n",
    "\n",
    "for i, pdf_file in enumerate(pdf_files):\n",
    "    if i % 100 == 0 and i > 0:\n",
    "        print(f\"Processed {i}/{len(pdf_files)} PDFs...\")\n",
    "    \n",
    "    try:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        best_form_page = None\n",
    "        best_confidence = 0\n",
    "        \n",
    "        # Check each page\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # Visual detection with CLIP\n",
    "            detection = detect_form_visual_clip(\n",
    "                img, clip_model, clip_processor, device,\n",
    "                example_features, nonexample_features,\n",
    "                SIMILARITY_THRESHOLD, NEGATIVE_THRESHOLD\n",
    "            )\n",
    "            \n",
    "            # If this is a form with higher confidence\n",
    "            if detection['is_form'] and detection['confidence'] > best_confidence:\n",
    "                best_confidence = detection['confidence']\n",
    "                best_form_page = page_num\n",
    "                \n",
    "                # Stop early if very confident\n",
    "                if best_confidence > CONFIDENCE_THRESHOLD:\n",
    "                    break\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'file': pdf_file,\n",
    "            'total_pages': len(pdf_document),\n",
    "            'has_form': best_form_page is not None,\n",
    "            'form_page': best_form_page + 1 if best_form_page is not None else None,\n",
    "            'confidence': best_confidence\n",
    "        }\n",
    "        results_all_visual.append(result)\n",
    "        \n",
    "        # Extract best form page if found\n",
    "        if best_form_page is not None:\n",
    "            output_pdf = fitz.open()\n",
    "            output_pdf.insert_pdf(pdf_document, from_page=best_form_page, to_page=best_form_page)\n",
    "            output_path = os.path.join(formpage_dir, pdf_file)\n",
    "            output_pdf.save(output_path)\n",
    "            output_pdf.close()\n",
    "        \n",
    "        pdf_document.close()\n",
    "        processed += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        results_all_visual.append({\n",
    "            'file': pdf_file,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Save full results\n",
    "results_all_visual_df = pd.DataFrame(results_all_visual)\n",
    "results_all_visual_df.to_csv('../../data/intermediate_products/clip_visual_detection_all_pdfs.csv', index=False)\n",
    "\n",
    "print(f\"\\\\nProcessing complete!\")\n",
    "print(f\"Total processed: {processed}\")\n",
    "print(f\"Forms found: {results_all_visual_df['has_form'].sum()}\")\n",
    "print(f\"Results saved to: ../../data/intermediate_products/clip_visual_detection_all_pdfs.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irgp1bo7p78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_form_hybrid(image, detector, model, processor, example_features=None, \n",
    "                      form_threshold=0.5, similarity_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Hybrid form detection requiring BOTH zero-shot classification AND example similarity\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image to analyze\n",
    "        detector: Zero-shot classifier pipeline\n",
    "        model: CLIP model for feature extraction\n",
    "        processor: CLIP processor\n",
    "        example_features: List of feature vectors from example forms\n",
    "        form_threshold: Threshold for zero-shot form classification\n",
    "        similarity_threshold: Threshold for example similarity\n",
    "    \n",
    "    Returns:\n",
    "        dict with detection results\n",
    "    \"\"\"\n",
    "    # Zero-shot classification\n",
    "    predictions = detector(image, candidate_labels=[\n",
    "        \"multi-column data form with entry boxes\",\n",
    "        \"prose in single column layout\"\n",
    "    ])\n",
    "    \n",
    "    form_score = next(p['score'] for p in predictions if 'form' in p['label'])\n",
    "    prose_score = next(p['score'] for p in predictions if 'prose' in p['label'])\n",
    "    \n",
    "    result = {\n",
    "        'form_score': form_score,\n",
    "        'prose_score': prose_score,\n",
    "        'is_form_zeroshot': form_score > prose_score,\n",
    "        'similarity_scores': [],\n",
    "        'max_similarity': 0,\n",
    "        'is_form_example': False\n",
    "    }\n",
    "    \n",
    "    # Example-based detection if examples are available\n",
    "    if example_features:\n",
    "        # Extract features from current image\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "            image_features = image_features.cpu().numpy()\n",
    "        \n",
    "        # Calculate similarity with each example\n",
    "        for example_feat in example_features:\n",
    "            similarity = cosine_similarity(image_features, example_feat)[0][0]\n",
    "            result['similarity_scores'].append(similarity)\n",
    "        \n",
    "        result['max_similarity'] = max(result['similarity_scores']) if result['similarity_scores'] else 0\n",
    "        result['is_form_example'] = result['max_similarity'] > similarity_threshold\n",
    "        \n",
    "        # STRICTER: Require BOTH conditions to be true\n",
    "        result['is_form'] = result['is_form_zeroshot'] AND result['is_form_example']\n",
    "        \n",
    "        # Confidence is the minimum of both scores (since both must be high)\n",
    "        # Normalize similarity to 0-1 range for fair comparison\n",
    "        normalized_similarity = result['max_similarity']\n",
    "        result['confidence'] = min(form_score, normalized_similarity)\n",
    "        \n",
    "    else:\n",
    "        # If no examples, only use zero-shot\n",
    "        result['is_form'] = result['is_form_zeroshot']\n",
    "        result['confidence'] = form_score\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ftmx5gcbrli",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDFs with hybrid detection - Find highest probability form\n",
    "results_hybrid = []\n",
    "\n",
    "# Set thresholds\n",
    "SIMILARITY_THRESHOLD = 0.7  # Adjust based on your examples\n",
    "CONFIDENCE_THRESHOLD = 0.90  # Stop early if we find a very confident match\n",
    "\n",
    "print(f\"Processing with hybrid detection (examples available: {len(example_features) > 0})\")\n",
    "\n",
    "for pdf_file in pdf_files[:10]:  # Test with first 10\n",
    "    try:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        best_form_page = None\n",
    "        best_confidence = 0\n",
    "        \n",
    "        # Check each page\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            # Convert page to image\n",
    "            page = pdf_document[page_num]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # Hybrid detection\n",
    "            detection = detect_form_hybrid(\n",
    "                img, detector, model, processor, \n",
    "                example_features if example_features else None,\n",
    "                0.5, SIMILARITY_THRESHOLD\n",
    "            )\n",
    "            \n",
    "            # If this is a form and has higher confidence than current best\n",
    "            if detection['is_form'] and detection['confidence'] > best_confidence:\n",
    "                best_confidence = detection['confidence']\n",
    "                best_form_page = page_num\n",
    "                \n",
    "                # Stop early if confidence is very high\n",
    "                if best_confidence > CONFIDENCE_THRESHOLD:\n",
    "                    break\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'file': pdf_file,\n",
    "            'total_pages': len(pdf_document),\n",
    "            'has_form': best_form_page is not None,\n",
    "            'best_form_page': best_form_page + 1 if best_form_page is not None else None,\n",
    "            'best_form_confidence': best_confidence\n",
    "        }\n",
    "        results_hybrid.append(result)\n",
    "        \n",
    "        # Extract best form page if found\n",
    "        if best_form_page is not None:\n",
    "            # Create a new PDF with just the best form page\n",
    "            output_pdf = fitz.open()\n",
    "            output_pdf.insert_pdf(pdf_document, from_page=best_form_page, to_page=best_form_page)\n",
    "            \n",
    "            # Save to formpage directory\n",
    "            output_path = os.path.join(formpage_dir, pdf_file)\n",
    "            output_pdf.save(output_path)\n",
    "            output_pdf.close()\n",
    "            \n",
    "            print(f\"✓ {pdf_file}: Best form on page {best_form_page + 1} (confidence: {best_confidence:.3f})\")\n",
    "        else:\n",
    "            print(f\"✗ {pdf_file}: No form pages found\")\n",
    "        \n",
    "        pdf_document.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {str(e)}\")\n",
    "        results_hybrid.append({\n",
    "            'file': pdf_file,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "results_hybrid_df = pd.DataFrame(results_hybrid)\n",
    "print(f\"\\nHybrid Detection Summary:\")\n",
    "print(f\"Total PDFs: {len(results_hybrid_df)}\")\n",
    "print(f\"PDFs with forms: {results_hybrid_df['has_form'].sum()}\")\n",
    "if example_features:\n",
    "    print(f\"Using {len(example_features)} example forms for similarity matching\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g5ksbpc2u6t",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare detection modes: OR vs AND logic\n",
    "print(\"Detection Logic Comparison:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"OR Logic (Original): Page is a form if:\")\n",
    "print(\"  - Zero-shot says it's a form (form_score > prose_score)\")\n",
    "print(\"  - OR it looks like an example (similarity > 0.7)\")\n",
    "print(\"  → More permissive, catches more forms but may have false positives\")\n",
    "print()\n",
    "print(\"AND Logic (Stricter): Page is a form if:\")\n",
    "print(\"  - Zero-shot says it's a form (form_score > prose_score)\")\n",
    "print(\"  - AND it looks like an example (similarity > 0.7)\")\n",
    "print(\"  → More restrictive, higher precision but may miss some forms\")\n",
    "print()\n",
    "print(\"Note: If no examples are provided, both modes use only zero-shot classification\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dm6cqs8b11h",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_form_hybrid_configurable(image, detector, model, processor, example_features=None, \n",
    "                                   form_threshold=0.5, similarity_threshold=0.7, \n",
    "                                   logic_mode='AND'):\n",
    "    \"\"\"\n",
    "    Configurable hybrid form detection with choice of AND/OR logic\n",
    "    \n",
    "    Args:\n",
    "        logic_mode: 'AND' requires both conditions, 'OR' requires either condition\n",
    "    \"\"\"\n",
    "    # Zero-shot classification\n",
    "    predictions = detector(image, candidate_labels=[\n",
    "        \"multi-column data form with entry boxes\",\n",
    "        \"prose in single column layout\"\n",
    "    ])\n",
    "    \n",
    "    form_score = next(p['score'] for p in predictions if 'form' in p['label'])\n",
    "    prose_score = next(p['score'] for p in predictions if 'prose' in p['label'])\n",
    "    \n",
    "    result = {\n",
    "        'form_score': form_score,\n",
    "        'prose_score': prose_score,\n",
    "        'is_form_zeroshot': form_score > prose_score,\n",
    "        'similarity_scores': [],\n",
    "        'max_similarity': 0,\n",
    "        'is_form_example': False,\n",
    "        'logic_mode': logic_mode\n",
    "    }\n",
    "    \n",
    "    # Example-based detection if examples are available\n",
    "    if example_features:\n",
    "        # Extract features from current image\n",
    "        inputs = processor(images=image, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            image_features = model.get_image_features(**inputs)\n",
    "            image_features = image_features.cpu().numpy()\n",
    "        \n",
    "        # Calculate similarity with each example\n",
    "        for example_feat in example_features:\n",
    "            similarity = cosine_similarity(image_features, example_feat)[0][0]\n",
    "            result['similarity_scores'].append(similarity)\n",
    "        \n",
    "        result['max_similarity'] = max(result['similarity_scores']) if result['similarity_scores'] else 0\n",
    "        result['is_form_example'] = result['max_similarity'] > similarity_threshold\n",
    "        \n",
    "        # Apply chosen logic\n",
    "        if logic_mode == 'AND':\n",
    "            result['is_form'] = result['is_form_zeroshot'] and result['is_form_example']\n",
    "            # Confidence is minimum of both (both must be high)\n",
    "            result['confidence'] = min(form_score, result['max_similarity'])\n",
    "        else:  # OR logic\n",
    "            result['is_form'] = result['is_form_zeroshot'] or result['is_form_example']\n",
    "            # Confidence is weighted average\n",
    "            result['confidence'] = 0.5 * form_score + 0.5 * result['max_similarity']\n",
    "        \n",
    "    else:\n",
    "        # If no examples, only use zero-shot\n",
    "        result['is_form'] = result['is_form_zeroshot']\n",
    "        result['confidence'] = form_score\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7fac552-5ce0-4763-a272-5e0215fd90a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': '25581-000.pdf',\n",
       "  'total_pages': 26,\n",
       "  'form_pages': [0,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   15,\n",
       "   17,\n",
       "   18,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   25],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.9850072264671326,\n",
       "    'prose_score': 0.014992760494351387,\n",
       "    'max_similarity': 0.9357165,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.9603618681430817,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.20860306918621063,\n",
       "    'prose_score': 0.7913969159126282,\n",
       "    'max_similarity': 0.6042408,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.406421922147274,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.1713697463274002,\n",
       "    'prose_score': 0.828630268573761,\n",
       "    'max_similarity': 0.7604046,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4658871665596962,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.06545615196228027,\n",
       "    'prose_score': 0.9345439076423645,\n",
       "    'max_similarity': 0.7590505,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.41225332021713257,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.07136119157075882,\n",
       "    'prose_score': 0.9286388158798218,\n",
       "    'max_similarity': 0.7034476,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3874043859541416,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 6,\n",
       "    'form_score': 0.8096569776535034,\n",
       "    'prose_score': 0.19034308195114136,\n",
       "    'max_similarity': 0.70293,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7562934756278992,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 7,\n",
       "    'form_score': 0.7629449963569641,\n",
       "    'prose_score': 0.2370549887418747,\n",
       "    'max_similarity': 0.7241675,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7435562610626221,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 8,\n",
       "    'form_score': 0.7521566152572632,\n",
       "    'prose_score': 0.247843399643898,\n",
       "    'max_similarity': 0.72243875,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7372976839542389,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 9,\n",
       "    'form_score': 0.5092777013778687,\n",
       "    'prose_score': 0.49072229862213135,\n",
       "    'max_similarity': 0.73241377,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6208457350730896,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 10,\n",
       "    'form_score': 0.7130816578865051,\n",
       "    'prose_score': 0.2869182825088501,\n",
       "    'max_similarity': 0.7020435,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7075625658035278,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 11,\n",
       "    'form_score': 0.77127605676651,\n",
       "    'prose_score': 0.22872398793697357,\n",
       "    'max_similarity': 0.74996275,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7606194019317627,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 12,\n",
       "    'form_score': 0.8771405220031738,\n",
       "    'prose_score': 0.12285950034856796,\n",
       "    'max_similarity': 0.7572454,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8171929717063904,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 13,\n",
       "    'form_score': 0.657455325126648,\n",
       "    'prose_score': 0.34254470467567444,\n",
       "    'max_similarity': 0.7734227,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7154390215873718,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 14,\n",
       "    'form_score': 0.2709810733795166,\n",
       "    'prose_score': 0.7290189266204834,\n",
       "    'max_similarity': 0.775552,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5232665240764618,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 15,\n",
       "    'form_score': 0.2598496675491333,\n",
       "    'prose_score': 0.7401503324508667,\n",
       "    'max_similarity': 0.6747346,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4672921299934387,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 16,\n",
       "    'form_score': 0.8378704190254211,\n",
       "    'prose_score': 0.16212958097457886,\n",
       "    'max_similarity': 0.740757,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7893137037754059,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 17,\n",
       "    'form_score': 0.07442034035921097,\n",
       "    'prose_score': 0.9255796670913696,\n",
       "    'max_similarity': 0.6883771,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3813987113535404,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 18,\n",
       "    'form_score': 0.5308279395103455,\n",
       "    'prose_score': 0.46917203068733215,\n",
       "    'max_similarity': 0.7109281,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6208780109882355,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 19,\n",
       "    'form_score': 0.02011246792972088,\n",
       "    'prose_score': 0.9798874855041504,\n",
       "    'max_similarity': 0.7751869,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3976496821269393,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 20,\n",
       "    'form_score': 0.015614509582519531,\n",
       "    'prose_score': 0.9843854308128357,\n",
       "    'max_similarity': 0.64894164,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3322780728340149,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 21,\n",
       "    'form_score': 0.7583638429641724,\n",
       "    'prose_score': 0.24163614213466644,\n",
       "    'max_similarity': 0.8211192,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7897415161132812,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 22,\n",
       "    'form_score': 0.3239830434322357,\n",
       "    'prose_score': 0.6760169863700867,\n",
       "    'max_similarity': 0.8475478,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5857654362916946,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 23,\n",
       "    'form_score': 0.012227986007928848,\n",
       "    'prose_score': 0.9877719879150391,\n",
       "    'max_similarity': 0.79323214,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.40273006446659565,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 24,\n",
       "    'form_score': 0.8810985684394836,\n",
       "    'prose_score': 0.11890146881341934,\n",
       "    'max_similarity': 0.64705837,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7640784680843353,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 25,\n",
       "    'form_score': 0.08821658790111542,\n",
       "    'prose_score': 0.9117833971977234,\n",
       "    'max_similarity': 0.6337211,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.36096885055303574,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 26,\n",
       "    'form_score': 0.022280598059296608,\n",
       "    'prose_score': 0.9777194261550903,\n",
       "    'max_similarity': 0.71830416,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.37029237765818834,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '99171-000.pdf',\n",
       "  'total_pages': 32,\n",
       "  'form_pages': [0, 2, 4, 5, 10, 11, 15, 16, 18, 19, 20, 22, 23, 31],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.945388913154602,\n",
       "    'prose_score': 0.05461104214191437,\n",
       "    'max_similarity': 0.9241061,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.9347475171089172,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.010571835562586784,\n",
       "    'prose_score': 0.9894281029701233,\n",
       "    'max_similarity': 0.6379897,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3242807677015662,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.02685379981994629,\n",
       "    'prose_score': 0.9731462001800537,\n",
       "    'max_similarity': 0.71891344,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3728836178779602,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.05075322091579437,\n",
       "    'prose_score': 0.9492468237876892,\n",
       "    'max_similarity': 0.69015175,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.37045248597860336,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.021723901852965355,\n",
       "    'prose_score': 0.9782760739326477,\n",
       "    'max_similarity': 0.7211344,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.37142916303128004,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 6,\n",
       "    'form_score': 0.025342367589473724,\n",
       "    'prose_score': 0.9746575951576233,\n",
       "    'max_similarity': 0.70784235,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3665923587977886,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 7,\n",
       "    'form_score': 0.019521363079547882,\n",
       "    'prose_score': 0.9804787039756775,\n",
       "    'max_similarity': 0.68497956,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.35225046053528786,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 8,\n",
       "    'form_score': 0.15816470980644226,\n",
       "    'prose_score': 0.8418353199958801,\n",
       "    'max_similarity': 0.68674135,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.42245303094387054,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 9,\n",
       "    'form_score': 0.12468082457780838,\n",
       "    'prose_score': 0.8753191828727722,\n",
       "    'max_similarity': 0.6310062,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3778435029089451,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 10,\n",
       "    'form_score': 0.028092125430703163,\n",
       "    'prose_score': 0.971907913684845,\n",
       "    'max_similarity': 0.69189465,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.35999338794499636,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 11,\n",
       "    'form_score': 0.5209147334098816,\n",
       "    'prose_score': 0.4790852665901184,\n",
       "    'max_similarity': 0.5841549,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.552534818649292,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 12,\n",
       "    'form_score': 0.5384431481361389,\n",
       "    'prose_score': 0.46155688166618347,\n",
       "    'max_similarity': 0.5968504,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5676467716693878,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 13,\n",
       "    'form_score': 0.06689222157001495,\n",
       "    'prose_score': 0.9331077337265015,\n",
       "    'max_similarity': 0.668882,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.36788711696863174,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 14,\n",
       "    'form_score': 0.007000443525612354,\n",
       "    'prose_score': 0.9929995536804199,\n",
       "    'max_similarity': 0.67289793,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3399491892196238,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 15,\n",
       "    'form_score': 0.014901126734912395,\n",
       "    'prose_score': 0.9850988388061523,\n",
       "    'max_similarity': 0.6392087,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3270549005828798,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 16,\n",
       "    'form_score': 0.7422356605529785,\n",
       "    'prose_score': 0.2577643394470215,\n",
       "    'max_similarity': 0.6582054,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.70022052526474,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 17,\n",
       "    'form_score': 0.08687128126621246,\n",
       "    'prose_score': 0.9131287336349487,\n",
       "    'max_similarity': 0.7239617,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.40541649609804153,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 18,\n",
       "    'form_score': 0.377960741519928,\n",
       "    'prose_score': 0.622039258480072,\n",
       "    'max_similarity': 0.63973856,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.5088496506214142,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 19,\n",
       "    'form_score': 0.39271748065948486,\n",
       "    'prose_score': 0.6072824597358704,\n",
       "    'max_similarity': 0.75939965,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.576058566570282,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 20,\n",
       "    'form_score': 0.05891631171107292,\n",
       "    'prose_score': 0.9410836696624756,\n",
       "    'max_similarity': 0.7283875,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3936518933624029,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 21,\n",
       "    'form_score': 0.9183995127677917,\n",
       "    'prose_score': 0.08160047978162766,\n",
       "    'max_similarity': 0.720048,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8192237615585327,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 22,\n",
       "    'form_score': 0.2821482717990875,\n",
       "    'prose_score': 0.7178516983985901,\n",
       "    'max_similarity': 0.69591314,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.48903070390224457,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 23,\n",
       "    'form_score': 0.8469696640968323,\n",
       "    'prose_score': 0.15303027629852295,\n",
       "    'max_similarity': 0.7462731,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7966213822364807,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 24,\n",
       "    'form_score': 0.6533351540565491,\n",
       "    'prose_score': 0.34666481614112854,\n",
       "    'max_similarity': 0.7538908,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7036129832267761,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 25,\n",
       "    'form_score': 0.4747619926929474,\n",
       "    'prose_score': 0.525238037109375,\n",
       "    'max_similarity': 0.6779958,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.5763788968324661,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 26,\n",
       "    'form_score': 0.03887282311916351,\n",
       "    'prose_score': 0.9611271023750305,\n",
       "    'max_similarity': 0.6224422,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3306575044989586,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 27,\n",
       "    'form_score': 0.20298698544502258,\n",
       "    'prose_score': 0.797012984752655,\n",
       "    'max_similarity': 0.6703092,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.43664808571338654,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 28,\n",
       "    'form_score': 0.019448479637503624,\n",
       "    'prose_score': 0.9805514812469482,\n",
       "    'max_similarity': 0.6039667,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3117075962945819,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 29,\n",
       "    'form_score': 0.17189133167266846,\n",
       "    'prose_score': 0.8281086087226868,\n",
       "    'max_similarity': 0.6406846,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4062879681587219,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 30,\n",
       "    'form_score': 0.037379179149866104,\n",
       "    'prose_score': 0.9626207947731018,\n",
       "    'max_similarity': 0.6530994,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.34523929841816425,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 31,\n",
       "    'form_score': 0.043413300067186356,\n",
       "    'prose_score': 0.9565866589546204,\n",
       "    'max_similarity': 0.6683648,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3558890614658594,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 32,\n",
       "    'form_score': 0.3773040473461151,\n",
       "    'prose_score': 0.6226959824562073,\n",
       "    'max_similarity': 0.7093544,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5433292239904404,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '13924-002.pdf',\n",
       "  'total_pages': 2,\n",
       "  'form_pages': [0, 1],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.9691547155380249,\n",
       "    'prose_score': 0.030845260247588158,\n",
       "    'max_similarity': 0.9415493,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.9553520083427429,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.6324083209037781,\n",
       "    'prose_score': 0.3675916790962219,\n",
       "    'max_similarity': 0.7399607,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6861844956874847,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '0000000000000000000062223-001.pdf',\n",
       "  'total_pages': 5,\n",
       "  'form_pages': [2, 4],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 3,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.3112011253833771,\n",
       "    'prose_score': 0.6887988448143005,\n",
       "    'max_similarity': 0.58185893,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4465300291776657,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.40567681193351746,\n",
       "    'prose_score': 0.5943232178688049,\n",
       "    'max_similarity': 0.65244365,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.5290602296590805,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.6860320568084717,\n",
       "    'prose_score': 0.3139679729938507,\n",
       "    'max_similarity': 0.38089755,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5334648042917252,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.010876900516450405,\n",
       "    'prose_score': 0.9891231656074524,\n",
       "    'max_similarity': 0.6049382,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3079075547866523,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.45436009764671326,\n",
       "    'prose_score': 0.5456399321556091,\n",
       "    'max_similarity': 0.710021,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5821905583143234,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '0000000000000000000057475-003.pdf',\n",
       "  'total_pages': 2,\n",
       "  'form_pages': [0, 1],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.16909907758235931,\n",
       "    'prose_score': 0.8309009075164795,\n",
       "    'max_similarity': 0.74484205,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.45697056502103806,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.6534457206726074,\n",
       "    'prose_score': 0.3465542495250702,\n",
       "    'max_similarity': 0.6661431,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.659794420003891,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '0000000000000000000061824-000.pdf',\n",
       "  'total_pages': 24,\n",
       "  'form_pages': [0, 3, 5, 6, 7, 9, 10, 11, 16, 19, 20, 21, 23],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.07846973091363907,\n",
       "    'prose_score': 0.9215302467346191,\n",
       "    'max_similarity': 0.70258844,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3905290849506855,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.029995469376444817,\n",
       "    'prose_score': 0.9700045585632324,\n",
       "    'max_similarity': 0.67208105,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.35103826131671667,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.22471968829631805,\n",
       "    'prose_score': 0.7752802968025208,\n",
       "    'max_similarity': 0.6803011,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.45251037925481796,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.10493450611829758,\n",
       "    'prose_score': 0.895065426826477,\n",
       "    'max_similarity': 0.7218493,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.41339191421866417,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.0352492555975914,\n",
       "    'prose_score': 0.9647507667541504,\n",
       "    'max_similarity': 0.69658804,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3659186474978924,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 6,\n",
       "    'form_score': 0.2581447660923004,\n",
       "    'prose_score': 0.7418552041053772,\n",
       "    'max_similarity': 0.7124392,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4852919727563858,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 7,\n",
       "    'form_score': 0.1307169795036316,\n",
       "    'prose_score': 0.8692830204963684,\n",
       "    'max_similarity': 0.728287,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4295019805431366,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 8,\n",
       "    'form_score': 0.39761629700660706,\n",
       "    'prose_score': 0.6023836731910706,\n",
       "    'max_similarity': 0.71863496,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5581256300210953,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 9,\n",
       "    'form_score': 0.30110371112823486,\n",
       "    'prose_score': 0.6988963484764099,\n",
       "    'max_similarity': 0.5987375,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4499205946922302,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 10,\n",
       "    'form_score': 0.06622264534235,\n",
       "    'prose_score': 0.9337772727012634,\n",
       "    'max_similarity': 0.7221248,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3941737301647663,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 11,\n",
       "    'form_score': 0.19777804613113403,\n",
       "    'prose_score': 0.802221953868866,\n",
       "    'max_similarity': 0.77078974,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4842838943004608,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 12,\n",
       "    'form_score': 0.7604248523712158,\n",
       "    'prose_score': 0.23957514762878418,\n",
       "    'max_similarity': 0.7394815,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7499531805515289,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 13,\n",
       "    'form_score': 0.1484542340040207,\n",
       "    'prose_score': 0.8515457510948181,\n",
       "    'max_similarity': 0.6813131,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.41488366574048996,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 14,\n",
       "    'form_score': 0.09863802790641785,\n",
       "    'prose_score': 0.9013619422912598,\n",
       "    'max_similarity': 0.63054043,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.36458922922611237,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 15,\n",
       "    'form_score': 0.08447889238595963,\n",
       "    'prose_score': 0.9155211448669434,\n",
       "    'max_similarity': 0.6856854,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3850821442902088,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 16,\n",
       "    'form_score': 0.45382481813430786,\n",
       "    'prose_score': 0.5461751222610474,\n",
       "    'max_similarity': 0.6593658,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.5565952956676483,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 17,\n",
       "    'form_score': 0.12295737117528915,\n",
       "    'prose_score': 0.8770426511764526,\n",
       "    'max_similarity': 0.7158251,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4193912260234356,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 18,\n",
       "    'form_score': 0.21754573285579681,\n",
       "    'prose_score': 0.7824543118476868,\n",
       "    'max_similarity': 0.57975686,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.39865129441022873,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 19,\n",
       "    'form_score': 0.1584591418504715,\n",
       "    'prose_score': 0.8415408730506897,\n",
       "    'max_similarity': 0.6112808,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3848699703812599,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 20,\n",
       "    'form_score': 0.035923805087804794,\n",
       "    'prose_score': 0.9640761613845825,\n",
       "    'max_similarity': 0.7418053,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3888645600527525,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 21,\n",
       "    'form_score': 0.3335494101047516,\n",
       "    'prose_score': 0.666450560092926,\n",
       "    'max_similarity': 0.73402935,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5337893813848495,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 22,\n",
       "    'form_score': 0.056618593633174896,\n",
       "    'prose_score': 0.9433814287185669,\n",
       "    'max_similarity': 0.72146946,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.38904402777552605,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 23,\n",
       "    'form_score': 0.010218840092420578,\n",
       "    'prose_score': 0.9897811412811279,\n",
       "    'max_similarity': 0.6876277,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.34892325662076473,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 24,\n",
       "    'form_score': 0.912638783454895,\n",
       "    'prose_score': 0.08736121654510498,\n",
       "    'max_similarity': 0.73502827,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8238335251808167,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '1197-000.pdf',\n",
       "  'total_pages': 16,\n",
       "  'form_pages': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.9642615914344788,\n",
       "    'prose_score': 0.03573844954371452,\n",
       "    'max_similarity': 0.9429867,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.9536241590976715,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.7945914268493652,\n",
       "    'prose_score': 0.20540857315063477,\n",
       "    'max_similarity': 0.83045435,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8125228881835938,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.6795725226402283,\n",
       "    'prose_score': 0.32042741775512695,\n",
       "    'max_similarity': 0.81170624,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7456393837928772,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.490100234746933,\n",
       "    'prose_score': 0.5098997354507446,\n",
       "    'max_similarity': 0.7892164,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6396583169698715,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.6715134382247925,\n",
       "    'prose_score': 0.32848650217056274,\n",
       "    'max_similarity': 0.82216823,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7468408346176147,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 6,\n",
       "    'form_score': 0.9776575565338135,\n",
       "    'prose_score': 0.02234240248799324,\n",
       "    'max_similarity': 0.8505436,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.9141005873680115,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 7,\n",
       "    'form_score': 0.023074684664607048,\n",
       "    'prose_score': 0.9769253730773926,\n",
       "    'max_similarity': 0.7369593,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.38001698162406683,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 8,\n",
       "    'form_score': 0.6843571662902832,\n",
       "    'prose_score': 0.3156428635120392,\n",
       "    'max_similarity': 0.62249243,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6534247994422913,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 9,\n",
       "    'form_score': 0.790661096572876,\n",
       "    'prose_score': 0.2093389630317688,\n",
       "    'max_similarity': 0.78412163,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7873913645744324,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 10,\n",
       "    'form_score': 0.6136929392814636,\n",
       "    'prose_score': 0.38630709052085876,\n",
       "    'max_similarity': 0.58826166,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6009773015975952,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 11,\n",
       "    'form_score': 0.996557891368866,\n",
       "    'prose_score': 0.003442097222432494,\n",
       "    'max_similarity': 0.8249646,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.9107612371444702,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 12,\n",
       "    'form_score': 0.6124382019042969,\n",
       "    'prose_score': 0.38756173849105835,\n",
       "    'max_similarity': 0.7354541,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6739461421966553,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 13,\n",
       "    'form_score': 0.9755362868309021,\n",
       "    'prose_score': 0.024463752284646034,\n",
       "    'max_similarity': 0.8088603,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8921982944011688,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 14,\n",
       "    'form_score': 0.06894849240779877,\n",
       "    'prose_score': 0.93105149269104,\n",
       "    'max_similarity': 0.7269144,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.39793144911527634,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 15,\n",
       "    'form_score': 0.3603123128414154,\n",
       "    'prose_score': 0.639687716960907,\n",
       "    'max_similarity': 0.73926044,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5497863739728928,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 16,\n",
       "    'form_score': 0.9815294146537781,\n",
       "    'prose_score': 0.018470579758286476,\n",
       "    'max_similarity': 0.8154192,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8984743058681488,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '67419-000.pdf',\n",
       "  'total_pages': 27,\n",
       "  'form_pages': [0,\n",
       "   1,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   11,\n",
       "   13,\n",
       "   14,\n",
       "   16,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   25,\n",
       "   26],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.9755117297172546,\n",
       "    'prose_score': 0.0244882982224226,\n",
       "    'max_similarity': 0.9386521,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.9570819139480591,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.8939024209976196,\n",
       "    'prose_score': 0.10609761625528336,\n",
       "    'max_similarity': 0.8107668,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8523346185684204,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.22290921211242676,\n",
       "    'prose_score': 0.7770907878875732,\n",
       "    'max_similarity': 0.69784415,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.46037667989730835,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.1971716731786728,\n",
       "    'prose_score': 0.802828311920166,\n",
       "    'max_similarity': 0.76217103,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4796713516116142,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.028038224205374718,\n",
       "    'prose_score': 0.9719617366790771,\n",
       "    'max_similarity': 0.74351275,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3857754869386554,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 6,\n",
       "    'form_score': 0.014213756658136845,\n",
       "    'prose_score': 0.9857861995697021,\n",
       "    'max_similarity': 0.7429164,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.37856508092954755,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 7,\n",
       "    'form_score': 0.08807224780321121,\n",
       "    'prose_score': 0.9119277596473694,\n",
       "    'max_similarity': 0.7076886,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3978804387152195,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 8,\n",
       "    'form_score': 0.14049659669399261,\n",
       "    'prose_score': 0.8595033884048462,\n",
       "    'max_similarity': 0.75049484,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.44549571722745895,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 9,\n",
       "    'form_score': 0.1641165167093277,\n",
       "    'prose_score': 0.8358834385871887,\n",
       "    'max_similarity': 0.689475,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.42679575830698013,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 10,\n",
       "    'form_score': 0.024613913148641586,\n",
       "    'prose_score': 0.9753860831260681,\n",
       "    'max_similarity': 0.69080794,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3577109258621931,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 11,\n",
       "    'form_score': 0.013749987818300724,\n",
       "    'prose_score': 0.9862500429153442,\n",
       "    'max_similarity': 0.69754434,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3556471620686352,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 12,\n",
       "    'form_score': 0.12839829921722412,\n",
       "    'prose_score': 0.8716017603874207,\n",
       "    'max_similarity': 0.775524,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4519611597061157,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 13,\n",
       "    'form_score': 0.17364755272865295,\n",
       "    'prose_score': 0.8263524770736694,\n",
       "    'max_similarity': 0.6973728,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.43551017343997955,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 14,\n",
       "    'form_score': 0.031330522149801254,\n",
       "    'prose_score': 0.9686694741249084,\n",
       "    'max_similarity': 0.7694849,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.400407699868083,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 15,\n",
       "    'form_score': 0.17624059319496155,\n",
       "    'prose_score': 0.8237593770027161,\n",
       "    'max_similarity': 0.7538934,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.46506698429584503,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 16,\n",
       "    'form_score': 0.34293246269226074,\n",
       "    'prose_score': 0.6570675373077393,\n",
       "    'max_similarity': 0.6337503,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.48834139108657837,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 17,\n",
       "    'form_score': 0.04431682080030441,\n",
       "    'prose_score': 0.9556831121444702,\n",
       "    'max_similarity': 0.73513657,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3897266946732998,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 18,\n",
       "    'form_score': 0.2564444839954376,\n",
       "    'prose_score': 0.7435555458068848,\n",
       "    'max_similarity': 0.6985776,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4775110334157944,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 19,\n",
       "    'form_score': 0.16554304957389832,\n",
       "    'prose_score': 0.8344569802284241,\n",
       "    'max_similarity': 0.7372179,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4513804763555527,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 20,\n",
       "    'form_score': 0.3051927387714386,\n",
       "    'prose_score': 0.694807231426239,\n",
       "    'max_similarity': 0.7735574,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5393750816583633,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 21,\n",
       "    'form_score': 0.48432818055152893,\n",
       "    'prose_score': 0.5156718492507935,\n",
       "    'max_similarity': 0.758335,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.621331587433815,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 22,\n",
       "    'form_score': 0.6078627705574036,\n",
       "    'prose_score': 0.39213719964027405,\n",
       "    'max_similarity': 0.6414864,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6246745884418488,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 23,\n",
       "    'form_score': 0.6177180409431458,\n",
       "    'prose_score': 0.38228195905685425,\n",
       "    'max_similarity': 0.66965485,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.643686443567276,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 24,\n",
       "    'form_score': 0.22604499757289886,\n",
       "    'prose_score': 0.7739549875259399,\n",
       "    'max_similarity': 0.5789441,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.40249454230070114,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 25,\n",
       "    'form_score': 0.49660351872444153,\n",
       "    'prose_score': 0.5033964514732361,\n",
       "    'max_similarity': 0.58540225,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.5410028845071793,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 26,\n",
       "    'form_score': 0.574433445930481,\n",
       "    'prose_score': 0.42556649446487427,\n",
       "    'max_similarity': 0.6935823,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6340078711509705,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 27,\n",
       "    'form_score': 0.6634032726287842,\n",
       "    'prose_score': 0.336596816778183,\n",
       "    'max_similarity': 0.7357906,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6995969414710999,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '0000000000000000000058079-000.pdf',\n",
       "  'total_pages': 20,\n",
       "  'form_pages': [0, 1, 3, 4, 7, 9, 11, 12, 14, 15, 17, 19],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 1,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.5344115495681763,\n",
       "    'prose_score': 0.4655884802341461,\n",
       "    'max_similarity': 0.66276765,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5985895991325378,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.02116641029715538,\n",
       "    'prose_score': 0.9788336157798767,\n",
       "    'max_similarity': 0.7326453,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.37690584175288677,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.1341654360294342,\n",
       "    'prose_score': 0.8658345937728882,\n",
       "    'max_similarity': 0.6540878,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.39412660896778107,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.0690167173743248,\n",
       "    'prose_score': 0.9309832453727722,\n",
       "    'max_similarity': 0.7481868,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.4086017720401287,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.06148190796375275,\n",
       "    'prose_score': 0.9385181069374084,\n",
       "    'max_similarity': 0.71910495,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3902934268116951,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 6,\n",
       "    'form_score': 0.19777348637580872,\n",
       "    'prose_score': 0.8022264838218689,\n",
       "    'max_similarity': 0.6762747,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4370241016149521,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 7,\n",
       "    'form_score': 0.031326327472925186,\n",
       "    'prose_score': 0.9686736464500427,\n",
       "    'max_similarity': 0.6693224,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.35032434947788715,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 8,\n",
       "    'form_score': 0.05176657810807228,\n",
       "    'prose_score': 0.9482334852218628,\n",
       "    'max_similarity': 0.7011696,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3764680940657854,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 9,\n",
       "    'form_score': 0.43813851475715637,\n",
       "    'prose_score': 0.5618614554405212,\n",
       "    'max_similarity': 0.6843616,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.5612500458955765,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 10,\n",
       "    'form_score': 0.8538996577262878,\n",
       "    'prose_score': 0.14610034227371216,\n",
       "    'max_similarity': 0.77588534,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8148925006389618,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 11,\n",
       "    'form_score': 0.13724470138549805,\n",
       "    'prose_score': 0.862755298614502,\n",
       "    'max_similarity': 0.48174578,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3094952404499054,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 12,\n",
       "    'form_score': 0.6521078944206238,\n",
       "    'prose_score': 0.34789204597473145,\n",
       "    'max_similarity': 0.5356201,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5938639938831329,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 13,\n",
       "    'form_score': 0.828376054763794,\n",
       "    'prose_score': 0.17162394523620605,\n",
       "    'max_similarity': 0.6255636,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.726969838142395,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 14,\n",
       "    'form_score': 0.24674437940120697,\n",
       "    'prose_score': 0.7532555460929871,\n",
       "    'max_similarity': 0.66431427,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4555293247103691,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 15,\n",
       "    'form_score': 0.06564190983772278,\n",
       "    'prose_score': 0.9343580603599548,\n",
       "    'max_similarity': 0.7064689,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.3860553950071335,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 16,\n",
       "    'form_score': 0.9060728549957275,\n",
       "    'prose_score': 0.09392720460891724,\n",
       "    'max_similarity': 0.68896747,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7975201606750488,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 17,\n",
       "    'form_score': 0.3342544734477997,\n",
       "    'prose_score': 0.6657454967498779,\n",
       "    'max_similarity': 0.56164527,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.4479498714208603,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 18,\n",
       "    'form_score': 0.6288250684738159,\n",
       "    'prose_score': 0.3711749017238617,\n",
       "    'max_similarity': 0.5380337,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5834293961524963,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 19,\n",
       "    'form_score': 0.19378668069839478,\n",
       "    'prose_score': 0.80621337890625,\n",
       "    'max_similarity': 0.68881345,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.44130006432533264,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 20,\n",
       "    'form_score': 0.680286705493927,\n",
       "    'prose_score': 0.319713294506073,\n",
       "    'max_similarity': 0.5844598,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6323732435703278,\n",
       "    'detection_method': 'hybrid'}]},\n",
       " {'file': '104473-000.pdf',\n",
       "  'total_pages': 42,\n",
       "  'form_pages': [10,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   34,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   41],\n",
       "  'has_form': True,\n",
       "  'first_form_page': 11,\n",
       "  'page_details': [{'page': 1,\n",
       "    'form_score': 0.07822588086128235,\n",
       "    'prose_score': 0.9217740893363953,\n",
       "    'max_similarity': 0.65182483,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3650253564119339,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 2,\n",
       "    'form_score': 0.10675914585590363,\n",
       "    'prose_score': 0.8932408690452576,\n",
       "    'max_similarity': 0.6149182,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3608386591076851,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 3,\n",
       "    'form_score': 0.05031714215874672,\n",
       "    'prose_score': 0.949682891368866,\n",
       "    'max_similarity': 0.6388259,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.34457151778042316,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 4,\n",
       "    'form_score': 0.13947510719299316,\n",
       "    'prose_score': 0.8605248332023621,\n",
       "    'max_similarity': 0.6247181,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.38209661841392517,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 5,\n",
       "    'form_score': 0.07589202374219894,\n",
       "    'prose_score': 0.9241080284118652,\n",
       "    'max_similarity': 0.64501107,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3604515455663204,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 6,\n",
       "    'form_score': 0.04686414822936058,\n",
       "    'prose_score': 0.9531359076499939,\n",
       "    'max_similarity': 0.56424284,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3055534940212965,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 7,\n",
       "    'form_score': 0.004105316009372473,\n",
       "    'prose_score': 0.9958946704864502,\n",
       "    'max_similarity': 0.6613276,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3327164582442492,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 8,\n",
       "    'form_score': 0.09028706699609756,\n",
       "    'prose_score': 0.9097129702568054,\n",
       "    'max_similarity': 0.6540351,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.372161079198122,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 9,\n",
       "    'form_score': 0.02440911903977394,\n",
       "    'prose_score': 0.9755908250808716,\n",
       "    'max_similarity': 0.6668204,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.34561476297676563,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 10,\n",
       "    'form_score': 0.0025948365218937397,\n",
       "    'prose_score': 0.9974051117897034,\n",
       "    'max_similarity': 0.61614835,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3093715945724398,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 11,\n",
       "    'form_score': 0.7895859479904175,\n",
       "    'prose_score': 0.21041402220726013,\n",
       "    'max_similarity': 0.6195805,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7045832276344299,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 12,\n",
       "    'form_score': 0.002862878143787384,\n",
       "    'prose_score': 0.9971370697021484,\n",
       "    'max_similarity': 0.60281324,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.3028380610048771,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 13,\n",
       "    'form_score': 0.06021016463637352,\n",
       "    'prose_score': 0.9397898316383362,\n",
       "    'max_similarity': 0.6145142,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.33736216835677624,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 14,\n",
       "    'form_score': 0.05401233211159706,\n",
       "    'prose_score': 0.9459876418113708,\n",
       "    'max_similarity': 0.6368116,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.34541197307407856,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 15,\n",
       "    'form_score': 0.006100348196923733,\n",
       "    'prose_score': 0.9938995838165283,\n",
       "    'max_similarity': 0.7165358,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.36131807742640376,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 16,\n",
       "    'form_score': 0.5317968726158142,\n",
       "    'prose_score': 0.4682031273841858,\n",
       "    'max_similarity': 0.56293327,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.5473650693893433,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 17,\n",
       "    'form_score': 0.9965213537216187,\n",
       "    'prose_score': 0.0034786902833729982,\n",
       "    'max_similarity': 0.712418,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8544696867465973,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 18,\n",
       "    'form_score': 0.8026395440101624,\n",
       "    'prose_score': 0.19736044108867645,\n",
       "    'max_similarity': 0.46431017,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6334748566150665,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 19,\n",
       "    'form_score': 0.9981643557548523,\n",
       "    'prose_score': 0.0018356661312282085,\n",
       "    'max_similarity': 0.6492666,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.823715478181839,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 20,\n",
       "    'form_score': 0.9991766810417175,\n",
       "    'prose_score': 0.0008232930558733642,\n",
       "    'max_similarity': 0.65368235,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8264295160770416,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 21,\n",
       "    'form_score': 0.9956509470939636,\n",
       "    'prose_score': 0.004349033813923597,\n",
       "    'max_similarity': 0.5682559,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7819534242153168,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 22,\n",
       "    'form_score': 0.9940160512924194,\n",
       "    'prose_score': 0.00598397059366107,\n",
       "    'max_similarity': 0.5801815,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.78709876537323,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 23,\n",
       "    'form_score': 0.9867696762084961,\n",
       "    'prose_score': 0.01323026418685913,\n",
       "    'max_similarity': 0.6440623,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8154159784317017,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 24,\n",
       "    'form_score': 0.377909392118454,\n",
       "    'prose_score': 0.6220905780792236,\n",
       "    'max_similarity': 0.42712462,\n",
       "    'is_form': False,\n",
       "    'confidence': 0.40251700580120087,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 25,\n",
       "    'form_score': 0.9973651766777039,\n",
       "    'prose_score': 0.0026348447427153587,\n",
       "    'max_similarity': 0.6427472,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8200562000274658,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 26,\n",
       "    'form_score': 0.9969027638435364,\n",
       "    'prose_score': 0.003097173757851124,\n",
       "    'max_similarity': 0.5672927,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.782097727060318,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 27,\n",
       "    'form_score': 0.9939017295837402,\n",
       "    'prose_score': 0.006098325829952955,\n",
       "    'max_similarity': 0.5749334,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7844175696372986,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 28,\n",
       "    'form_score': 0.9792152643203735,\n",
       "    'prose_score': 0.02078470028936863,\n",
       "    'max_similarity': 0.5757903,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7775027751922607,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 29,\n",
       "    'form_score': 0.9805229306221008,\n",
       "    'prose_score': 0.01947709172964096,\n",
       "    'max_similarity': 0.5744901,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7775065004825592,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 30,\n",
       "    'form_score': 0.9794617295265198,\n",
       "    'prose_score': 0.020538201555609703,\n",
       "    'max_similarity': 0.5747493,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7771055102348328,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 31,\n",
       "    'form_score': 0.9802384376525879,\n",
       "    'prose_score': 0.01976151578128338,\n",
       "    'max_similarity': 0.5745088,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7773736119270325,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 32,\n",
       "    'form_score': 0.9795559048652649,\n",
       "    'prose_score': 0.020444083958864212,\n",
       "    'max_similarity': 0.57912254,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7793392241001129,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 33,\n",
       "    'form_score': 0.780095636844635,\n",
       "    'prose_score': 0.2199043482542038,\n",
       "    'max_similarity': 0.46371847,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6219070553779602,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 34,\n",
       "    'form_score': 0.9996159076690674,\n",
       "    'prose_score': 0.00038405347731895745,\n",
       "    'max_similarity': 0.6205955,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.810105711221695,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 35,\n",
       "    'form_score': 0.9932181239128113,\n",
       "    'prose_score': 0.006781839299947023,\n",
       "    'max_similarity': 0.57057565,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7818968892097473,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 36,\n",
       "    'form_score': 0.9961338043212891,\n",
       "    'prose_score': 0.0038662166334688663,\n",
       "    'max_similarity': 0.6202134,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8081735968589783,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 37,\n",
       "    'form_score': 0.7665623426437378,\n",
       "    'prose_score': 0.233437642455101,\n",
       "    'max_similarity': 0.47386724,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.6202147901058197,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 38,\n",
       "    'form_score': 0.9996034502983093,\n",
       "    'prose_score': 0.0003965273790527135,\n",
       "    'max_similarity': 0.62513405,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8123687505722046,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 39,\n",
       "    'form_score': 0.9939153790473938,\n",
       "    'prose_score': 0.00608460046350956,\n",
       "    'max_similarity': 0.58636093,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7901381552219391,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 40,\n",
       "    'form_score': 0.9991236329078674,\n",
       "    'prose_score': 0.0008763418882153928,\n",
       "    'max_similarity': 0.57424843,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7866860330104828,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 41,\n",
       "    'form_score': 0.9945017099380493,\n",
       "    'prose_score': 0.005498270504176617,\n",
       "    'max_similarity': 0.6009861,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.7977439165115356,\n",
       "    'detection_method': 'hybrid'},\n",
       "   {'page': 42,\n",
       "    'form_score': 0.9640658497810364,\n",
       "    'prose_score': 0.03593411296606064,\n",
       "    'max_similarity': 0.68789864,\n",
       "    'is_form': True,\n",
       "    'confidence': 0.8259822428226471,\n",
       "    'detection_method': 'hybrid'}]}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jkyl5iwnwzr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Enhanced zero-shot with detailed descriptions\n",
    "# This approach uses more specific descriptions without needing example images\n",
    "\n",
    "def detect_form_enhanced_zeroshot(image, detector):\n",
    "    \"\"\"\n",
    "    Enhanced zero-shot detection with more detailed form descriptions\n",
    "    \"\"\"\n",
    "    # More detailed labels that better describe government forms\n",
    "    detailed_labels = [\n",
    "        \"government form with fields, checkboxes, and blank spaces to fill in\",\n",
    "        \"data collection form with labeled entry boxes and structured layout\", \n",
    "        \"official form with sections for entering information\",\n",
    "        \"standardized form with fields for names, dates, and other data\",\n",
    "        \"legal contract or agreement with continuous prose text\",\n",
    "        \"document with paragraphs of text and legal language\",\n",
    "        \"narrative document without form fields\"\n",
    "    ]\n",
    "    \n",
    "    predictions = detector(image, candidate_labels=detailed_labels)\n",
    "    \n",
    "    # Aggregate scores for form-like vs prose-like\n",
    "    form_score = 0\n",
    "    prose_score = 0\n",
    "    \n",
    "    for pred in predictions:\n",
    "        if any(word in pred['label'].lower() for word in ['form', 'fields', 'boxes', 'fill', 'data collection']):\n",
    "            form_score += pred['score']\n",
    "        else:\n",
    "            prose_score += pred['score']\n",
    "    \n",
    "    # Normalize scores\n",
    "    total = form_score + prose_score\n",
    "    if total > 0:\n",
    "        form_score /= total\n",
    "        prose_score /= total\n",
    "    \n",
    "    return {\n",
    "        'form_score': form_score,\n",
    "        'prose_score': prose_score,\n",
    "        'is_form': form_score > prose_score,\n",
    "        'predictions': predictions[:3]  # Top 3 predictions for debugging\n",
    "    }\n",
    "\n",
    "# Test enhanced zero-shot on a few files\n",
    "print(\"\\nTesting enhanced zero-shot detection:\")\n",
    "for pdf_file in pdf_files[:3]:  # Just test 3 files\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    \n",
    "    # Just check first page\n",
    "    page = pdf_document[0]\n",
    "    pix = page.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    result = detect_form_enhanced_zeroshot(img, detector)\n",
    "    print(f\"\\n{pdf_file}:\")\n",
    "    print(f\"  Form score: {result['form_score']:.3f}\")\n",
    "    print(f\"  Prose score: {result['prose_score']:.3f}\")\n",
    "    print(f\"  Is form: {result['is_form']}\")\n",
    "    print(f\"  Top prediction: {result['predictions'][0]['label']} ({result['predictions'][0]['score']:.3f})\")\n",
    "    \n",
    "    pdf_document.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liz4ftslfmq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each PDF file - Extract highest probability form page\n",
    "results = []\n",
    "CONFIDENCE_THRESHOLD = 0.90  # Stop if we find a form with this confidence\n",
    "\n",
    "for pdf_file in pdf_files[:10]:  # Process first 10 files as a test\n",
    "    try:\n",
    "        pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "        \n",
    "        # Open the PDF\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        best_form_page = None\n",
    "        best_confidence = 0\n",
    "        \n",
    "        # Check each page\n",
    "        for page_num in range(len(pdf_document)):\n",
    "            # Convert page to image\n",
    "            page = pdf_document[page_num]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            # Run zero-shot classification\n",
    "            predictions = detector(img, candidate_labels=[\n",
    "                \"multi-column data form with entry boxes\",\n",
    "                \"prose in single column layout\"\n",
    "            ])\n",
    "            \n",
    "            # Get scores\n",
    "            form_score = next(p['score'] for p in predictions if 'form' in p['label'])\n",
    "            prose_score = next(p['score'] for p in predictions if 'prose' in p['label'])\n",
    "            \n",
    "            # If this is a form page and has higher confidence than current best\n",
    "            if form_score > prose_score and form_score > best_confidence:\n",
    "                best_confidence = form_score\n",
    "                best_form_page = page_num\n",
    "                \n",
    "                # Stop early if confidence is very high\n",
    "                if best_confidence > CONFIDENCE_THRESHOLD:\n",
    "                    break\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'file': pdf_file,\n",
    "            'total_pages': len(pdf_document),\n",
    "            'has_form': best_form_page is not None,\n",
    "            'best_form_page': best_form_page + 1 if best_form_page is not None else None,\n",
    "            'best_form_confidence': best_confidence\n",
    "        }\n",
    "        results.append(result)\n",
    "        \n",
    "        # If we found a form page, extract it\n",
    "        if best_form_page is not None:\n",
    "            # Create a new PDF with just the best form page\n",
    "            output_pdf = fitz.open()\n",
    "            output_pdf.insert_pdf(pdf_document, from_page=best_form_page, to_page=best_form_page)\n",
    "            \n",
    "            # Save to formpage directory with same basename\n",
    "            output_path = os.path.join(formpage_dir, pdf_file)\n",
    "            output_pdf.save(output_path)\n",
    "            output_pdf.close()\n",
    "            \n",
    "            print(f\"✓ {pdf_file}: Best form on page {best_form_page + 1} (confidence: {best_confidence:.3f})\")\n",
    "        else:\n",
    "            print(f\"✗ {pdf_file}: No form pages found\")\n",
    "        \n",
    "        # Close the PDF\n",
    "        pdf_document.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_file}: {str(e)}\")\n",
    "        results.append({\n",
    "            'file': pdf_file,\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nProcessed {len(results_df)} PDFs\")\n",
    "print(f\"Found {results_df['has_form'].sum()} PDFs with forms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cdb00-b0e5-4176-805e-c8330b9993bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "os.makedirs('../../data/intermediate_products', exist_ok=True)\n",
    "results_df.to_csv('../../data/intermediate_products/zeroshot_form_contract_fullpdf.csv', index=False)\n",
    "print(f\"Results saved to ../../data/intermediate_products/zeroshot_form_contract_fullpdf.csv\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total PDFs processed: {len(results_df)}\")\n",
    "print(f\"PDFs with forms: {results_df['has_form'].sum()}\")\n",
    "print(f\"PDFs without forms: {(~results_df['has_form']).sum()}\")\n",
    "if 'error' in results_df.columns:\n",
    "    print(f\"PDFs with errors: {results_df['error'].notna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlokwokgzc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full processing - uncomment to process all PDFs\n",
    "# WARNING: This will take a long time for many PDFs\n",
    "\n",
    "# # Process ALL PDF files\n",
    "# results_all = []\n",
    "# \n",
    "# for i, pdf_file in enumerate(pdf_files):\n",
    "#     if i % 100 == 0:\n",
    "#         print(f\"Processing PDF {i+1}/{len(pdf_files)}...\")\n",
    "#     \n",
    "#     try:\n",
    "#         pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "#         \n",
    "#         # Open the PDF\n",
    "#         pdf_document = fitz.open(pdf_path)\n",
    "#         \n",
    "#         form_pages = []\n",
    "#         \n",
    "#         # Check each page\n",
    "#         for page_num in range(len(pdf_document)):\n",
    "#             # Convert page to image\n",
    "#             page = pdf_document[page_num]\n",
    "#             pix = page.get_pixmap()\n",
    "#             img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "#             \n",
    "#             # Run zero-shot classification\n",
    "#             predictions = detector(img, candidate_labels=[\n",
    "#                 \"multi-column data form with entry boxes\",\n",
    "#                 \"prose in single column layout\"\n",
    "#             ])\n",
    "#             \n",
    "#             # Get scores\n",
    "#             form_score = next(p['score'] for p in predictions if 'form' in p['label'])\n",
    "#             prose_score = next(p['score'] for p in predictions if 'prose' in p['label'])\n",
    "#             \n",
    "#             # If this page is likely a form\n",
    "#             if form_score > prose_score:\n",
    "#                 form_pages.append(page_num)\n",
    "#         \n",
    "#         # Store results\n",
    "#         result = {\n",
    "#             'file': pdf_file,\n",
    "#             'total_pages': len(pdf_document),\n",
    "#             'form_pages': form_pages,\n",
    "#             'has_form': len(form_pages) > 0,\n",
    "#             'first_form_page': form_pages[0] + 1 if form_pages else None\n",
    "#         }\n",
    "#         results_all.append(result)\n",
    "#         \n",
    "#         # If the PDF has at least one form page, extract the first form page\n",
    "#         if form_pages:\n",
    "#             first_form_page_num = form_pages[0]\n",
    "#             \n",
    "#             # Create a new PDF with just the first form page\n",
    "#             output_pdf = fitz.open()\n",
    "#             output_pdf.insert_pdf(pdf_document, from_page=first_form_page_num, to_page=first_form_page_num)\n",
    "#             \n",
    "#             # Save to formpage directory\n",
    "#             output_path = os.path.join(formpage_dir, pdf_file)\n",
    "#             output_pdf.save(output_path)\n",
    "#             output_pdf.close()\n",
    "#         \n",
    "#         # Close the PDF\n",
    "#         pdf_document.close()\n",
    "#         \n",
    "#     except Exception as e:\n",
    "#         results_all.append({\n",
    "#             'file': pdf_file,\n",
    "#             'error': str(e)\n",
    "#         })\n",
    "# \n",
    "# # Save full results\n",
    "# results_all_df = pd.DataFrame(results_all)\n",
    "# results_all_df.to_csv('../../data/intermediate_products/zeroshot_form_contract_fullpdf_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
