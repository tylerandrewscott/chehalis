{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Form Detection Issues\n",
    "\n",
    "This notebook investigates why example forms are not being detected as forms when compared against themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model\n",
    "model_name = \"openai/clip-vit-large-patch14-336\"\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "clip_model = clip_model.to(device)\n",
    "clip_model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Extract features from a single example form\n",
    "example_forms_dir = \"../../data/raw/_exampleforms/\"\n",
    "example_files = [f for f in os.listdir(example_forms_dir) if f.endswith('.pdf')]\n",
    "test_file = example_files[0]\n",
    "\n",
    "print(f\"Testing with: {test_file}\")\n",
    "\n",
    "# Load the test image\n",
    "pdf_path = os.path.join(example_forms_dir, test_file)\n",
    "pdf = fitz.open(pdf_path)\n",
    "page = pdf[0]\n",
    "pix = page.get_pixmap()\n",
    "img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "pdf.close()\n",
    "\n",
    "# Extract features\n",
    "inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    features1 = clip_model.get_image_features(**inputs)\n",
    "    features1 = features1.cpu().numpy()\n",
    "    \n",
    "print(f\"Features shape: {features1.shape}\")\n",
    "print(f\"Features norm before normalization: {np.linalg.norm(features1)}\")\n",
    "\n",
    "# Normalize\n",
    "features1_norm = features1 / np.linalg.norm(features1, axis=1, keepdims=True)\n",
    "print(f\"Features norm after normalization: {np.linalg.norm(features1_norm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Compare the same image with itself\n",
    "# Load the same image again\n",
    "pdf = fitz.open(pdf_path)\n",
    "page = pdf[0]\n",
    "pix = page.get_pixmap()\n",
    "img2 = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "pdf.close()\n",
    "\n",
    "# Extract features again\n",
    "inputs2 = clip_processor(images=img2, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    features2 = clip_model.get_image_features(**inputs2)\n",
    "    features2 = features2.cpu().numpy()\n",
    "    features2_norm = features2 / np.linalg.norm(features2, axis=1, keepdims=True)\n",
    "\n",
    "# Compare\n",
    "similarity = cosine_similarity(features1_norm, features2_norm)[0][0]\n",
    "print(f\"\\nSimilarity of the same image with itself: {similarity:.6f}\")\n",
    "print(f\"This should be 1.0 or very close to 1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Load all example features as done in the main notebook\n",
    "example_features = []\n",
    "\n",
    "for example_file in example_files[:5]:  # Test with first 5\n",
    "    example_path = os.path.join(example_forms_dir, example_file)\n",
    "    \n",
    "    try:\n",
    "        pdf = fitz.open(example_path)\n",
    "        page = pdf[0]\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        pdf.close()\n",
    "        \n",
    "        # Extract features\n",
    "        inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            features = clip_model.get_image_features(**inputs)\n",
    "            features = features.cpu().numpy()\n",
    "            features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "            example_features.append(features)\n",
    "        \n",
    "        print(f\"Loaded {example_file}: shape {features.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {example_file}: {e}\")\n",
    "\n",
    "print(f\"\\nTotal example features loaded: {len(example_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Check similarity between examples\n",
    "print(\"Similarity matrix between first 5 examples:\")\n",
    "similarity_matrix = np.zeros((min(5, len(example_features)), min(5, len(example_features))))\n",
    "\n",
    "for i in range(min(5, len(example_features))):\n",
    "    for j in range(min(5, len(example_features))):\n",
    "        sim = cosine_similarity(example_features[i], example_features[j])[0][0]\n",
    "        similarity_matrix[i, j] = sim\n",
    "\n",
    "# Display as DataFrame for better readability\n",
    "sim_df = pd.DataFrame(similarity_matrix, \n",
    "                      index=[f\"Ex{i}\" for i in range(similarity_matrix.shape[0])],\n",
    "                      columns=[f\"Ex{i}\" for i in range(similarity_matrix.shape[1])])\n",
    "print(sim_df.round(3))\n",
    "print(\"\\nDiagonal should be 1.0 (same image with itself)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Replicate the exact detection function\n",
    "def detect_form_visual_clip_debug(image, clip_model, clip_processor, device,\n",
    "                                 positive_features=None, negative_features=None,\n",
    "                                 similarity_threshold=0.7, negative_threshold=0.7):\n",
    "    \"\"\"\n",
    "    Debug version with extra logging\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'is_form': False,\n",
    "        'confidence': 0,\n",
    "        'max_positive_similarity': 0,\n",
    "        'max_negative_similarity': 0,\n",
    "        'positive_similarities': [],\n",
    "        'negative_similarities': []\n",
    "    }\n",
    "    \n",
    "    # Extract visual features from current image\n",
    "    try:\n",
    "        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = clip_model.get_image_features(**inputs)\n",
    "            features = features.cpu().numpy()\n",
    "            print(f\"  Raw features shape: {features.shape}\")\n",
    "            print(f\"  Raw features norm: {np.linalg.norm(features)}\")\n",
    "            \n",
    "            # Normalize features\n",
    "            features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "            print(f\"  Normalized features norm: {np.linalg.norm(features)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting features: {e}\")\n",
    "        return result\n",
    "    \n",
    "    # Check similarity to positive examples\n",
    "    if positive_features:\n",
    "        print(f\"  Checking against {len(positive_features)} positive examples\")\n",
    "        for i, pos_feat in enumerate(positive_features):\n",
    "            sim = cosine_similarity(features, pos_feat)[0][0]\n",
    "            result['positive_similarities'].append(sim)\n",
    "            print(f\"    Example {i}: similarity = {sim:.4f}\")\n",
    "        \n",
    "        result['max_positive_similarity'] = max(result['positive_similarities'])\n",
    "        is_like_positive = result['max_positive_similarity'] > similarity_threshold\n",
    "        print(f\"  Max positive similarity: {result['max_positive_similarity']:.4f}\")\n",
    "        print(f\"  Is like positive (>{similarity_threshold})? {is_like_positive}\")\n",
    "    else:\n",
    "        is_like_positive = False\n",
    "        print(\"  No positive features provided\")\n",
    "    \n",
    "    # For now, ignore negative examples to isolate the issue\n",
    "    is_not_like_negative = True\n",
    "    \n",
    "    # Decision: must be like positive AND not like negative\n",
    "    result['is_form'] = is_like_positive and is_not_like_negative\n",
    "    print(f\"  Final decision: {result['is_form']}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Test detection on the first example form\n",
    "print(\"Testing detection on the first example form:\")\n",
    "print(f\"File: {example_files[0]}\\n\")\n",
    "\n",
    "# Load the first example\n",
    "pdf = fitz.open(os.path.join(example_forms_dir, example_files[0]))\n",
    "page = pdf[0]\n",
    "pix = page.get_pixmap()\n",
    "test_img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "pdf.close()\n",
    "\n",
    "# Run detection\n",
    "result = detect_form_visual_clip_debug(\n",
    "    test_img, clip_model, clip_processor, device,\n",
    "    example_features, None, 0.7, 0.7\n",
    ")\n",
    "\n",
    "print(f\"\\nResult: {result['is_form']}\")\n",
    "print(f\"This should be True since we're testing an example against itself!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 7: Check if the issue is with feature dimensions\n",
    "print(\"Checking feature dimensions:\")\n",
    "for i, feat in enumerate(example_features[:3]):\n",
    "    print(f\"Example {i}: shape = {feat.shape}, dtype = {feat.dtype}\")\n",
    "    print(f\"  Min value: {feat.min():.4f}, Max value: {feat.max():.4f}\")\n",
    "    print(f\"  Mean: {feat.mean():.4f}, Std: {feat.std():.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 8: Try different similarity thresholds\n",
    "print(\"Testing different similarity thresholds:\\n\")\n",
    "\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for threshold in thresholds:\n",
    "    detected = 0\n",
    "    for i, example_file in enumerate(example_files[:5]):\n",
    "        # Load example\n",
    "        pdf = fitz.open(os.path.join(example_forms_dir, example_file))\n",
    "        page = pdf[0]\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        pdf.close()\n",
    "        \n",
    "        # Extract features\n",
    "        inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            features = clip_model.get_image_features(**inputs)\n",
    "            features = features.cpu().numpy()\n",
    "            features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "        \n",
    "        # Check similarity\n",
    "        max_sim = 0\n",
    "        for pos_feat in example_features:\n",
    "            sim = cosine_similarity(features, pos_feat)[0][0]\n",
    "            max_sim = max(max_sim, sim)\n",
    "        \n",
    "        if max_sim > threshold:\n",
    "            detected += 1\n",
    "    \n",
    "    print(f\"Threshold {threshold}: {detected}/5 examples detected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}