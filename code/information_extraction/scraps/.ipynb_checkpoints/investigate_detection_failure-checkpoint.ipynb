{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Why Zero-Shot Detection is Failing\n",
    "\n",
    "The debugging shows it should work, but in practice it's missing example forms.\n",
    "Let's dig deeper into what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CLIP model\n",
    "model_name = \"openai/clip-vit-large-patch14-336\"\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "clip_processor = CLIPProcessor.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "clip_model = clip_model.to(device)\n",
    "clip_model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ALL example forms and extract features\n",
    "example_forms_dir = \"../../data/raw/_exampleforms/\"\n",
    "example_files = [f for f in os.listdir(example_forms_dir) if f.endswith('.pdf')]\n",
    "print(f\"Found {len(example_files)} example forms\")\n",
    "\n",
    "example_features = []\n",
    "example_names = []\n",
    "\n",
    "for example_file in example_files:\n",
    "    try:\n",
    "        pdf_path = os.path.join(example_forms_dir, example_file)\n",
    "        pdf = fitz.open(pdf_path)\n",
    "        page = pdf[0]\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        pdf.close()\n",
    "        \n",
    "        # Extract features\n",
    "        inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            features = clip_model.get_image_features(**inputs)\n",
    "            features = features.cpu().numpy()\n",
    "            features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "            \n",
    "        example_features.append(features)\n",
    "        example_names.append(example_file)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {example_file}: {e}\")\n",
    "\n",
    "print(f\"Successfully loaded {len(example_features)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity matrix between all examples\n",
    "n_examples = len(example_features)\n",
    "similarity_matrix = np.zeros((n_examples, n_examples))\n",
    "\n",
    "for i in range(n_examples):\n",
    "    for j in range(n_examples):\n",
    "        sim = cosine_similarity(example_features[i], example_features[j])[0][0]\n",
    "        similarity_matrix[i, j] = sim\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(similarity_matrix, \n",
    "            xticklabels=[name[:15] for name in example_names],\n",
    "            yticklabels=[name[:15] for name in example_names],\n",
    "            annot=True, fmt='.2f', cmap='coolwarm',\n",
    "            vmin=0, vmax=1)\n",
    "plt.title(\"Similarity Matrix Between Example Forms\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistics\n",
    "np.fill_diagonal(similarity_matrix, np.nan)  # Exclude self-similarity\n",
    "avg_similarity = np.nanmean(similarity_matrix)\n",
    "min_similarity = np.nanmin(similarity_matrix)\n",
    "max_similarity = np.nanmax(similarity_matrix)\n",
    "\n",
    "print(f\"\\nExample forms similarity statistics:\")\n",
    "print(f\"Average similarity: {avg_similarity:.3f}\")\n",
    "print(f\"Min similarity: {min_similarity:.3f}\")\n",
    "print(f\"Max similarity: {max_similarity:.3f}\")\n",
    "print(f\"\\nIf examples are too diverse (low avg similarity), detection will be harder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test detection on each example against all others\n",
    "print(\"Testing each example against all others:\\n\")\n",
    "\n",
    "detection_results = []\n",
    "threshold = 0.7\n",
    "\n",
    "for i, (test_features, test_name) in enumerate(zip(example_features, example_names)):\n",
    "    # Create feature list excluding current example\n",
    "    other_features = example_features[:i] + example_features[i+1:]\n",
    "    \n",
    "    # Test similarity\n",
    "    similarities = []\n",
    "    for other_feat in other_features:\n",
    "        sim = cosine_similarity(test_features, other_feat)[0][0]\n",
    "        similarities.append(sim)\n",
    "    \n",
    "    max_sim = max(similarities) if similarities else 0\n",
    "    would_detect = max_sim > threshold\n",
    "    \n",
    "    detection_results.append({\n",
    "        'file': test_name,\n",
    "        'max_similarity': max_sim,\n",
    "        'would_detect': would_detect\n",
    "    })\n",
    "    \n",
    "    print(f\"{test_name[:30]:30s} | Max sim: {max_sim:.3f} | Detected: {would_detect}\")\n",
    "\n",
    "# Summary\n",
    "detected_count = sum(r['would_detect'] for r in detection_results)\n",
    "print(f\"\\nWith threshold {threshold}: {detected_count}/{len(detection_results)} examples would be detected\")\n",
    "print(f\"This suggests the threshold might be too high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "thresholds = np.arange(0.4, 0.9, 0.05)\n",
    "detection_rates = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    detected = 0\n",
    "    for i, test_features in enumerate(example_features):\n",
    "        other_features = example_features[:i] + example_features[i+1:]\n",
    "        if other_features:\n",
    "            max_sim = max(cosine_similarity(test_features, other_feat)[0][0] \n",
    "                         for other_feat in other_features)\n",
    "            if max_sim > thresh:\n",
    "                detected += 1\n",
    "    \n",
    "    detection_rate = detected / len(example_features)\n",
    "    detection_rates.append(detection_rate)\n",
    "    print(f\"Threshold {thresh:.2f}: {detection_rate:.1%} detection rate\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, detection_rates, 'b-o')\n",
    "plt.axhline(y=0.8, color='r', linestyle='--', label='80% target')\n",
    "plt.axvline(x=0.7, color='g', linestyle='--', label='Current threshold')\n",
    "plt.xlabel('Similarity Threshold')\n",
    "plt.ylabel('Detection Rate')\n",
    "plt.title('Detection Rate vs Threshold for Example Forms')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Find optimal threshold\n",
    "optimal_idx = np.argmax(np.array(detection_rates) >= 0.8)\n",
    "if detection_rates[optimal_idx] >= 0.8:\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"\\nOptimal threshold for 80% detection: {optimal_threshold:.2f}\")\n",
    "else:\n",
    "    print(\"\\nNo threshold achieves 80% detection rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some negative examples\n",
    "nonexample_dir = \"../../data/raw/_nonexamples/\"\n",
    "nonexample_features = []\n",
    "\n",
    "if os.path.exists(nonexample_dir):\n",
    "    nonexample_files = [f for f in os.listdir(nonexample_dir) if f.endswith('.pdf')][:5]  # Just first 5\n",
    "    \n",
    "    for nonexample_file in nonexample_files:\n",
    "        try:\n",
    "            pdf_path = os.path.join(nonexample_dir, nonexample_file)\n",
    "            pdf = fitz.open(pdf_path)\n",
    "            page = pdf[0]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            pdf.close()\n",
    "            \n",
    "            inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "            with torch.no_grad():\n",
    "                features = clip_model.get_image_features(**inputs)\n",
    "                features = features.cpu().numpy()\n",
    "                features = features / np.linalg.norm(features, axis=1, keepdims=True)\n",
    "                \n",
    "            nonexample_features.append(features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {nonexample_file}: {e}\")\n",
    "\n",
    "print(f\"Loaded {len(nonexample_features)} non-examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check similarity between examples and non-examples\n",
    "if nonexample_features:\n",
    "    print(\"Checking if examples are distinguishable from non-examples:\\n\")\n",
    "    \n",
    "    # For each example, find max similarity to non-examples\n",
    "    for i, (ex_feat, ex_name) in enumerate(zip(example_features[:5], example_names[:5])):\n",
    "        sims_to_nonexamples = []\n",
    "        for nonex_feat in nonexample_features:\n",
    "            sim = cosine_similarity(ex_feat, nonex_feat)[0][0]\n",
    "            sims_to_nonexamples.append(sim)\n",
    "        \n",
    "        max_sim_to_nonex = max(sims_to_nonexamples)\n",
    "        print(f\"Example {ex_name[:20]:20s} | Max sim to non-examples: {max_sim_to_nonex:.3f}\")\n",
    "    \n",
    "    print(\"\\nIf these values are high (>0.7), examples and non-examples are too similar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature statistics\n",
    "print(\"Analyzing feature characteristics:\\n\")\n",
    "\n",
    "# Stack all example features\n",
    "all_features = np.vstack(example_features)\n",
    "\n",
    "# Feature statistics\n",
    "print(f\"Feature dimensions: {all_features.shape}\")\n",
    "print(f\"Feature mean: {np.mean(all_features):.4f}\")\n",
    "print(f\"Feature std: {np.std(all_features):.4f}\")\n",
    "print(f\"Feature min: {np.min(all_features):.4f}\")\n",
    "print(f\"Feature max: {np.max(all_features):.4f}\")\n",
    "\n",
    "# Check if features are properly normalized\n",
    "norms = np.linalg.norm(all_features, axis=1)\n",
    "print(f\"\\nFeature norms: min={np.min(norms):.4f}, max={np.max(norms):.4f}\")\n",
    "print(f\"All normalized to 1.0: {np.allclose(norms, 1.0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try alternative similarity metrics\n",
    "print(\"Testing alternative similarity metrics:\\n\")\n",
    "\n",
    "# Pick two examples\n",
    "if len(example_features) >= 2:\n",
    "    feat1, feat2 = example_features[0], example_features[1]\n",
    "    \n",
    "    # Cosine similarity\n",
    "    cos_sim = cosine_similarity(feat1, feat2)[0][0]\n",
    "    print(f\"Cosine similarity: {cos_sim:.4f}\")\n",
    "    \n",
    "    # Euclidean distance\n",
    "    euclidean_dist = np.linalg.norm(feat1 - feat2)\n",
    "    print(f\"Euclidean distance: {euclidean_dist:.4f}\")\n",
    "    \n",
    "    # Dot product (same as cosine for normalized vectors)\n",
    "    dot_prod = np.dot(feat1.flatten(), feat2.flatten())\n",
    "    print(f\"Dot product: {dot_prod:.4f}\")\n",
    "    \n",
    "    print(\"\\nFor normalized vectors, cosine similarity = dot product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendation\n",
    "print(\"=== RECOMMENDATIONS ===\")\n",
    "print(\"\\nBased on the analysis:\")\n",
    "\n",
    "if avg_similarity < 0.6:\n",
    "    print(\"1. Your example forms are too diverse. Consider:\")\n",
    "    print(\"   - Grouping similar forms together\")\n",
    "    print(\"   - Creating separate detectors for different form types\")\n",
    "    print(\"   - Adding more examples of each type\")\n",
    "\n",
    "if optimal_threshold < 0.7:\n",
    "    print(f\"\\n2. Lower the similarity threshold to {optimal_threshold:.2f}\")\n",
    "    \n",
    "if len(example_features) < 10:\n",
    "    print(\"\\n3. Add more example forms. You currently have too few examples.\")\n",
    "\n",
    "print(\"\\n4. Alternative approaches to consider:\")\n",
    "print(\"   - Fine-tune CLIP on your specific forms\")\n",
    "print(\"   - Use a document-specific model like LayoutLMv3\")\n",
    "print(\"   - Combine visual features with text detection\")\n",
    "print(\"   - Use traditional CV methods (template matching, edge detection)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}