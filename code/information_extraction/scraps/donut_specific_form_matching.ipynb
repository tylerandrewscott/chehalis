{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specific Form Type Detection using Donut\n",
    "\n",
    "This notebook uses Donut to detect a specific type of form (as represented by examples in `_exampleforms`),\n",
    "not just any form. We'll use Donut's ability to extract features and compare documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 193450 PDF files to process\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "\n",
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "# Paths\n",
    "pdf_dir = \"../../data/raw/_contracts/\"\n",
    "formpage_dir = \"../../data/raw/_formpage/\"\n",
    "example_forms_dir = \"../../data/raw/_exampleforms/\"\n",
    "nonexample_forms_dir = \"../../data/raw/_nonexamples/\"\n",
    "\n",
    "os.makedirs(formpage_dir, exist_ok=True)\n",
    "\n",
    "pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith('.pdf')]\n",
    "print(f\"Found {len(pdf_files)} PDF files to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Donut model for feature extraction...\n",
      "Model loaded on mps\n"
     ]
    }
   ],
   "source": [
    "# Load Donut model\n",
    "print(\"Loading Donut model for feature extraction...\")\n",
    "\n",
    "# Load the base Donut model (not fine-tuned for any specific task)\n",
    "model_name = \"naver-clova-ix/donut-base\"\n",
    "processor = DonutProcessor.from_pretrained(model_name)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Load vision encoder directly for better feature extraction\n",
    "def extract_donut_features_v2(image, processor, model, device):\n",
    "    \"\"\"\n",
    "    Alternative feature extraction that might work better\n",
    "    \"\"\"\n",
    "    # Process image\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    \n",
    "    # Get encoder outputs\n",
    "    with torch.no_grad():\n",
    "        # Try different pooling strategies\n",
    "        encoder_outputs = model.encoder(pixel_values)\n",
    "        \n",
    "        # Option 1: Global average pooling\n",
    "        features_avg = encoder_outputs.last_hidden_state.mean(dim=[1, 2])  # Average over spatial dimensions\n",
    "        \n",
    "        # Option 2: Use pooler output if available\n",
    "        if hasattr(encoder_outputs, 'pooler_output') and encoder_outputs.pooler_output is not None:\n",
    "            features_pooler = encoder_outputs.pooler_output\n",
    "        else:\n",
    "            features_pooler = features_avg\n",
    "        \n",
    "        # Use average pooling\n",
    "        features = features_avg.cpu().numpy()\n",
    "        \n",
    "        # L2 normalize\n",
    "        features = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-6)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Keep original function but add v2\n",
    "def extract_donut_features(image, processor, model, device):\n",
    "    \"\"\"\n",
    "    Extract visual features from document using Donut's vision encoder\n",
    "    \"\"\"\n",
    "    # Process image\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    \n",
    "    # Extract features from the encoder (Swin Transformer)\n",
    "    with torch.no_grad():\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = model.encoder(pixel_values)\n",
    "        # Use the last hidden states and pool them\n",
    "        features = encoder_outputs.last_hidden_state.mean(dim=1)\n",
    "        features = features.cpu().numpy()\n",
    "        # Normalize\n",
    "        features = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-6)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract visual features using Donut's encoder\n",
    "def extract_donut_features(image, processor, model, device):\n",
    "    \"\"\"\n",
    "    Extract visual features from document using Donut's vision encoder\n",
    "    \"\"\"\n",
    "    # Process image\n",
    "    pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    \n",
    "    # Extract features from the encoder (Swin Transformer)\n",
    "    with torch.no_grad():\n",
    "        # Get encoder outputs\n",
    "        encoder_outputs = model.encoder(pixel_values)\n",
    "        \n",
    "        # Get the shape of the hidden states\n",
    "        hidden_states = encoder_outputs.last_hidden_state\n",
    "        \n",
    "        # Check dimensions before pooling\n",
    "        if len(hidden_states.shape) == 4:  # [batch, height, width, channels]\n",
    "            # Mean pool over spatial dimensions (height and width)\n",
    "            features = hidden_states.mean(dim=[1, 2])\n",
    "        elif len(hidden_states.shape) == 3:  # [batch, sequence, features]\n",
    "            # Mean pool over sequence dimension\n",
    "            features = hidden_states.mean(dim=1)\n",
    "        else:\n",
    "            # Fallback: flatten and take mean\n",
    "            features = hidden_states.flatten(start_dim=1).mean(dim=1, keepdim=True)\n",
    "        \n",
    "        features = features.cpu().numpy()\n",
    "        \n",
    "        # L2 normalize\n",
    "        if len(features.shape) == 1:\n",
    "            features = features.reshape(1, -1)\n",
    "        norm = np.linalg.norm(features, axis=1, keepdims=True)\n",
    "        features = features / (norm + 1e-6)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking encoder output shape...\n",
      "Encoder output shape: torch.Size([1, 4800, 1024])\n",
      "Number of dimensions: 3\n",
      "Extracted features shape: (1, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check encoder output shape\n",
    "print(\"Checking encoder output shape...\")\n",
    "\n",
    "# Test with a dummy image\n",
    "test_img = Image.new('RGB', (224, 224), color='white')\n",
    "pixel_values = processor(test_img, return_tensors=\"pt\").pixel_values\n",
    "pixel_values = pixel_values.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoder_outputs = model.encoder(pixel_values)\n",
    "    print(f\"Encoder output shape: {encoder_outputs.last_hidden_state.shape}\")\n",
    "    print(f\"Number of dimensions: {len(encoder_outputs.last_hidden_state.shape)}\")\n",
    "    \n",
    "# Test feature extraction\n",
    "test_features = extract_donut_features(test_img, processor, model, device)\n",
    "print(f\"Extracted features shape: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell has been removed - features are re-extracted in the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading example forms (specific type we're looking for)...\n",
      "Found 74 example forms of the specific type\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing examples: 100%|██████████████████████| 74/74 [01:51<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 74 example features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load example forms and extract their features\n",
    "print(\"Loading example forms (specific type we're looking for)...\")\n",
    "\n",
    "example_features = []\n",
    "example_names = []\n",
    "\n",
    "if os.path.exists(example_forms_dir):\n",
    "    example_files = [f for f in os.listdir(example_forms_dir) if f.endswith('.pdf')]\n",
    "    print(f\"Found {len(example_files)} example forms of the specific type\")\n",
    "    \n",
    "    for example_file in tqdm(example_files, desc=\"Processing examples\"):\n",
    "        try:\n",
    "            pdf_path = os.path.join(example_forms_dir, example_file)\n",
    "            pdf = fitz.open(pdf_path)\n",
    "            page = pdf[0]  # First page only\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            pdf.close()\n",
    "            \n",
    "            # Extract features\n",
    "            features = extract_donut_features(img, processor, model, device)\n",
    "            example_features.append(features)\n",
    "            example_names.append(example_file)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {example_file}: {e}\")\n",
    "    \n",
    "    print(f\"Successfully loaded {len(example_features)} example features\")\n",
    "else:\n",
    "    print(f\"No example forms found at {example_forms_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading non-examples (other document types)...\n",
      "Found 11 non-example documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing non-examples: 100%|██████████████████| 11/11 [00:16<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11 non-example features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load non-examples (different types of documents)\n",
    "print(\"\\nLoading non-examples (other document types)...\")\n",
    "\n",
    "nonexample_features = []\n",
    "\n",
    "if os.path.exists(nonexample_forms_dir):\n",
    "    nonexample_files = [f for f in os.listdir(nonexample_forms_dir) if f.endswith('.pdf')]\n",
    "    print(f\"Found {len(nonexample_files)} non-example documents\")\n",
    "    \n",
    "    # Process first page of each non-example\n",
    "    for nonexample_file in tqdm(nonexample_files, desc=\"Processing non-examples\"):  # Limit to 10\n",
    "        try:\n",
    "            pdf_path = os.path.join(nonexample_forms_dir, nonexample_file)\n",
    "            pdf = fitz.open(pdf_path)\n",
    "            \n",
    "            # Just use first page of non-examples\n",
    "            page = pdf[0]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            \n",
    "            features = extract_donut_features(img, processor, model, device)\n",
    "            nonexample_features.append(features)\n",
    "            \n",
    "            pdf.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {nonexample_file}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len(nonexample_features)} non-example features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing similarity between example forms...\n",
      "Example-to-example similarity:\n",
      "  Average: 0.990\n",
      "  Min: 0.940\n",
      "  Max: 1.000\n",
      "\n",
      "Suggested threshold: 0.752\n"
     ]
    }
   ],
   "source": [
    "# Analyze similarity between examples\n",
    "if len(example_features) > 1:\n",
    "    print(\"\\nAnalyzing similarity between example forms...\")\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(len(example_features)):\n",
    "        for j in range(i+1, len(example_features)):\n",
    "            sim = cosine_similarity(example_features[i], example_features[j])[0][0]\n",
    "            similarities.append(sim)\n",
    "    \n",
    "    avg_similarity = np.mean(similarities)\n",
    "    min_similarity = np.min(similarities)\n",
    "    max_similarity = np.max(similarities)\n",
    "    \n",
    "    print(f\"Example-to-example similarity:\")\n",
    "    print(f\"  Average: {avg_similarity:.3f}\")\n",
    "    print(f\"  Min: {min_similarity:.3f}\")\n",
    "    print(f\"  Max: {max_similarity:.3f}\")\n",
    "    \n",
    "    # Suggest threshold - use a lower threshold since we're looking for specific forms\n",
    "    suggested_threshold = min_similarity * 0.8  # 80% of minimum similarity\n",
    "    print(f\"\\nSuggested threshold: {suggested_threshold:.3f}\")\n",
    "else:\n",
    "    suggested_threshold = 0.7  # Default threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detection function for specific form type\n",
    "def detect_specific_form_type(image, processor, model, device, \n",
    "                             example_features, nonexample_features=None,\n",
    "                             similarity_threshold=0.7, negative_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Detect if a page is the specific form type represented by examples\n",
    "    \"\"\"\n",
    "    # Extract features from the page\n",
    "    page_features = extract_donut_features(image, processor, model, device)\n",
    "    \n",
    "    # Compare to positive examples\n",
    "    positive_similarities = []\n",
    "    for ex_feat in example_features:\n",
    "        sim = cosine_similarity(page_features, ex_feat)[0][0]\n",
    "        positive_similarities.append(sim)\n",
    "    \n",
    "    max_positive_sim = max(positive_similarities) if positive_similarities else 0\n",
    "    avg_positive_sim = np.mean(positive_similarities) if positive_similarities else 0\n",
    "    \n",
    "    # Compare to negative examples if provided\n",
    "    if nonexample_features:\n",
    "        negative_similarities = []\n",
    "        for neg_feat in nonexample_features:\n",
    "            sim = cosine_similarity(page_features, neg_feat)[0][0]\n",
    "            negative_similarities.append(sim)\n",
    "        max_negative_sim = max(negative_similarities) if negative_similarities else 0\n",
    "        avg_negative_sim = np.mean(negative_similarities) if negative_similarities else 0\n",
    "    else:\n",
    "        max_negative_sim = 0\n",
    "        avg_negative_sim = 0\n",
    "    \n",
    "    # Decision logic: must be similar to examples\n",
    "    is_specific_form = max_positive_sim > similarity_threshold\n",
    "    \n",
    "    # Additional check: if too similar to non-examples relative to examples, reject\n",
    "    if nonexample_features and max_negative_sim > 0:\n",
    "        # Only reject if negative similarity is very close to positive similarity\n",
    "        similarity_ratio = max_positive_sim / (max_negative_sim + 1e-6)\n",
    "        if similarity_ratio < 1.2:  # Less than 20% more similar to positives than negatives\n",
    "            is_specific_form = False\n",
    "    \n",
    "    # Confidence based on:\n",
    "    # 1. How similar to positive examples\n",
    "    # 2. How much more similar to positives than negatives\n",
    "    if nonexample_features and len(negative_similarities) > 0:\n",
    "        # Confidence is high when positive sim is high AND negative sim is low\n",
    "        confidence = max_positive_sim * (1 - max_negative_sim)\n",
    "    else:\n",
    "        confidence = max_positive_sim\n",
    "    \n",
    "    return {\n",
    "        'is_specific_form': is_specific_form,\n",
    "        'confidence': confidence,\n",
    "        'max_similarity_to_examples': max_positive_sim,\n",
    "        'avg_similarity_to_examples': avg_positive_sim,\n",
    "        'max_similarity_to_nonexamples': max_negative_sim\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING FEATURE EXTRACTION ===\n",
      "\n",
      "Testing with: 25581-000.pdf\n",
      "Stored feature shape: (1, 1024)\n",
      "New feature shape: (1, 1024)\n",
      "Self-similarity (should be 1.0): 1.000000\n",
      "Stored vs new extraction (should be 1.0): 1.000000\n",
      "\n",
      "Similarity to all stored examples:\n",
      "  Example 0: 1.000000\n",
      "  Example 1: 0.998013\n",
      "  Example 2: 0.996304\n",
      "  Example 3: 0.999286\n",
      "  Example 4: 0.992019\n",
      "\n",
      "Feature statistics:\n",
      "  Stored - Min: -0.9341, Max: 0.1705, Mean: -0.0010\n",
      "  New    - Min: -0.9341, Max: 0.1705, Mean: -0.0010\n",
      "\n",
      "Normalization check:\n",
      "  Stored norm: 1.000000\n",
      "  New norm: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check if features are being extracted correctly\n",
    "print(\"=== DEBUGGING FEATURE EXTRACTION ===\\n\")\n",
    "\n",
    "# Test with first example\n",
    "if len(example_features) > 0 and len(example_names) > 0:\n",
    "    test_file = example_names[0]\n",
    "    test_feat_stored = example_features[0]\n",
    "    \n",
    "    # Re-load and re-extract features for the same file\n",
    "    pdf_path = os.path.join(example_forms_dir, test_file)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    page = pdf[0]\n",
    "    pix = page.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    pdf.close()\n",
    "    \n",
    "    # Extract features again\n",
    "    test_feat_new = extract_donut_features(img, processor, model, device)\n",
    "    \n",
    "    # Compare\n",
    "    print(f\"Testing with: {test_file}\")\n",
    "    print(f\"Stored feature shape: {test_feat_stored.shape}\")\n",
    "    print(f\"New feature shape: {test_feat_new.shape}\")\n",
    "    \n",
    "    # Self-similarity (should be 1.0)\n",
    "    self_similarity = cosine_similarity(test_feat_new, test_feat_new)[0][0]\n",
    "    print(f\"Self-similarity (should be 1.0): {self_similarity:.6f}\")\n",
    "    \n",
    "    # Similarity between stored and new extraction (should be 1.0)\n",
    "    stored_vs_new = cosine_similarity(test_feat_stored, test_feat_new)[0][0]\n",
    "    print(f\"Stored vs new extraction (should be 1.0): {stored_vs_new:.6f}\")\n",
    "    \n",
    "    # Check against all stored features\n",
    "    print(f\"\\nSimilarity to all stored examples:\")\n",
    "    for i, ex_feat in enumerate(example_features[:5]):\n",
    "        sim = cosine_similarity(test_feat_new, ex_feat)[0][0]\n",
    "        print(f\"  Example {i}: {sim:.6f}\")\n",
    "    \n",
    "    # Check feature statistics\n",
    "    print(f\"\\nFeature statistics:\")\n",
    "    print(f\"  Stored - Min: {test_feat_stored.min():.4f}, Max: {test_feat_stored.max():.4f}, Mean: {test_feat_stored.mean():.4f}\")\n",
    "    print(f\"  New    - Min: {test_feat_new.min():.4f}, Max: {test_feat_new.max():.4f}, Mean: {test_feat_new.mean():.4f}\")\n",
    "    \n",
    "    # Check normalization\n",
    "    print(f\"\\nNormalization check:\")\n",
    "    print(f\"  Stored norm: {np.linalg.norm(test_feat_stored):.6f}\")\n",
    "    print(f\"  New norm: {np.linalg.norm(test_feat_new):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DEBUGGING DETECTION FUNCTION ===\n",
      "\n",
      "Testing detection on: 25581-000.pdf\n",
      "Threshold: 0.7523807525634766\n",
      "\\nPage features shape: (1, 1024)\n",
      "Page features norm: 1.000000\n",
      "\\nComparing to 74 examples:\n",
      "  Example 0: 1.000000 *\n",
      "  Example 1: 0.998013 \n",
      "  Example 2: 0.996304 \n",
      "  Example 3: 0.999286 \n",
      "  Example 4: 0.992019 \n",
      "\\nMax similarity: 1.000000\n",
      "Is above threshold (0.752)? True\n",
      "\\nExpected ~1.0 for first example, got: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# Debug the detection function itself\n",
    "print(\"\\n=== DEBUGGING DETECTION FUNCTION ===\\n\")\n",
    "\n",
    "if len(example_features) > 0:\n",
    "    # Load first example\n",
    "    test_file = example_names[0]\n",
    "    pdf_path = os.path.join(example_forms_dir, test_file)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    page = pdf[0]\n",
    "    pix = page.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    pdf.close()\n",
    "    \n",
    "    # Manual detection steps\n",
    "    print(f\"Testing detection on: {test_file}\")\n",
    "    print(f\"Threshold: {suggested_threshold}\")\n",
    "    \n",
    "    # Extract features\n",
    "    page_features = extract_donut_features(img, processor, model, device)\n",
    "    print(f\"\\\\nPage features shape: {page_features.shape}\")\n",
    "    print(f\"Page features norm: {np.linalg.norm(page_features):.6f}\")\n",
    "    \n",
    "    # Compare to each example\n",
    "    print(f\"\\\\nComparing to {len(example_features)} examples:\")\n",
    "    similarities = []\n",
    "    for i, ex_feat in enumerate(example_features):\n",
    "        sim = cosine_similarity(page_features, ex_feat)[0][0]\n",
    "        similarities.append(sim)\n",
    "        if i < 5:  # Show first 5\n",
    "            print(f\"  Example {i}: {sim:.6f} {'*' if i == 0 else ''}\")  # Mark if it's comparing to itself\n",
    "    \n",
    "    max_sim = max(similarities)\n",
    "    print(f\"\\\\nMax similarity: {max_sim:.6f}\")\n",
    "    print(f\"Is above threshold ({suggested_threshold:.3f})? {max_sim > suggested_threshold}\")\n",
    "    \n",
    "    # The first example should have similarity ~1.0 to itself\n",
    "    print(f\"\\\\nExpected ~1.0 for first example, got: {similarities[0]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CHECKING SIMILARITY TO NON-EXAMPLES ===\n",
      "\n",
      "Testing 25581-000.pdf against non-examples:\n",
      "  Non-example 0: 0.942\n",
      "  Non-example 1: 0.972\n",
      "  Non-example 2: 0.987\n",
      "  Non-example 3: 0.982\n",
      "  Non-example 4: 0.969\n",
      "  Non-example 5: 0.967\n",
      "  Non-example 6: 0.970\n",
      "  Non-example 7: 0.971\n",
      "  Non-example 8: 0.968\n",
      "  Non-example 9: 0.970\n",
      "  Non-example 10: 0.969\n",
      "\n",
      "\n",
      "Checking first non-example against examples:\n",
      "  Example 0: 0.942\n",
      "  Example 1: 0.937\n",
      "  Example 2: 0.942\n",
      "  Example 3: 0.944\n",
      "  Example 4: 0.935\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check similarity to non-examples\n",
    "print(\"\\n=== CHECKING SIMILARITY TO NON-EXAMPLES ===\\n\")\n",
    "\n",
    "if len(example_features) > 0 and len(nonexample_features) > 0:\n",
    "    # Test first example against non-examples\n",
    "    test_file = example_names[0]\n",
    "    pdf_path = os.path.join(example_forms_dir, test_file)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    page = pdf[0]\n",
    "    pix = page.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    pdf.close()\n",
    "    \n",
    "    # Extract features\n",
    "    test_features = extract_donut_features(img, processor, model, device)\n",
    "    \n",
    "    print(f\"Testing {test_file} against non-examples:\")\n",
    "    \n",
    "    # Check against non-examples\n",
    "    for i, neg_feat in enumerate(nonexample_features):\n",
    "        sim = cosine_similarity(test_features, neg_feat)[0][0]\n",
    "        print(f\"  Non-example {i}: {sim:.3f}\")\n",
    "    \n",
    "    # Also check an actual non-example against examples\n",
    "    print(\"\\n\\nChecking first non-example against examples:\")\n",
    "    for i, ex_feat in enumerate(example_features[:5]):\n",
    "        sim = cosine_similarity(nonexample_features[0], ex_feat)[0][0]\n",
    "        print(f\"  Example {i}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing detection on example forms (should all be detected)...\n",
      "\n",
      "25581-000.pdf:\n",
      "  Detected: False\n",
      "  Max similarity: 1.000\n",
      "  Confidence: 0.013\n",
      "\n",
      "99171-000.pdf:\n",
      "  Detected: False\n",
      "  Max similarity: 1.000\n",
      "  Confidence: 0.015\n",
      "\n",
      "13924-002.pdf:\n",
      "  Detected: False\n",
      "  Max similarity: 1.000\n",
      "  Confidence: 0.018\n",
      "\n",
      "1197-000.pdf:\n",
      "  Detected: False\n",
      "  Max similarity: 1.000\n",
      "  Confidence: 0.014\n",
      "\n",
      "67419-000.pdf:\n",
      "  Detected: False\n",
      "  Max similarity: 1.000\n",
      "  Confidence: 0.022\n"
     ]
    }
   ],
   "source": [
    "# Test on example forms themselves\n",
    "print(\"\\nTesting detection on example forms (should all be detected)...\")\n",
    "\n",
    "threshold = suggested_threshold if 'suggested_threshold' in locals() else 0.5\n",
    "\n",
    "for i, (example_file, example_feat) in enumerate(zip(example_names[:5], example_features[:5])):\n",
    "    # Load the image\n",
    "    pdf_path = os.path.join(example_forms_dir, example_file)\n",
    "    pdf = fitz.open(pdf_path)\n",
    "    page = pdf[0]\n",
    "    pix = page.get_pixmap()\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    pdf.close()\n",
    "    \n",
    "    # Test detection\n",
    "    result = detect_specific_form_type(\n",
    "        img, processor, model, device,\n",
    "        example_features, nonexample_features,\n",
    "        similarity_threshold=threshold\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{example_file}:\")\n",
    "    print(f\"  Detected: {result['is_specific_form']}\")\n",
    "    print(f\"  Max similarity: {result['max_similarity_to_examples']:.3f}\")\n",
    "    print(f\"  Confidence: {result['confidence']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process PDFs to find specific form type\n",
    "def process_pdfs_for_specific_form(pdf_files, pdf_dir, formpage_dir, \n",
    "                                  processor, model, device,\n",
    "                                  example_features, nonexample_features=None,\n",
    "                                  similarity_threshold=0.7, max_files=None):\n",
    "    \"\"\"\n",
    "    Process PDFs to find pages matching the specific form type\n",
    "    \"\"\"\n",
    "    if max_files:\n",
    "        pdf_files = pdf_files[:max_files]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for pdf_file in tqdm(pdf_files, desc=\"Processing PDFs\"):\n",
    "        try:\n",
    "            pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "            \n",
    "            best_match_page = None\n",
    "            best_similarity = 0\n",
    "            best_confidence = 0\n",
    "            page_results = []\n",
    "            \n",
    "            # Check each page\n",
    "            for page_num in range(len(pdf_document)):\n",
    "                page = pdf_document[page_num]\n",
    "                pix = page.get_pixmap()\n",
    "                img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "                \n",
    "                # Detect specific form type\n",
    "                detection = detect_specific_form_type(\n",
    "                    img, processor, model, device,\n",
    "                    example_features, nonexample_features,\n",
    "                    similarity_threshold\n",
    "                )\n",
    "                \n",
    "                page_results.append({\n",
    "                    'page': page_num + 1,\n",
    "                    'is_specific_form': detection['is_specific_form'],\n",
    "                    'similarity': detection['max_similarity_to_examples'],\n",
    "                    'confidence': detection['confidence']\n",
    "                })\n",
    "                \n",
    "                # Track best matching page\n",
    "                if detection['is_specific_form'] and detection['max_similarity_to_examples'] > best_similarity:\n",
    "                    best_similarity = detection['max_similarity_to_examples']\n",
    "                    best_confidence = detection['confidence']\n",
    "                    best_match_page = page_num\n",
    "                    \n",
    "                    # Stop early if very high similarity\n",
    "                    if best_similarity > 0.95:\n",
    "                        break\n",
    "            \n",
    "            # Store results\n",
    "            result = {\n",
    "                'file': pdf_file,\n",
    "                'total_pages': len(pdf_document),\n",
    "                'has_specific_form': best_match_page is not None,\n",
    "                'best_match_page': best_match_page + 1 if best_match_page is not None else None,\n",
    "                'best_similarity': best_similarity,\n",
    "                'confidence': best_confidence\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "            # Extract best matching page if found\n",
    "            if best_match_page is not None:\n",
    "                output_pdf = fitz.open()\n",
    "                output_pdf.insert_pdf(pdf_document, from_page=best_match_page, to_page=best_match_page)\n",
    "                \n",
    "                output_path = os.path.join(formpage_dir, pdf_file)\n",
    "                output_pdf.save(output_path)\n",
    "                output_pdf.close()\n",
    "            \n",
    "            pdf_document.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing {pdf_file}: {str(e)}\")\n",
    "            results.append({\n",
    "                'file': pdf_file,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a test batch\n",
    "print(\"\\nProcessing first 10 PDFs to find specific form type...\")\n",
    "\n",
    "results = process_pdfs_for_specific_form(\n",
    "    pdf_files[:10],\n",
    "    pdf_dir,\n",
    "    formpage_dir,\n",
    "    processor,\n",
    "    model,\n",
    "    device,\n",
    "    example_features,\n",
    "    nonexample_features,\n",
    "    similarity_threshold=threshold\n",
    ")\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\nProcessed {len(results_df)} PDFs\")\n",
    "print(f\"Found {results_df['has_specific_form'].sum()} PDFs with the specific form type\")\n",
    "\n",
    "# Show results\n",
    "print(\"\\nResults:\")\n",
    "for _, row in results_df.iterrows():\n",
    "    if 'error' not in row:\n",
    "        if row['has_specific_form']:\n",
    "            print(f\"{row['file']}: Found on page {row['best_match_page']} (similarity: {row['best_similarity']:.3f})\")\n",
    "        else:\n",
    "            print(f\"{row['file']}: Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "output_path = '../../data/intermediate_products/donut_specific_form_detection.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nResults saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full processing\n",
    "\"\"\"\n",
    "print(\"\\n=== PROCESSING ALL PDFs FOR SPECIFIC FORM TYPE ===\")\n",
    "print(f\"Looking for forms similar to the {len(example_features)} examples\")\n",
    "print(f\"Using similarity threshold: {threshold:.3f}\")\n",
    "\n",
    "all_results = process_pdfs_for_specific_form(\n",
    "    pdf_files,\n",
    "    pdf_dir,\n",
    "    formpage_dir,\n",
    "    processor,\n",
    "    model,\n",
    "    device,\n",
    "    example_features,\n",
    "    nonexample_features,\n",
    "    similarity_threshold=threshold\n",
    ")\n",
    "\n",
    "# Save results\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "all_results_df.to_csv('../../data/intermediate_products/donut_specific_form_all.csv', index=False)\n",
    "\n",
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Total processed: {len(all_results_df)}\")\n",
    "print(f\"Found specific form type in: {all_results_df['has_specific_form'].sum()} documents\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach Summary\n",
    "\n",
    "This notebook uses Donut's vision encoder to:\n",
    "1. Extract visual features from your specific example forms\n",
    "2. Compare new documents against these examples\n",
    "3. Find pages that match your specific form type (not just any form)\n",
    "\n",
    "### Key Differences:\n",
    "- **Not asking \"is this a form?\"** - Instead asking \"is this like my example forms?\"\n",
    "- **Uses similarity matching** - Compares visual features to examples\n",
    "- **Handles non-examples** - Can reject documents that are forms but not your type\n",
    "\n",
    "### Advantages:\n",
    "- No need to describe the form in words\n",
    "- Learns from your examples\n",
    "- Can distinguish between different form types\n",
    "- Uses Donut's document understanding capabilities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
