{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textract EDS Adapter\n",
    "\n",
    "This notebook processes PDF documents using AWS Textract with a custom adapter. It:\n",
    "1. Reads the zero-shot results CSV to identify documents with forms\n",
    "2. Extracts the lowest page number from each document's form_pages\n",
    "3. Sends individual pages to Textract using the custom adapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "CSV_PATH = \"../../code/preprocessing/zero_shot_results_full_corpus.csv\"\n",
    "CONTRACTS_DIR = \"../../data/raw/_contracts/\"\n",
    "\n",
    "# AWS Textract configuration\n",
    "REGION_NAME = \"us-east-1\"  # Update with your region\n",
    "CUSTOM_ADAPTER_ID = \"your-custom-adapter-id\"  # Update with your custom adapter ID\n",
    "\n",
    "# Initialize AWS client\n",
    "textract_client = boto3.client('textract', region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Total documents in CSV: {len(df)}\")\n",
    "\n",
    "# Filter for documents containing forms\n",
    "forms_df = df[df['contains_form'] == True].copy()\n",
    "print(f\"Documents with forms: {len(forms_df)}\")\n",
    "\n",
    "# Display sample of filtered data\n",
    "print(\"\\nSample of documents with forms:\")\n",
    "print(forms_df[['filename', 'form_pages', 'num_form_pages']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowest_page_number(form_pages_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract the lowest page number from the form_pages string.\n",
    "    \n",
    "    Args:\n",
    "        form_pages_str: String containing page numbers (e.g., \"1,2,4,10,15,16\" or \"5\")\n",
    "    \n",
    "    Returns:\n",
    "        int: The lowest page number\n",
    "    \"\"\"\n",
    "    if pd.isna(form_pages_str) or form_pages_str == \"\":\n",
    "        return None\n",
    "    \n",
    "    # Handle both single numbers and comma-separated lists\n",
    "    if ',' in str(form_pages_str):\n",
    "        page_numbers = [int(x.strip()) for x in str(form_pages_str).split(',')]\n",
    "    else:\n",
    "        page_numbers = [int(str(form_pages_str).strip())]\n",
    "    \n",
    "    return min(page_numbers)\n",
    "\n",
    "def extract_single_page_pdf(pdf_path: str, page_number: int) -> bytes:\n",
    "    \"\"\"\n",
    "    Extract a single page from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        page_number: Page number to extract (1-indexed)\n",
    "    \n",
    "    Returns:\n",
    "        bytes: PDF content of the single page\n",
    "    \"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "        \n",
    "        # PyPDF2 uses 0-based indexing, so subtract 1\n",
    "        pdf_writer.add_page(pdf_reader.pages[page_number - 1])\n",
    "        \n",
    "        output_buffer = BytesIO()\n",
    "        pdf_writer.write(output_buffer)\n",
    "        return output_buffer.getvalue()\n",
    "\n",
    "def process_with_textract(pdf_bytes: bytes, adapter_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a PDF page with Textract using a custom adapter.\n",
    "    \n",
    "    Args:\n",
    "        pdf_bytes: PDF content as bytes\n",
    "        adapter_id: Custom adapter ID\n",
    "    \n",
    "    Returns:\n",
    "        dict: Textract response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = textract_client.analyze_document(\n",
    "            Document={'Bytes': pdf_bytes},\n",
    "            FeatureTypes=['FORMS', 'TABLES'],\n",
    "            AdaptersConfig={\n",
    "                'Adapters': [\n",
    "                    {\n",
    "                        'AdapterId': adapter_id,\n",
    "                        'Version': '1'  # Adjust version as needed\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with Textract: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add lowest page number to dataframe\n",
    "forms_df['lowest_page'] = forms_df['form_pages'].apply(get_lowest_page_number)\n",
    "\n",
    "# Remove rows where we couldn't determine the lowest page\n",
    "forms_df = forms_df.dropna(subset=['lowest_page'])\n",
    "forms_df['lowest_page'] = forms_df['lowest_page'].astype(int)\n",
    "\n",
    "print(f\"Documents with valid page numbers: {len(forms_df)}\")\n",
    "print(\"\\nSample with lowest page numbers:\")\n",
    "print(forms_df[['filename', 'form_pages', 'lowest_page']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each document\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "for idx, row in forms_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    lowest_page = row['lowest_page']\n",
    "    \n",
    "    pdf_path = os.path.join(CONTRACTS_DIR, filename)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(pdf_path):\n",
    "        error_msg = f\"File not found: {filename}\"\n",
    "        print(error_msg)\n",
    "        errors.append({'filename': filename, 'error': error_msg})\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing {filename}, page {lowest_page}...\")\n",
    "        \n",
    "        # Extract the specific page\n",
    "        page_pdf_bytes = extract_single_page_pdf(pdf_path, lowest_page)\n",
    "        \n",
    "        # Process with Textract\n",
    "        textract_response = process_with_textract(page_pdf_bytes, CUSTOM_ADAPTER_ID)\n",
    "        \n",
    "        if textract_response:\n",
    "            result = {\n",
    "                'filename': filename,\n",
    "                'page_number': lowest_page,\n",
    "                'textract_response': textract_response,\n",
    "                'status': 'success'\n",
    "            }\n",
    "            results.append(result)\n",
    "            print(f\"✓ Successfully processed {filename}\")\n",
    "        else:\n",
    "            error_msg = f\"Textract processing failed for {filename}\"\n",
    "            print(f\"✗ {error_msg}\")\n",
    "            errors.append({'filename': filename, 'error': error_msg})\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing {filename}: {str(e)}\"\n",
    "        print(f\"✗ {error_msg}\")\n",
    "        errors.append({'filename': filename, 'error': error_msg})\n",
    "\n",
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Successfully processed: {len(results)} documents\")\n",
    "print(f\"Errors: {len(errors)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(\"textract_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save successful results\n",
    "if results:\n",
    "    # Save individual JSON files for each result\n",
    "    for result in results:\n",
    "        filename_base = Path(result['filename']).stem\n",
    "        json_filename = f\"{filename_base}_page_{result['page_number']}_textract.json\"\n",
    "        json_path = output_dir / json_filename\n",
    "        \n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(result['textract_response'], f, indent=2, default=str)\n",
    "    \n",
    "    # Save summary of all results\n",
    "    summary = {\n",
    "        'processed_count': len(results),\n",
    "        'error_count': len(errors),\n",
    "        'processed_files': [{\n",
    "            'filename': r['filename'],\n",
    "            'page_number': r['page_number'],\n",
    "            'json_file': f\"{Path(r['filename']).stem}_page_{r['page_number']}_textract.json\"\n",
    "        } for r in results]\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / 'processing_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "# Save errors if any\n",
    "if errors:\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    errors_df.to_csv(output_dir / 'processing_errors.csv', index=False)\n",
    "    print(f\"Errors saved to: {output_dir / 'processing_errors.csv'}\")\n",
    "\n",
    "print(f\"Results saved to: {output_dir}\")\n",
    "print(f\"Individual JSON files: {len(results)}\")\n",
    "print(f\"Summary file: processing_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "if results:\n",
    "    print(\"Processing Summary:\")\n",
    "    print(f\"- Total documents processed: {len(results)}\")\n",
    "    print(f\"- Total errors: {len(errors)}\")\n",
    "    print(f\"- Success rate: {len(results)/(len(results)+len(errors))*100:.1f}%\")\n",
    "    \n",
    "    # Show sample of extracted text from first result\n",
    "    if len(results) > 0:\n",
    "        sample_result = results[0]\n",
    "        print(f\"\\nSample extraction from {sample_result['filename']} (page {sample_result['page_number']}):\")\n",
    "        \n",
    "        # Extract text blocks from Textract response\n",
    "        textract_blocks = sample_result['textract_response'].get('Blocks', [])\n",
    "        text_blocks = [block['Text'] for block in textract_blocks if block['BlockType'] == 'LINE']\n",
    "        \n",
    "        print(\"First 10 lines of detected text:\")\n",
    "        for i, text in enumerate(text_blocks[:10]):\n",
    "            print(f\"{i+1:2d}: {text}\")\n",
    "            \n",
    "        # Show key-value pairs if detected\n",
    "        key_value_blocks = [block for block in textract_blocks if block['BlockType'] == 'KEY_VALUE_SET']\n",
    "        if key_value_blocks:\n",
    "            print(f\"\\nDetected {len(key_value_blocks)} key-value pairs in the form.\")\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if errors:\n",
    "    print(\"Error Analysis:\")\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    print(errors_df.head(10))\n",
    "    \n",
    "    # Count error types\n",
    "    error_types = errors_df['error'].value_counts()\n",
    "    print(\"\\nError type distribution:\")\n",
    "    print(error_types)\n",
    "else:\n",
    "    print(\"No errors to analyze!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}