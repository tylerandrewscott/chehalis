{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textract EDS Basic Processing\n",
    "\n",
    "This notebook processes PDF documents using AWS Textract WITHOUT a custom adapter. It:\n",
    "1. Reads the zero-shot results CSV to identify documents with forms\n",
    "2. Extracts the lowest page number from each document's form_pages\n",
    "3. Sends individual pages to Textract using standard QUERIES feature\n",
    "4. Extracts three specific pieces of information from EDS forms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "import PyPDF2\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CLOBBER = False  # Set to True to overwrite existing results, False to skip already processed files\n",
    "\n",
    "# File paths\n",
    "CSV_PATH = \"../../code/preprocessing/zero_shot_results_full_corpus.csv\"\n",
    "CONTRACTS_DIR = \"../../data/raw/_contracts/\"\n",
    "OUTPUT_DIR = \"../../data/intermediate_products/eds_forms_textract_textblurbs/\"\n",
    "\n",
    "# AWS Textract configuration\n",
    "REGION_NAME = \"us-east-1\"  # Update with your region\n",
    "CUSTOM_ADAPTER_ID = \"4403a7771cbe\"  # Update with your custom adapter ID\n",
    "ADAPTER_VERSION = \"2\"  # Update with your adapter version\n",
    "\n",
    "# Feature types - only QUERIES works with custom adapters\n",
    "FEATURE_TYPES = ['QUERIES']\n",
    "\n",
    "# Three specific queries for EDS basic processing\n",
    "EDS_QUERIES = [\n",
    "    \"EDS Number\",\n",
    "    \"What text is provided under 'Description of work and justification for spending money'?\",\n",
    "    \"What text is provided under 'Justification of vendor selection and determination of price reasonableness'?\"\n",
    "]\n",
    "\n",
    "# Initialize AWS client\n",
    "textract_client = boto3.client('textract', region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents in CSV: 42490\n",
      "Documents with forms: 26109\n",
      "\n",
      "Sample of documents with forms:\n",
      "                               filename      form_pages  num_form_pages\n",
      "804                           0-001.pdf  1,2,4,10,15,16               6\n",
      "956   0000000000000000000021689-004.pdf               5               1\n",
      "1660  0000000000000000000025661-003.pdf               5               1\n",
      "2895  0000000000000000000029856-000.pdf               1               1\n",
      "3996  0000000000000000000031808-000.pdf               1               1\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Total documents in CSV: {len(df)}\")\n",
    "\n",
    "# Filter for documents containing forms\n",
    "forms_df = df[df['contains_form'] == True].copy()\n",
    "print(f\"Documents with forms: {len(forms_df)}\")\n",
    "\n",
    "# Display sample of filtered data\n",
    "print(\"\\nSample of documents with forms:\")\n",
    "print(forms_df[['filename', 'form_pages', 'num_form_pages']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "forms_df = forms_df[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lowest_page_number(form_pages_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Extract the lowest page number from the form_pages string.\n",
    "    \n",
    "    Args:\n",
    "        form_pages_str: String containing page numbers (e.g., \"1,2,4,10,15,16\" or \"5\")\n",
    "    \n",
    "    Returns:\n",
    "        int: The lowest page number\n",
    "    \"\"\"\n",
    "    if pd.isna(form_pages_str) or form_pages_str == \"\":\n",
    "        return None\n",
    "    \n",
    "    # Handle both single numbers and comma-separated lists\n",
    "    if ',' in str(form_pages_str):\n",
    "        page_numbers = [int(x.strip()) for x in str(form_pages_str).split(',')]\n",
    "    else:\n",
    "        page_numbers = [int(str(form_pages_str).strip())]\n",
    "    \n",
    "    return min(page_numbers)\n",
    "\n",
    "def get_output_filename(filename: str, page_number: int) -> str:\n",
    "    \"\"\"\n",
    "    Generate the output JSON filename for a given PDF and page number.\n",
    "    \n",
    "    Args:\n",
    "        filename: Original PDF filename\n",
    "        page_number: Page number\n",
    "    \n",
    "    Returns:\n",
    "        str: Output JSON filename\n",
    "    \"\"\"\n",
    "    filename_base = Path(filename).stem\n",
    "    return f\"{filename_base}_page_{page_number}_textract_basic.json\"\n",
    "\n",
    "def file_already_processed(filename: str, page_number: int, output_dir: Path) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a file has already been processed.\n",
    "    \n",
    "    Args:\n",
    "        filename: Original PDF filename\n",
    "        page_number: Page number\n",
    "        output_dir: Output directory path\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if file exists and has been processed\n",
    "    \"\"\"\n",
    "    json_filename = get_output_filename(filename, page_number)\n",
    "    json_path = output_dir / json_filename\n",
    "    return json_path.exists() and json_path.stat().st_size > 0\n",
    "\n",
    "def extract_single_page_pdf(pdf_path: str, page_number: int) -> bytes:\n",
    "    \"\"\"\n",
    "    Extract a single page from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        page_number: Page number to extract (1-indexed)\n",
    "    \n",
    "    Returns:\n",
    "        bytes: PDF content of the single page\n",
    "    \"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "        pdf_writer = PyPDF2.PdfWriter()\n",
    "        \n",
    "        # PyPDF2 uses 0-based indexing, so subtract 1\n",
    "        pdf_writer.add_page(pdf_reader.pages[page_number - 1])\n",
    "        \n",
    "        output_buffer = BytesIO()\n",
    "        pdf_writer.write(output_buffer)\n",
    "        return output_buffer.getvalue()\n",
    "\n",
    "def process_with_textract_basic(pdf_bytes: bytes, adapter_id: str, queries: List[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a PDF page with Textract using custom adapter and limited queries.\n",
    "    \n",
    "    Args:\n",
    "        pdf_bytes: PDF content as bytes\n",
    "        adapter_id: Custom adapter ID\n",
    "        queries: List of queries (uses EDS_QUERIES if not provided)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Textract response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use provided queries or default EDS queries\n",
    "        if queries is None:\n",
    "            queries = EDS_QUERIES\n",
    "        \n",
    "        # Prepare the request parameters WITH custom adapter\n",
    "        request_params = {\n",
    "            'Document': {'Bytes': pdf_bytes},\n",
    "            'FeatureTypes': FEATURE_TYPES,\n",
    "            'QueriesConfig': {\n",
    "                'Queries': [{'Text': query} for query in queries]\n",
    "            },\n",
    "            'AdaptersConfig': {\n",
    "                'Adapters': [\n",
    "                    {\n",
    "                        'AdapterId': adapter_id,\n",
    "                        'Version': ADAPTER_VERSION\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = textract_client.analyze_document(**request_params)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing with Textract: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents with valid page numbers: 100\n",
      "\n",
      "Sample with lowest page numbers:\n",
      "                               filename      form_pages  lowest_page\n",
      "804                           0-001.pdf  1,2,4,10,15,16            1\n",
      "956   0000000000000000000021689-004.pdf               5            5\n",
      "1660  0000000000000000000025661-003.pdf               5            5\n",
      "2895  0000000000000000000029856-000.pdf               1            1\n",
      "3996  0000000000000000000031808-000.pdf               1            1\n",
      "4488  0000000000000000000034656-000.pdf               1            1\n",
      "5734  0000000000000000000036599-001.pdf               4            4\n",
      "5749  0000000000000000000036618-001.pdf               4            4\n",
      "5841  0000000000000000000036347-001.pdf            3,10            3\n",
      "7128  0000000000000000000038668-000.pdf              14           14\n"
     ]
    }
   ],
   "source": [
    "# Add lowest page number to dataframe\n",
    "forms_df['lowest_page'] = forms_df['form_pages'].apply(get_lowest_page_number)\n",
    "\n",
    "# Remove rows where we couldn't determine the lowest page\n",
    "forms_df = forms_df.dropna(subset=['lowest_page'])\n",
    "forms_df['lowest_page'] = forms_df['lowest_page'].astype(int)\n",
    "\n",
    "print(f\"Documents with valid page numbers: {len(forms_df)}\")\n",
    "print(\"\\nSample with lowest page numbers:\")\n",
    "print(forms_df[['filename', 'form_pages', 'lowest_page']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLOBBER = False: Checking for existing results...\n",
      "No existing results found. Processing all files.\n",
      "Processing 0-001.pdf, page 1...\n",
      "✓ Successfully processed 0-001.pdf → 0-001_page_1_textract_basic.json\n",
      "Processing 0000000000000000000021689-004.pdf, page 5...\n",
      "✓ Successfully processed 0000000000000000000021689-004.pdf → 0000000000000000000021689-004_page_5_textract_basic.json\n",
      "Processing 0000000000000000000025661-003.pdf, page 5...\n",
      "✓ Successfully processed 0000000000000000000025661-003.pdf → 0000000000000000000025661-003_page_5_textract_basic.json\n",
      "Processing 0000000000000000000029856-000.pdf, page 1...\n",
      "✓ Successfully processed 0000000000000000000029856-000.pdf → 0000000000000000000029856-000_page_1_textract_basic.json\n",
      "Processing 0000000000000000000031808-000.pdf, page 1...\n",
      "✓ Successfully processed 0000000000000000000031808-000.pdf → 0000000000000000000031808-000_page_1_textract_basic.json\n",
      "Processing 0000000000000000000034656-000.pdf, page 1...\n",
      "✓ Successfully processed 0000000000000000000034656-000.pdf → 0000000000000000000034656-000_page_1_textract_basic.json\n",
      "Processing 0000000000000000000036599-001.pdf, page 4...\n",
      "✓ Successfully processed 0000000000000000000036599-001.pdf → 0000000000000000000036599-001_page_4_textract_basic.json\n",
      "Processing 0000000000000000000036618-001.pdf, page 4...\n",
      "✓ Successfully processed 0000000000000000000036618-001.pdf → 0000000000000000000036618-001_page_4_textract_basic.json\n",
      "Processing 0000000000000000000036347-001.pdf, page 3...\n",
      "✓ Successfully processed 0000000000000000000036347-001.pdf → 0000000000000000000036347-001_page_3_textract_basic.json\n",
      "Processing 0000000000000000000038668-000.pdf, page 14...\n",
      "✓ Successfully processed 0000000000000000000038668-000.pdf → 0000000000000000000038668-000_page_14_textract_basic.json\n",
      "Processing 0000000000000000000038918-001.pdf, page 15...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m page_pdf_bytes \u001b[38;5;241m=\u001b[39m extract_single_page_pdf(pdf_path, lowest_page)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Process with Textract using custom adapter and 3 queries\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m textract_response \u001b[38;5;241m=\u001b[39m process_with_textract_basic(page_pdf_bytes, CUSTOM_ADAPTER_ID)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m textract_response:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Save result immediately to avoid losing work\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     json_filename \u001b[38;5;241m=\u001b[39m get_output_filename(filename, lowest_page)\n",
      "Cell \u001b[0;32mIn[41], line 108\u001b[0m, in \u001b[0;36mprocess_with_textract_basic\u001b[0;34m(pdf_bytes, adapter_id, queries)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Prepare the request parameters WITH custom adapter\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     request_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocument\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBytes\u001b[39m\u001b[38;5;124m'\u001b[39m: pdf_bytes},\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatureTypes\u001b[39m\u001b[38;5;124m'\u001b[39m: FEATURE_TYPES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m         }\n\u001b[1;32m    106\u001b[0m     }\n\u001b[0;32m--> 108\u001b[0m     response \u001b[38;5;241m=\u001b[39m textract_client\u001b[38;5;241m.\u001b[39manalyze_document(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_params)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/client.py:601\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    599\u001b[0m     )\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/context.py:123\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    122\u001b[0m     hook()\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/client.py:1056\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1052\u001b[0m     maybe_compress_request(\n\u001b[1;32m   1053\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mconfig, request_dict, operation_model\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[1;32m   1055\u001b[0m     apply_request_checksum(request_dict)\n\u001b[0;32m-> 1056\u001b[0m     http, parsed_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m   1057\u001b[0m         operation_model, request_dict, request_context\n\u001b[1;32m   1058\u001b[0m     )\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1062\u001b[0m     http_response\u001b[38;5;241m=\u001b[39mhttp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     context\u001b[38;5;241m=\u001b[39mrequest_context,\n\u001b[1;32m   1066\u001b[0m )\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/client.py:1080\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1080\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpoint\u001b[38;5;241m.\u001b[39mmake_request(operation_model, request_dict)\n\u001b[1;32m   1081\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeta\u001b[38;5;241m.\u001b[39mevents\u001b[38;5;241m.\u001b[39memit(\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter-call-error.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_model\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;241m.\u001b[39mhyphenize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation_model\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1084\u001b[0m             exception\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m   1085\u001b[0m             context\u001b[38;5;241m=\u001b[39mrequest_context,\n\u001b[1;32m   1086\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/endpoint.py:118\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    113\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaking request for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with params: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m         operation_model,\n\u001b[1;32m    116\u001b[0m         request_dict,\n\u001b[1;32m    117\u001b[0m     )\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(request_dict, operation_model)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/endpoint.py:196\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_retries_context(context, attempts)\n\u001b[1;32m    195\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_request(request_dict, operation_model)\n\u001b[0;32m--> 196\u001b[0m success_response, exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_response(\n\u001b[1;32m    197\u001b[0m     request, operation_model, context\n\u001b[1;32m    198\u001b[0m )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_needs_retry(\n\u001b[1;32m    200\u001b[0m     attempts,\n\u001b[1;32m    201\u001b[0m     operation_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    204\u001b[0m     exception,\n\u001b[1;32m    205\u001b[0m ):\n\u001b[1;32m    206\u001b[0m     attempts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/endpoint.py:238\u001b[0m, in \u001b[0;36mEndpoint._get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, request, operation_model, context):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# This will return a tuple of (success_response, exception)\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# and success_response is itself a tuple of\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# (http_response, parsed_dict).\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# If an exception occurs then the success_response is None.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# If no exception occurs then exception is None.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m     success_response, exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_get_response(\n\u001b[1;32m    239\u001b[0m         request, operation_model, context\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m     kwargs_to_emit \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparsed_response\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: context,\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m'\u001b[39m: exception,\n\u001b[1;32m    246\u001b[0m     }\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/endpoint.py:278\u001b[0m, in \u001b[0;36mEndpoint._do_get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    276\u001b[0m     http_response \u001b[38;5;241m=\u001b[39m first_non_none_response(responses)\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m http_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 278\u001b[0m         http_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send(request)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, e)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/endpoint.py:382\u001b[0m, in \u001b[0;36mEndpoint._send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_send\u001b[39m(\u001b[38;5;28mself\u001b[39m, request):\n\u001b[0;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_session\u001b[38;5;241m.\u001b[39msend(request)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/botocore/httpsession.py:464\u001b[0m, in \u001b[0;36mURLLib3Session.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    461\u001b[0m     conn\u001b[38;5;241m.\u001b[39mproxy_headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m host\n\u001b[1;32m    463\u001b[0m request_target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request_target(request\u001b[38;5;241m.\u001b[39murl, proxy_url)\n\u001b[0;32m--> 464\u001b[0m urllib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    465\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    466\u001b[0m     url\u001b[38;5;241m=\u001b[39mrequest_target,\n\u001b[1;32m    467\u001b[0m     body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    468\u001b[0m     headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    469\u001b[0m     retries\u001b[38;5;241m=\u001b[39mRetry(\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    470\u001b[0m     assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    471\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    472\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    473\u001b[0m     chunked\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunked(request\u001b[38;5;241m.\u001b[39mheaders),\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m http_response \u001b[38;5;241m=\u001b[39m botocore\u001b[38;5;241m.\u001b[39mawsrequest\u001b[38;5;241m.\u001b[39mAWSResponse(\n\u001b[1;32m    477\u001b[0m     request\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m    478\u001b[0m     urllib_response\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    479\u001b[0m     urllib_response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    480\u001b[0m     urllib_response,\n\u001b[1;32m    481\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m request\u001b[38;5;241m.\u001b[39mstream_output:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;66;03m# Cause the raw stream to be exhausted immediately. We do it\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;66;03m# this way instead of using preload_content because\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;66;03m# preload_content will never buffer chunked responses\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:791\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    788\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    792\u001b[0m     conn,\n\u001b[1;32m    793\u001b[0m     method,\n\u001b[1;32m    794\u001b[0m     url,\n\u001b[1;32m    795\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    796\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    797\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    798\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    799\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    800\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    801\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    802\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    807\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connectionpool.py:1097\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1097\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1101\u001b[0m         (\n\u001b[1;32m   1102\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconn\u001b[38;5;241m.\u001b[39mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1108\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:642\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_time_off:\n\u001b[1;32m    634\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    635\u001b[0m         (\n\u001b[1;32m    636\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSystem time is way off (before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRECENT_DATE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). This will probably \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m         SystemTimeWarning,\n\u001b[1;32m    640\u001b[0m     )\n\u001b[0;32m--> 642\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_and_match_hostname(\n\u001b[1;32m    643\u001b[0m     sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[1;32m    644\u001b[0m     cert_reqs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_reqs,\n\u001b[1;32m    645\u001b[0m     ssl_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_version,\n\u001b[1;32m    646\u001b[0m     ssl_minimum_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_minimum_version,\n\u001b[1;32m    647\u001b[0m     ssl_maximum_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_maximum_version,\n\u001b[1;32m    648\u001b[0m     ca_certs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs,\n\u001b[1;32m    649\u001b[0m     ca_cert_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir,\n\u001b[1;32m    650\u001b[0m     ca_cert_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_data,\n\u001b[1;32m    651\u001b[0m     cert_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_file,\n\u001b[1;32m    652\u001b[0m     key_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_file,\n\u001b[1;32m    653\u001b[0m     key_password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_password,\n\u001b[1;32m    654\u001b[0m     server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[1;32m    655\u001b[0m     ssl_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context,\n\u001b[1;32m    656\u001b[0m     tls_in_tls\u001b[38;5;241m=\u001b[39mtls_in_tls,\n\u001b[1;32m    657\u001b[0m     assert_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_hostname,\n\u001b[1;32m    658\u001b[0m     assert_fingerprint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_fingerprint,\n\u001b[1;32m    659\u001b[0m )\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39mis_verified\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/connection.py:783\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[1;32m    781\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[0;32m--> 783\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m ssl_wrap_socket(\n\u001b[1;32m    784\u001b[0m     sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[1;32m    785\u001b[0m     keyfile\u001b[38;5;241m=\u001b[39mkey_file,\n\u001b[1;32m    786\u001b[0m     certfile\u001b[38;5;241m=\u001b[39mcert_file,\n\u001b[1;32m    787\u001b[0m     key_password\u001b[38;5;241m=\u001b[39mkey_password,\n\u001b[1;32m    788\u001b[0m     ca_certs\u001b[38;5;241m=\u001b[39mca_certs,\n\u001b[1;32m    789\u001b[0m     ca_cert_dir\u001b[38;5;241m=\u001b[39mca_cert_dir,\n\u001b[1;32m    790\u001b[0m     ca_cert_data\u001b[38;5;241m=\u001b[39mca_cert_data,\n\u001b[1;32m    791\u001b[0m     server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[1;32m    792\u001b[0m     ssl_context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[1;32m    793\u001b[0m     tls_in_tls\u001b[38;5;241m=\u001b[39mtls_in_tls,\n\u001b[1;32m    794\u001b[0m )\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/util/ssl_.py:471\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:  \u001b[38;5;66;03m# Defensive: in CI, we always have set_alpn_protocols\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/urllib3/util/ssl_.py:515\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    512\u001b[0m     SSLTransport\u001b[38;5;241m.\u001b[39m_validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[0;32m--> 515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock, server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:517\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    512\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    513\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[1;32m    518\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[1;32m    519\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[1;32m    520\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[1;32m    521\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[1;32m    522\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[1;32m    523\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    524\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[1;32m    525\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1108\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   1106\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/ssl.py:1383\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[1;32m   1382\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create output directory if it doesn't exist\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Check existing results if CLOBBER is False\n",
    "if not CLOBBER:\n",
    "    print(\"CLOBBER = False: Checking for existing results...\")\n",
    "    already_processed = []\n",
    "    for idx, row in forms_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        lowest_page = row['lowest_page']\n",
    "        if file_already_processed(filename, lowest_page, output_dir):\n",
    "            already_processed.append(filename)\n",
    "    \n",
    "    if already_processed:\n",
    "        print(f\"Found {len(already_processed)} already processed files. Skipping these.\")\n",
    "        # Filter out already processed files\n",
    "        forms_df = forms_df[~forms_df['filename'].isin(already_processed)]\n",
    "        print(f\"Remaining files to process: {len(forms_df)}\")\n",
    "    else:\n",
    "        print(\"No existing results found. Processing all files.\")\n",
    "else:\n",
    "    print(\"CLOBBER = True: Processing all files (will overwrite existing results)\")\n",
    "\n",
    "# Process each document\n",
    "results = []\n",
    "errors = []\n",
    "skipped = []\n",
    "\n",
    "for idx, row in forms_df.iterrows():\n",
    "    filename = row['filename']\n",
    "    lowest_page = row['lowest_page']\n",
    "    \n",
    "    pdf_path = os.path.join(CONTRACTS_DIR, filename)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(pdf_path):\n",
    "        error_msg = f\"File not found: {filename}\"\n",
    "        print(error_msg)\n",
    "        errors.append({'filename': filename, 'error': error_msg})\n",
    "        continue\n",
    "    \n",
    "    # Double-check if file already processed (in case of race conditions)\n",
    "    if not CLOBBER and file_already_processed(filename, lowest_page, output_dir):\n",
    "        print(f\"⏭ Skipping {filename} (already processed)\")\n",
    "        skipped.append({'filename': filename, 'page_number': lowest_page})\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing {filename}, page {lowest_page}...\")\n",
    "        \n",
    "        # Extract the specific page\n",
    "        page_pdf_bytes = extract_single_page_pdf(pdf_path, lowest_page)\n",
    "        \n",
    "        # Process with Textract using custom adapter and 3 queries\n",
    "        textract_response = process_with_textract_basic(page_pdf_bytes, CUSTOM_ADAPTER_ID)\n",
    "        \n",
    "        if textract_response:\n",
    "            # Save result immediately to avoid losing work\n",
    "            json_filename = get_output_filename(filename, lowest_page)\n",
    "            json_path = output_dir / json_filename\n",
    "            \n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(textract_response, f, indent=2, default=str)\n",
    "            \n",
    "            result = {\n",
    "                'filename': filename,\n",
    "                'page_number': lowest_page,\n",
    "                'json_file': json_filename,\n",
    "                'status': 'success'\n",
    "            }\n",
    "            results.append(result)\n",
    "            print(f\"✓ Successfully processed {filename} → {json_filename}\")\n",
    "        else:\n",
    "            error_msg = f\"Textract processing failed for {filename}\"\n",
    "            print(f\"✗ {error_msg}\")\n",
    "            errors.append({'filename': filename, 'error': error_msg})\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing {filename}: {str(e)}\"\n",
    "        print(f\"✗ {error_msg}\")\n",
    "        errors.append({'filename': filename, 'error': error_msg})\n",
    "\n",
    "print(f\"\\nProcessing complete!\")\n",
    "print(f\"Successfully processed: {len(results)} documents\")\n",
    "print(f\"Skipped (already processed): {len(skipped)} documents\")\n",
    "print(f\"Errors: {len(errors)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary and error files\n",
    "if results or skipped:\n",
    "    # Count existing files if CLOBBER was False\n",
    "    existing_files = []\n",
    "    if not CLOBBER:\n",
    "        for json_file in output_dir.glob(\"*.json\"):\n",
    "            if json_file.name != \"processing_summary.json\":\n",
    "                existing_files.append(json_file.name)\n",
    "    \n",
    "    # Save summary of all results (including existing ones)\n",
    "    summary = {\n",
    "        'processing_type': 'custom_adapter_limited_queries',\n",
    "        'queries_used': EDS_QUERIES,\n",
    "        'clobber_mode': CLOBBER,\n",
    "        'newly_processed_count': len(results),\n",
    "        'skipped_count': len(skipped),\n",
    "        'error_count': len(errors),\n",
    "        'total_existing_files': len(existing_files) if not CLOBBER else 0,\n",
    "        'newly_processed_files': [{\n",
    "            'filename': r['filename'],\n",
    "            'page_number': r['page_number'],\n",
    "            'json_file': r['json_file']\n",
    "        } for r in results],\n",
    "        'skipped_files': skipped\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / 'processing_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "# Save errors if any\n",
    "if errors:\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    errors_df.to_csv(output_dir / 'processing_errors.csv', index=False)\n",
    "    print(f\"Errors saved to: {output_dir / 'processing_errors.csv'}\")\n",
    "\n",
    "print(f\"Results saved to: {output_dir}\")\n",
    "print(f\"Newly processed JSON files: {len(results)}\")\n",
    "if not CLOBBER and skipped:\n",
    "    print(f\"Skipped existing files: {len(skipped)}\")\n",
    "print(f\"Summary file: processing_summary.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "total_processed = len(results) + len(skipped)\n",
    "if total_processed > 0:\n",
    "    print(\"Processing Summary:\")\n",
    "    print(f\"- Processing type: Custom adapter with limited queries\")\n",
    "    print(f\"- Queries used: {len(EDS_QUERIES)}\")\n",
    "    for i, query in enumerate(EDS_QUERIES, 1):\n",
    "        print(f\"  {i}. {query}\")\n",
    "    print(f\"- Total documents in scope: {total_processed}\")\n",
    "    print(f\"- Newly processed: {len(results)}\")\n",
    "    if not CLOBBER and skipped:\n",
    "        print(f\"- Skipped (already processed): {len(skipped)}\")\n",
    "    print(f\"- Total errors: {len(errors)}\")\n",
    "    if len(results) + len(errors) > 0:\n",
    "        print(f\"- Success rate: {len(results)/(len(results)+len(errors))*100:.1f}%\")\n",
    "    \n",
    "    # Show sample of extracted answers from first result\n",
    "    if len(results) > 0:\n",
    "        sample_result = results[0]\n",
    "        print(f\"\\nSample extraction from {sample_result['filename']} (page {sample_result['page_number']}):\"))\n",
    "        \n",
    "        # Load the JSON file to get Textract response\n",
    "        json_path = output_dir / sample_result['json_file']\n",
    "        with open(json_path, 'r') as f:\n",
    "            textract_response = json.load(f)\n",
    "        \n",
    "        # Extract query results from Textract response\n",
    "        textract_blocks = textract_response.get('Blocks', [])\n",
    "        query_blocks = [block for block in textract_blocks if block['BlockType'] == 'QUERY']\n",
    "        \n",
    "        print(\"Query responses:\")\n",
    "        for query_block in query_blocks:\n",
    "            query_text = query_block.get('Query', {}).get('Text', 'Unknown query')\n",
    "            \n",
    "            # Find the corresponding answer block\n",
    "            answer_text = \"No answer found\"\n",
    "            if 'Relationships' in query_block:\n",
    "                for relationship in query_block['Relationships']:\n",
    "                    if relationship['Type'] == 'ANSWER':\n",
    "                        answer_ids = relationship['Ids']\n",
    "                        for answer_id in answer_ids:\n",
    "                            answer_block = next((b for b in textract_blocks if b['Id'] == answer_id), None)\n",
    "                            if answer_block and 'Text' in answer_block:\n",
    "                                answer_text = answer_block['Text']\n",
    "                                break\n",
    "            \n",
    "            print(f\"Q: {query_text}\")\n",
    "            print(f\"A: {answer_text}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"No files were processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary and error files\n",
    "if results or skipped:\n",
    "    # Count existing files if CLOBBER was False\n",
    "    existing_files = []\n",
    "    if not CLOBBER:\n",
    "        for json_file in output_dir.glob(\"*.json\"):\n",
    "            if json_file.name != \"processing_summary.json\":\n",
    "                existing_files.append(json_file.name)\n",
    "    \n",
    "    # Save summary of all results (including existing ones)\n",
    "    summary = {\n",
    "        'processing_type': 'textract_eds_adapter_textblurbs',\n",
    "        'queries_used': EDS_QUERIES,\n",
    "        'clobber_mode': CLOBBER,\n",
    "        'newly_processed_count': len(results),\n",
    "        'skipped_count': len(skipped),\n",
    "        'error_count': len(errors),\n",
    "        'total_existing_files': len(existing_files) if not CLOBBER else 0,\n",
    "        'newly_processed_files': [{\n",
    "            'filename': r['filename'],\n",
    "            'page_number': r['page_number'],\n",
    "            'json_file': r['json_file']\n",
    "        } for r in results],\n",
    "        'skipped_files': skipped\n",
    "    }\n",
    "    \n",
    "    with open(output_dir / 'processing_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "# Save errors if any\n",
    "if errors:\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    errors_df.to_csv(output_dir / 'processing_errors.csv', index=False)\n",
    "    print(f\"Errors saved to: {output_dir / 'processing_errors.csv'}\")\n",
    "\n",
    "print(f\"Results saved to: {output_dir}\")\n",
    "print(f\"Newly processed JSON files: {len(results)}\")\n",
    "if not CLOBBER and skipped:\n",
    "    print(f\"Skipped existing files: {len(skipped)}\")\n",
    "print(f\"Summary file: processing_summary.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "total_processed = len(results) + len(skipped)\n",
    "if total_processed > 0:\n",
    "    print(\"Processing Summary:\")\n",
    "    print(f\"- Processing type: Basic Textract (no custom adapter)\")\n",
    "    print(f\"- Queries used: {len(EDS_QUERIES)}\")\n",
    "    for i, query in enumerate(EDS_QUERIES, 1):\n",
    "        print(f\"  {i}. {query}\")\n",
    "    print(f\"- Total documents in scope: {total_processed}\")\n",
    "    print(f\"- Newly processed: {len(results)}\")\n",
    "    if not CLOBBER and skipped:\n",
    "        print(f\"- Skipped (already processed): {len(skipped)}\")\n",
    "    print(f\"- Total errors: {len(errors)}\")\n",
    "    if len(results) + len(errors) > 0:\n",
    "        print(f\"- Success rate: {len(results)/(len(results)+len(errors))*100:.1f}%\")\n",
    "    \n",
    "    # Show sample of extracted answers from first result\n",
    "    if len(results) > 0:\n",
    "        sample_result = results[0]\n",
    "        print(f\"\\nSample extraction from {sample_result['filename']} (page {sample_result['page_number']}):\")\n",
    "        \n",
    "        # Load the JSON file to get Textract response\n",
    "        json_path = output_dir / sample_result['json_file']\n",
    "        with open(json_path, 'r') as f:\n",
    "            textract_response = json.load(f)\n",
    "        \n",
    "        # Extract query results from Textract response\n",
    "        textract_blocks = textract_response.get('Blocks', [])\n",
    "        query_blocks = [block for block in textract_blocks if block['BlockType'] == 'QUERY']\n",
    "        \n",
    "        print(\"Query responses:\")\n",
    "        for query_block in query_blocks:\n",
    "            query_text = query_block.get('Query', {}).get('Text', 'Unknown query')\n",
    "            \n",
    "            # Find the corresponding answer block\n",
    "            answer_text = \"No answer found\"\n",
    "            if 'Relationships' in query_block:\n",
    "                for relationship in query_block['Relationships']:\n",
    "                    if relationship['Type'] == 'ANSWER':\n",
    "                        answer_ids = relationship['Ids']\n",
    "                        for answer_id in answer_ids:\n",
    "                            answer_block = next((b for b in textract_blocks if b['Id'] == answer_id), None)\n",
    "                            if answer_block and 'Text' in answer_block:\n",
    "                                answer_text = answer_block['Text']\n",
    "                                break\n",
    "            \n",
    "            print(f\"Q: {query_text}\")\n",
    "            print(f\"A: {answer_text}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"No files were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if errors:\n",
    "    print(\"Error Analysis:\")\n",
    "    errors_df = pd.DataFrame(errors)\n",
    "    print(errors_df.head(10))\n",
    "    \n",
    "    # Count error types\n",
    "    error_types = errors_df['error'].value_counts()\n",
    "    print(\"\\nError type distribution:\")\n",
    "    print(error_types)\n",
    "else:\n",
    "    print(\"No errors to analyze!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
