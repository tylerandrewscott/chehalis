{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7df74465-5f2a-4c55-97b6-cf7e5698a176",
   "metadata": {},
   "source": [
    "# Government Contract Document Processing Pipeline - DeepSeek Vision-Language Model\n",
    "\n",
    "This notebook provides an **AI-powered** solution for extracting structured information from government contract forms using **DeepSeek Vision-Language Model** with chat-based prompting.\n",
    "\n",
    "## **🚀 DeepSeek Vision Features:**\n",
    "- **Multi-modal Understanding**: Processes both text and images simultaneously\n",
    "- **Natural Language Prompts**: Extract data using conversational instructions\n",
    "- **Contextual Intelligence**: Understands form structure and relationships\n",
    "- **Flexible Output**: JSON, structured text, or custom formats\n",
    "- **No Training Required**: Zero-shot form understanding\n",
    "- **Cost Effective**: Open-source model with local inference\n",
    "\n",
    "## **📊 Expected Performance:**\n",
    "| Feature | Traditional OCR | DeepSeek Vision |\n",
    "|---------|-----------------|------------------|\n",
    "| **Accuracy** | 70-80% | 90-95% |\n",
    "| **Understanding** | Pattern matching | Contextual reasoning |\n",
    "| **Flexibility** | Fixed patterns | Natural language prompts |\n",
    "| **Error Handling** | Rigid | Intelligent interpretation |\n",
    "| **Form Variations** | Requires retraining | Adapts automatically |\n",
    "| **Complex Fields** | Manual parsing | Natural understanding |\n",
    "\n",
    "**Advantages**: Handles handwritten text, varying layouts, and complex relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6313e-f6b5-4797-9660-cf62d419a5d8",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Required packages for DeepSeek Vision\n",
    "required_packages = [\n",
    "    'torch', 'transformers', 'PIL', 'pdf2image', 'pandas', \n",
    "    'numpy', 'tqdm', 'matplotlib', 'seaborn', 'json', 'base64'\n",
    "]\n",
    "\n",
    "missing = []\n",
    "for pkg in required_packages:\n",
    "    try:\n",
    "        if pkg == 'PIL':\n",
    "            __import__('PIL')\n",
    "        else:\n",
    "            __import__(pkg)\n",
    "    except ImportError:\n",
    "        missing.append(pkg)\n",
    "\n",
    "if missing:\n",
    "    print(f\"❌ Missing packages: {', '.join(missing)}\")\n",
    "    print(\"Install with: pip install torch transformers Pillow pdf2image pandas numpy tqdm matplotlib seaborn\")\n",
    "else:\n",
    "    print(\"✅ All packages available\")\n",
    "\n",
    "# Import everything\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import base64\n",
    "import io\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import pdf2image\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")\n",
    "print(\"🧠 Ready for DeepSeek Vision-Language processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c3e356-42f6-4a73-b8e8-09b41b8938fb",
   "metadata": {},
   "source": [
    "## 2. DeepSeek Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for DeepSeek Vision processing\n",
    "CONFIG = {\n",
    "    \"model_name\": \"deepseek-ai/deepseek-vl-7b-chat\",  # DeepSeek Vision-Language model\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"batch_size\": 1,  # Process one document at a time for better accuracy\n",
    "    \"max_pages_per_doc\": 5,  # Limit pages to process per document\n",
    "    \"image_dpi\": 300,  # High DPI for better vision model input\n",
    "    \"max_tokens\": 2048,  # Maximum tokens for response\n",
    "    \"temperature\": 0.1,  # Low temperature for consistent extraction\n",
    "    \"cache_dir\": \"./deepseek_cache\",  # Model cache directory\n",
    "    \"confidence_threshold\": 0.7,  # Minimum confidence for field extraction\n",
    "    \"use_json_mode\": True,  # Request structured JSON output\n",
    "}\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(CONFIG[\"cache_dir\"], exist_ok=True)\n",
    "os.makedirs(\"./results\", exist_ok=True)\n",
    "\n",
    "print(\"✓ Configuration set for DeepSeek Vision\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Max tokens: {CONFIG['max_tokens']}\")\n",
    "\n",
    "if CONFIG['device'] == 'cpu':\n",
    "    print(\"⚠️  Running on CPU - processing will be slower\")\n",
    "    print(\"💡 For faster processing, use a GPU-enabled environment\")\n",
    "else:\n",
    "    print(f\"🚀 GPU detected - ready for fast processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ecde33-3520-435f-9d4e-b21925db161b",
   "metadata": {},
   "source": [
    "## 3. DeepSeek Vision Processor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processor-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DeepSeekContractProcessor:\n",
    "    \"\"\"Government contract processor using DeepSeek Vision-Language Model\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = None, device: str = None):\n",
    "        \"\"\"Initialize the DeepSeek processor\"\"\"\n",
    "        \n",
    "        self.model_name = model_name or CONFIG[\"model_name\"]\n",
    "        self.device = device or CONFIG[\"device\"]\n",
    "        self.tokenizer = None\n",
    "        self.model = None\n",
    "        \n",
    "        print(f\"Initializing DeepSeekContractProcessor\")\n",
    "        print(f\"Model: {self.model_name}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load DeepSeek Vision-Language model\"\"\"\n",
    "        if self.model is not None:\n",
    "            return  # Already loaded\n",
    "            \n",
    "        print(\"Loading DeepSeek Vision model... This may take several minutes.\")\n",
    "        \n",
    "        try:\n",
    "            # Load tokenizer\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name,\n",
    "                cache_dir=CONFIG[\"cache_dir\"],\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            # Load model\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                self.model_name,\n",
    "                cache_dir=CONFIG[\"cache_dir\"],\n",
    "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "                device_map=\"auto\" if self.device == \"cuda\" else None,\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            if self.device == \"cpu\":\n",
    "                self.model = self.model.to(self.device)\n",
    "            \n",
    "            self.model.eval()\n",
    "            \n",
    "            print(\"✓ DeepSeek Vision model loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading model: {e}\")\n",
    "            print(\"💡 Try using a smaller model or CPU mode\")\n",
    "            raise\n",
    "    \n",
    "    def convert_pdf_to_images(self, pdf_path: str, max_pages: int = None) -> List[Image.Image]:\n",
    "        \"\"\"Convert PDF to list of PIL Images for vision model\"\"\"\n",
    "        try:\n",
    "            max_pages = max_pages or CONFIG[\"max_pages_per_doc\"]\n",
    "            \n",
    "            images = pdf2image.convert_from_path(\n",
    "                pdf_path,\n",
    "                dpi=CONFIG[\"image_dpi\"],\n",
    "                first_page=1,\n",
    "                last_page=max_pages\n",
    "            )\n",
    "            \n",
    "            return images\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error converting PDF {pdf_path}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def prepare_image_for_model(self, image: Image.Image) -> str:\n",
    "        \"\"\"Convert PIL Image to base64 string for model input\"\"\"\n",
    "        # Resize image if too large (DeepSeek works better with reasonable sizes)\n",
    "        max_size = 1024\n",
    "        if max(image.size) > max_size:\n",
    "            ratio = max_size / max(image.size)\n",
    "            new_size = tuple(int(dim * ratio) for dim in image.size)\n",
    "            image = image.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Convert to base64\n",
    "        buffered = io.BytesIO()\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "        \n",
    "        return img_str\n",
    "    \n",
    "    def create_extraction_prompt(self) -> str:\n",
    "        \"\"\"Create a detailed prompt for contract field extraction\"\"\"\n",
    "        \n",
    "        prompt = \"\"\"\n",
    "You are an expert document analyst specializing in government contract forms. Please analyze this contract document image and extract the following information. Look carefully at all text, checkboxes, and form fields.\n",
    "\n",
    "Extract these specific fields and return the results in JSON format:\n",
    "\n",
    "{\n",
    "  \"eds_number\": \"Contract or EDS number (format: like C22-6-0060 or similar)\",\n",
    "  \"date_prepared\": \"Date the document was prepared (MM/DD/YYYY format)\",\n",
    "  \"contracts_leases\": \"Type of contract - look for checked boxes or marked options (Professional Services, Grant, Lease, etc.)\",\n",
    "  \"account_number\": \"Account number (usually numeric with dashes like 5120-10660)\",\n",
    "  \"account_name\": \"Name of the account or fund\",\n",
    "  \"total_amount_this_action\": \"Dollar amount for this action (numbers only, no $ sign)\",\n",
    "  \"new_contract_total\": \"New total contract amount (numbers only, no $ sign)\",\n",
    "  \"revenue_generated_this_action\": \"Revenue generated by this action\",\n",
    "  \"revenue_generated_total_contract\": \"Total revenue generated by contract\",\n",
    "  \"from_date\": \"Contract start date (MM/DD/YYYY)\",\n",
    "  \"to_date\": \"Contract end date (MM/DD/YYYY)\",\n",
    "  \"method_source_selection\": \"Method of source selection (Negotiated, Competitive, etc.)\",\n",
    "  \"email_address\": \"Any email address found in the document\",\n",
    "  \"vendor_id\": \"Vendor ID number (usually 10 digits)\",\n",
    "  \"vendor_name\": \"Name of the vendor/contractor\",\n",
    "  \"primary_vendor_mwbe\": \"Whether primary vendor is MWBE (Yes/No)\",\n",
    "  \"sub_vendor_mwbe\": \"Whether sub vendor is MWBE (Yes/No)\",\n",
    "  \"renewal_language\": \"Whether renewal language is included (Yes/No)\",\n",
    "  \"termination_convenience_clause\": \"Whether termination for convenience clause exists (Yes/No)\",\n",
    "  \"description_work_justification\": \"Brief description of work or justification\"\n",
    "}\n",
    "\n",
    "Instructions:\n",
    "1. Look carefully at ALL text in the image, including handwritten entries\n",
    "2. For checkboxes, identify which ones are marked with X, checkmarks, or filled in\n",
    "3. If a field is not visible or clearly readable, use an empty string \"\"\n",
    "4. For Yes/No fields, use \"Yes\", \"No\", or \"\" if unclear\n",
    "5. Extract only the values, not the field labels\n",
    "6. Be precise with numbers and dates\n",
    "7. Return ONLY the JSON object, no other text\n",
    "\n",
    "Analyze this government contract form image:\n",
    "\"\"\"\n",
    "        \n",
    "        return prompt.strip()\n",
    "    \n",
    "    def create_validation_prompt(self, extracted_data: Dict) -> str:\n",
    "        \"\"\"Create a prompt to validate and improve extracted data\"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Please review and validate the following extracted contract data from the document image. Check for any obvious errors, missing information, or inconsistencies.\n",
    "\n",
    "Extracted Data:\n",
    "{json.dumps(extracted_data, indent=2)}\n",
    "\n",
    "Please:\n",
    "1. Verify dates are in correct MM/DD/YYYY format\n",
    "2. Check that monetary amounts are numeric only (no $ signs)\n",
    "3. Ensure contract types match what's actually checked in the form\n",
    "4. Validate email addresses have proper format\n",
    "5. Look for any information that might have been missed\n",
    "\n",
    "Return the corrected JSON data with the same structure. If everything looks correct, return the same data.\n",
    "\"\"\"\n",
    "        \n",
    "        return prompt.strip()\n",
    "    \n",
    "    def query_model_with_image(self, image: Image.Image, prompt: str) -> str:\n",
    "        \"\"\"Query DeepSeek model with image and prompt\"\"\"\n",
    "        try:\n",
    "            # Prepare image\n",
    "            image_b64 = self.prepare_image_for_model(image)\n",
    "            \n",
    "            # Create conversation with image\n",
    "            conversation = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/png;base64,{image_b64}\"\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # Apply chat template\n",
    "            inputs = self.tokenizer.apply_chat_template(\n",
    "                conversation,\n",
    "                add_generation_prompt=True,\n",
    "                tokenize=True,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(self.device)\n",
    "            \n",
    "            # Generate response\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    inputs,\n",
    "                    max_new_tokens=CONFIG[\"max_tokens\"],\n",
    "                    temperature=CONFIG[\"temperature\"],\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            # Decode response\n",
    "            response = self.tokenizer.decode(\n",
    "                outputs[0][inputs.shape[1]:],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "            \n",
    "            return response.strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error querying model: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def parse_json_response(self, response: str) -> Dict[str, str]:\n",
    "        \"\"\"Parse JSON response from model, with fallback parsing\"\"\"\n",
    "        \n",
    "        # Try to extract JSON from response\n",
    "        try:\n",
    "            # Look for JSON block\n",
    "            json_match = re.search(r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(0)\n",
    "                return json.loads(json_str)\n",
    "            \n",
    "            # Try parsing entire response as JSON\n",
    "            return json.loads(response)\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback: try to extract fields using regex\n",
    "            print(\"⚠️ JSON parsing failed, using fallback extraction\")\n",
    "            return self.fallback_field_extraction(response)\n",
    "    \n",
    "    def fallback_field_extraction(self, text: str) -> Dict[str, str]:\n",
    "        \"\"\"Fallback extraction using regex patterns\"\"\"\n",
    "        \n",
    "        fields = {\n",
    "            'eds_number': '',\n",
    "            'date_prepared': '',\n",
    "            'contracts_leases': '',\n",
    "            'account_number': '',\n",
    "            'account_name': '',\n",
    "            'total_amount_this_action': '',\n",
    "            'new_contract_total': '',\n",
    "            'revenue_generated_this_action': '',\n",
    "            'revenue_generated_total_contract': '',\n",
    "            'from_date': '',\n",
    "            'to_date': '',\n",
    "            'method_source_selection': '',\n",
    "            'email_address': '',\n",
    "            'vendor_id': '',\n",
    "            'vendor_name': '',\n",
    "            'primary_vendor_mwbe': '',\n",
    "            'sub_vendor_mwbe': '',\n",
    "            'renewal_language': '',\n",
    "            'termination_convenience_clause': '',\n",
    "            'description_work_justification': ''\n",
    "        }\n",
    "        \n",
    "        # Simple patterns for common fields\n",
    "        patterns = {\n",
    "            'eds_number': r'([A-Z]\\d{2}[A-Z]?-\\d+-\\d{4})',\n",
    "            'date_prepared': r'(\\d{1,2}/\\d{1,2}/\\d{4})',\n",
    "            'email_address': r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})',\n",
    "            'vendor_id': r'(\\d{10})',\n",
    "            'account_number': r'(\\d{4}-\\d{5})'\n",
    "        }\n",
    "        \n",
    "        for field, pattern in patterns.items():\n",
    "            match = re.search(pattern, text)\n",
    "            if match:\n",
    "                fields[field] = match.group(1)\n",
    "        \n",
    "        return fields\n",
    "    \n",
    "    def process_document(self, file_path: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process a single contract document using DeepSeek Vision\"\"\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        result = {\n",
    "            'file_path': file_path,\n",
    "            'filename': os.path.basename(file_path),\n",
    "            'status': 'processing',\n",
    "            'processing_time': 0,\n",
    "            'error': None,\n",
    "            'pages_processed': 0,\n",
    "            'extracted_fields': {},\n",
    "            'model_response': '',\n",
    "            'extraction_confidence': 0.0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Load model if needed\n",
    "            if self.model is None:\n",
    "                self.load_model()\n",
    "            \n",
    "            # Handle different file types\n",
    "            if file_path.lower().endswith('.pdf'):\n",
    "                images = self.convert_pdf_to_images(file_path)\n",
    "            else:\n",
    "                # Assume image file\n",
    "                images = [Image.open(file_path)]\n",
    "            \n",
    "            if not images:\n",
    "                raise ValueError(\"No images extracted from document\")\n",
    "            \n",
    "            # Process each page with DeepSeek Vision\n",
    "            all_extracted_fields = {}\n",
    "            all_responses = []\n",
    "            \n",
    "            extraction_prompt = self.create_extraction_prompt()\n",
    "            \n",
    "            for i, image in enumerate(images[:CONFIG[\"max_pages_per_doc\"]]):\n",
    "                print(f\"Processing page {i+1}/{len(images)} with DeepSeek Vision...\")\n",
    "                \n",
    "                # Query model with image and prompt\n",
    "                response = self.query_model_with_image(image, extraction_prompt)\n",
    "                all_responses.append(response)\n",
    "                \n",
    "                if response:\n",
    "                    # Parse extracted fields\n",
    "                    page_fields = self.parse_json_response(response)\n",
    "                    \n",
    "                    # Merge fields (later pages can override earlier ones)\n",
    "                    for field, value in page_fields.items():\n",
    "                        if value and value.strip():  # Only update if non-empty\n",
    "                            all_extracted_fields[field] = value.strip()\n",
    "            \n",
    "            # Ensure all expected fields are present\n",
    "            expected_fields = [\n",
    "                'eds_number', 'date_prepared', 'contracts_leases', 'account_number',\n",
    "                'account_name', 'total_amount_this_action', 'new_contract_total',\n",
    "                'revenue_generated_this_action', 'revenue_generated_total_contract',\n",
    "                'from_date', 'to_date', 'method_source_selection', 'email_address',\n",
    "                'vendor_id', 'vendor_name', 'primary_vendor_mwbe', 'sub_vendor_mwbe',\n",
    "                'renewal_language', 'termination_convenience_clause', 'description_work_justification'\n",
    "            ]\n",
    "            \n",
    "            for field in expected_fields:\n",
    "                if field not in all_extracted_fields:\n",
    "                    all_extracted_fields[field] = ''\n",
    "            \n",
    "            # Calculate confidence based on field completeness\n",
    "            filled_fields = sum(1 for v in all_extracted_fields.values() if v)\n",
    "            field_success_rate = filled_fields / len(expected_fields)\n",
    "            confidence = field_success_rate * 100\n",
    "            \n",
    "            # Update result\n",
    "            result.update({\n",
    "                'status': 'success',\n",
    "                'extracted_fields': all_extracted_fields,\n",
    "                'model_response': '\\n\\n'.join(all_responses),\n",
    "                'pages_processed': len(images),\n",
    "                'processing_time': time.time() - start_time,\n",
    "                'extraction_confidence': round(confidence, 2)\n",
    "            })\n",
    "            \n",
    "            logger.info(f\"Successfully processed {file_path} in {result['processing_time']:.2f}s\")\n",
    "            logger.info(f\"Fields extracted: {filled_fields}/{len(expected_fields)}, Confidence: {confidence:.1f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            result.update({\n",
    "                'status': 'failed',\n",
    "                'error': str(e),\n",
    "                'processing_time': time.time() - start_time\n",
    "            })\n",
    "            logger.error(f\"Failed to process {file_path}: {e}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def process_batch(self, file_paths: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Process a batch of documents with progress bar\"\"\"\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        with tqdm(total=len(file_paths), desc=\"Processing contracts with DeepSeek Vision\") as pbar:\n",
    "            for file_path in file_paths:\n",
    "                result = self.process_document(file_path)\n",
    "                results.append(result)\n",
    "                \n",
    "                # Update progress bar\n",
    "                status_icon = \"✓\" if result['status'] == 'success' else \"❌\"\n",
    "                pbar.set_postfix({\n",
    "                    'file': os.path.basename(file_path)[:20],\n",
    "                    'status': status_icon\n",
    "                })\n",
    "                pbar.update(1)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# %%\n",
    "# Initialize the DeepSeek processor\n",
    "processor = DeepSeekContractProcessor()\n",
    "print(\"✓ DeepSeekContractProcessor initialized\")\n",
    "print(\"💡 Model will be loaded when first document is processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332494a8-0ff8-46a4-b802-cd3383fc8615",
   "metadata": {},
   "source": [
    "## 4. Test on Sample Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the DeepSeek processor on a single document\n",
    "def test_single_document(file_path: str):\n",
    "    \"\"\"Test DeepSeek Vision processing on a single document\"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        print(\"\\n💡 To test the processor:\")\n",
    "        print(\"1. Place a sample contract PDF in the '../../data/raw/_exampleforms' folder\")\n",
    "        print(\"2. Update the file_path variable below\")\n",
    "        print(\"3. Ensure you have sufficient GPU memory (8GB+ recommended)\")\n",
    "        print(\"4. Run this cell again\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🔄 Testing DeepSeek Vision on: {file_path}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"⏳ This may take 2-5 minutes for model loading and inference...\")\n",
    "    \n",
    "    result = processor.process_document(file_path)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nStatus: {result['status']}\")\n",
    "    print(f\"Processing time: {result['processing_time']:.2f} seconds\")\n",
    "    print(f\"Pages processed: {result['pages_processed']}\")\n",
    "    print(f\"Confidence: {result.get('extraction_confidence', 0):.1f}%\")\n",
    "    \n",
    "    if result['status'] == 'success':\n",
    "        print(\"\\n📋 Extracted Contract Fields:\")\n",
    "        for field, value in result['extracted_fields'].items():\n",
    "            if value:  # Only show non-empty fields\n",
    "                print(f\"  {field}: {value}\")\n",
    "        \n",
    "        print(\"\\n🤖 Model Response Preview:\")\n",
    "        response_preview = result['model_response'][:300] + \"...\" if len(result['model_response']) > 300 else result['model_response']\n",
    "        print(f\"  {response_preview}\")\n",
    "        \n",
    "        if not any(result['extracted_fields'].values()):\n",
    "            print(\"  ⚠️ No fields extracted. Check model response for issues.\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Error: {result['error']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def test_custom_prompt(file_path: str, custom_prompt: str):\n",
    "    \"\"\"Test DeepSeek with a custom prompt\"\"\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"🔄 Testing custom prompt on: {file_path}\")\n",
    "    print(f\"Prompt: {custom_prompt[:100]}...\")\n",
    "    \n",
    "    # Load image\n",
    "    if file_path.lower().endswith('.pdf'):\n",
    "        images = processor.convert_pdf_to_images(file_path)\n",
    "        image = images[0] if images else None\n",
    "    else:\n",
    "        image = Image.open(file_path)\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"❌ Could not load image\")\n",
    "        return None\n",
    "    \n",
    "    # Load model if needed\n",
    "    if processor.model is None:\n",
    "        processor.load_model()\n",
    "    \n",
    "    # Query with custom prompt\n",
    "    response = processor.query_model_with_image(image, custom_prompt)\n",
    "    \n",
    "    print(\"\\n🤖 Model Response:\")\n",
    "    print(response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test with a sample file (update path as needed)\n",
    "sample_file = \"../../data/raw/_exampleforms/83501-000.pdf\"\n",
    "\n",
    "print(\"💡 Before running:\")\n",
    "print(\"• Ensure you have 8GB+ GPU memory (or use CPU mode)\")\n",
    "print(\"• First run will download the model (~7GB)\")\n",
    "print(\"• Processing time: 2-5 minutes per document\")\n",
    "print()\n",
    "\n",
    "# Uncomment to test:\n",
    "# test_result = test_single_document(sample_file)\n",
    "\n",
    "# Example custom prompts to try:\n",
    "custom_prompts = {\n",
    "    \"simple_extraction\": \"What is the contract number and vendor name in this document? Reply in plain text.\",\n",
    "    \"summary\": \"Provide a 2-sentence summary of this contract document.\",\n",
    "    \"amounts\": \"What are all the dollar amounts mentioned in this document? List them with their context.\",\n",
    "    \"dates\": \"Find all dates in this document and explain what each date represents.\"\n",
    "}\n",
    "\n",
    "# Uncomment to test custom prompts:\n",
    "# test_custom_prompt(sample_file, custom_prompts[\"simple_extraction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18fc599-205b-47aa-ac51-6deb7a4d4fa7",
   "metadata": {},
   "source": [
    "## 5. Batch Processing and Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document_directory(input_dir: str, file_extensions: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Process all documents in a directory using DeepSeek Vision\"\"\"\n",
    "    \n",
    "    if file_extensions is None:\n",
    "        file_extensions = ['.pdf', '.png', '.jpg', '.jpeg', '.tiff', '.tif']\n",
    "    \n",
    "    # Find all contract files\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in file_extensions):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(f\"❌ No files found in {input_dir} with extensions {file_extensions}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"📁 Found {len(file_paths)} files to process\")\n",
    "    print(f\"🧠 Processing with DeepSeek Vision-Language Model\")\n",
    "    \n",
    "    # Estimate processing time\n",
    "    estimated_time = len(file_paths) * 3  # ~3 minutes per document\n",
    "    print(f\"⏱️ Estimated time: {estimated_time//60}h {estimated_time%60}m\")\n",
    "    \n",
    "    # Process documents\n",
    "    all_results = processor.process_batch(file_paths)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = create_results_dataframe(all_results)\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_successful = (df['status'] == 'success').sum()\n",
    "    success_rate = (total_successful / len(df)) * 100\n",
    "    avg_time = df[df['status'] == 'success']['processing_time'].mean()\n",
    "    avg_confidence = df[df['status'] == 'success']['extraction_confidence'].mean()\n",
    "    \n",
    "    print(f\"\\n📊 DEEPSEEK VISION PROCESSING COMPLETE\")\n",
    "    print(f\"   Total files: {len(df)}\")\n",
    "    print(f\"   Successful: {total_successful}\")\n",
    "    print(f\"   Success rate: {success_rate:.1f}%\")\n",
    "    print(f\"   Average time: {avg_time:.2f}s per document\")\n",
    "    print(f\"   Average confidence: {avg_confidence:.1f}%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_results_dataframe(results: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    \"\"\"Convert DeepSeek results list to structured DataFrame\"\"\"\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    for result in results:\n",
    "        # Base record\n",
    "        record = {\n",
    "            'filename': result['filename'],\n",
    "            'file_path': result['file_path'],\n",
    "            'status': result['status'],\n",
    "            'processing_time': result['processing_time'],\n",
    "            'pages_processed': result['pages_processed'],\n",
    "            'extraction_confidence': result.get('extraction_confidence', 0),\n",
    "            'model_response_length': len(result.get('model_response', '')),\n",
    "            'error': result.get('error', '')\n",
    "        }\n",
    "        \n",
    "        # Add extracted fields\n",
    "        if result['status'] == 'success':\n",
    "            record.update(result['extracted_fields'])\n",
    "        \n",
    "        records.append(record)\n",
    "    \n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def create_specialized_prompts():\n",
    "    \"\"\"Create specialized prompts for different extraction scenarios\"\"\"\n",
    "    \n",
    "    prompts = {\n",
    "        \"financial_focus\": \"\"\"\n",
    "Focus on extracting financial information from this government contract. Find:\n",
    "- Contract amounts and totals\n",
    "- Account numbers and fund names\n",
    "- Revenue information\n",
    "- Budget codes or fiscal data\n",
    "\n",
    "Return the information in JSON format with clear field names.\n",
    "\"\"\",\n",
    "        \n",
    "        \"vendor_focus\": \"\"\"\n",
    "Extract vendor and contractor information from this document:\n",
    "- Vendor/contractor name and ID\n",
    "- Contact information (email, address)\n",
    "- MWBE status\n",
    "- Business type or classification\n",
    "\n",
    "Return as JSON with vendor-related fields.\n",
    "\"\"\",\n",
    "        \n",
    "        \"contract_terms\": \"\"\"\n",
    "Identify contract terms and conditions:\n",
    "- Contract type and category\n",
    "- Start and end dates\n",
    "- Renewal terms\n",
    "- Termination clauses\n",
    "- Method of selection\n",
    "\n",
    "Provide structured JSON output.\n",
    "\"\"\",\n",
    "        \n",
    "        \"quality_check\": \"\"\"\n",
    "Review this contract document for data quality:\n",
    "1. Are all required fields filled out?\n",
    "2. Are signatures present?\n",
    "3. Are dates consistent and logical?\n",
    "4. Is the document complete or are pages missing?\n",
    "5. Are there any obvious errors or inconsistencies?\n",
    "\n",
    "Provide a quality assessment with specific findings.\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    return prompts\n",
    "\n",
    "# Example usage\n",
    "INPUT_DIRECTORY = \"../../data/raw/_exampleforms\"\n",
    "\n",
    "print(\"🚀 Ready to process documents with DeepSeek Vision!\")\n",
    "print(f\"Input directory: {INPUT_DIRECTORY}\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")\n",
    "print(\"\\n💡 Features:\")\n",
    "print(\"• Natural language prompts for flexible extraction\")\n",
    "print(\"• Handles handwritten text and complex layouts\")\n",
    "print(\"• Can process multiple pages per document\")\n",
    "print(\"• Contextual understanding of form relationships\")\n",
    "print(\"\\n⚠️ Requirements:\")\n",
    "print(\"• 8GB+ GPU memory (or patience for CPU processing)\")\n",
    "print(\"• ~7GB disk space for model download\")\n",
    "print(\"• 2-5 minutes per document processing time\")\n",
    "\n",
    "# Load specialized prompts\n",
    "specialized_prompts = create_specialized_prompts()\n",
    "print(\"\\n📝 Available specialized prompts:\")\n",
    "for name, prompt in specialized_prompts.items():\n",
    "    print(f\"• {name}: {prompt[:60]}...\")\n",
    "\n",
    "print(\"\\n💡 To process your documents:\")\n",
    "print(\"1. Update INPUT_DIRECTORY above\")\n",
    "print(\"2. Uncomment the processing line below\")\n",
    "print(\"3. Run this cell\")\n",
    "\n",
    "# Uncomment the following line to start processing:\n",
    "# df_results = process_document_directory(INPUT_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-section",
   "metadata": {},
   "source": [
    "## 6. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for demonstration (replace with actual results)\n",
    "def create_sample_deepseek_results():\n",
    "    \"\"\"Create sample DeepSeek results for demonstration purposes\"\"\"\n",
    "    \n",
    "    sample_data = [\n",
    "        {\n",
    "            'filename': 'contract_001.pdf',\n",
    "            'status': 'success',\n",
    "            'processing_time': 145.3,\n",
    "            'pages_processed': 2,\n",
    "            'extraction_confidence': 91.2,\n",
    "            'model_response_length': 1247,\n",
    "            'eds_number': 'C22-6-0060',\n",
    "            'date_prepared': '6/13/2006',\n",
    "            'contracts_leases': 'Professional/Personal Services',\n",
    "            'account_number': '5120-10660',\n",
    "            'total_amount_this_action': '250000.00',\n",
    "            'from_date': '1/27/2006',\n",
    "            'to_date': '1/26/2009',\n",
    "            'vendor_name': 'PINEBROOK LANDSCAPING INC',\n",
    "            'email_address': 'sstombaugh@idoa.IN.gov',\n",
    "            'method_source_selection': 'Negotiated',\n",
    "        },\n",
    "        {\n",
    "            'filename': 'contract_002.pdf',\n",
    "            'status': 'success', \n",
    "            'processing_time': 98.7,\n",
    "            'pages_processed': 1,\n",
    "            'extraction_confidence': 96.4,\n",
    "            'model_response_length': 892,\n",
    "            'eds_number': 'C45A-6-789',\n",
    "            'date_prepared': '3/15/2023',\n",
    "            'total_amount_this_action': '75000.00',\n",
    "            'vendor_name': 'XYZ Services Inc',\n",
    "            'from_date': '03/15/2023',\n",
    "            'to_date': '03/14/2024',\n",
    "            'contracts_leases': 'Grant',\n",
    "        },\n",
    "        {\n",
    "            'filename': 'contract_003.pdf',\n",
    "            'status': 'failed',\n",
    "            'processing_time': 23.1,\n",
    "            'pages_processed': 0,\n",
    "            'extraction_confidence': 0.0,\n",
    "            'model_response_length': 0,\n",
    "            'error': 'CUDA out of memory'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(sample_data)\n",
    "\n",
    "# Use sample data for now (replace with df_results from actual processing)\n",
    "df_results = create_sample_deepseek_results()\n",
    "print(\"📊 Sample DeepSeek results loaded for demonstration\")\n",
    "\n",
    "def analyze_deepseek_results(df: pd.DataFrame):\n",
    "    \"\"\"Analyze and visualize DeepSeek processing results\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No results to analyze\")\n",
    "        return\n",
    "    \n",
    "    print(\"📈 DEEPSEEK VISION RESULTS ANALYSIS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    total_docs = len(df)\n",
    "    successful = (df['status'] == 'success').sum()\n",
    "    failed = (df['status'] == 'failed').sum()\n",
    "    success_rate = (successful / total_docs) * 100\n",
    "    \n",
    "    print(f\"Total documents: {total_docs}\")\n",
    "    print(f\"Successful: {successful}\")\n",
    "    print(f\"Failed: {failed}\")\n",
    "    print(f\"Success rate: {success_rate:.1f}%\")\n",
    "    \n",
    "    if successful > 0:\n",
    "        successful_df = df[df['status'] == 'success']\n",
    "        avg_time = successful_df['processing_time'].mean()\n",
    "        avg_confidence = successful_df['extraction_confidence'].mean()\n",
    "        avg_response_length = successful_df['model_response_length'].mean()\n",
    "        \n",
    "        print(f\"Average processing time: {avg_time:.1f}s ({avg_time/60:.1f} minutes)\")\n",
    "        print(f\"Average confidence: {avg_confidence:.1f}%\")\n",
    "        print(f\"Average response length: {avg_response_length:.0f} characters\")\n",
    "    \n",
    "    # Field extraction rates\n",
    "    print(f\"\\n📋 Field Extraction Rates:\")\n",
    "    field_columns = [\n",
    "        'eds_number', 'date_prepared', 'account_number', 'total_amount_this_action',\n",
    "        'vendor_name', 'from_date', 'to_date', 'email_address', 'contracts_leases'\n",
    "    ]\n",
    "    \n",
    "    for field in field_columns:\n",
    "        if field in df.columns:\n",
    "            non_empty = df[field].notna() & (df[field] != '')\n",
    "            rate = (non_empty.sum() / successful) * 100 if successful > 0 else 0\n",
    "            print(f\"  {field}: {rate:.1f}%\")\n",
    "    \n",
    "    # Performance insights\n",
    "    print(f\"\\n🧠 DeepSeek Vision Insights:\")\n",
    "    if successful > 0:\n",
    "        high_confidence = (successful_df['extraction_confidence'] >= 90).sum()\n",
    "        print(f\"  • High confidence extractions (≥90%): {high_confidence}/{successful}\")\n",
    "        \n",
    "        fast_processing = (successful_df['processing_time'] <= 120).sum()  # 2 minutes\n",
    "        print(f\"  • Fast processing (≤2min): {fast_processing}/{successful}\")\n",
    "        \n",
    "        detailed_responses = (successful_df['model_response_length'] >= 500).sum()\n",
    "        print(f\"  • Detailed responses (≥500 chars): {detailed_responses}/{successful}\")\n",
    "    \n",
    "    # Visualizations\n",
    "    create_deepseek_visualizations(df)\n",
    "\n",
    "def create_deepseek_visualizations(df: pd.DataFrame):\n",
    "    \"\"\"Create visualizations of DeepSeek results\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('DeepSeek Vision Processing Results Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Success/Failure distribution\n",
    "    status_counts = df['status'].value_counts()\n",
    "    axes[0, 0].pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Processing Status Distribution')\n",
    "    \n",
    "    # 2. Processing time distribution\n",
    "    successful_df = df[df['status'] == 'success']\n",
    "    if not successful_df.empty:\n",
    "        axes[0, 1].hist(successful_df['processing_time'], bins=10, alpha=0.7, color='green')\n",
    "        axes[0, 1].set_xlabel('Processing Time (seconds)')\n",
    "        axes[0, 1].set_ylabel('Number of Documents')\n",
    "        axes[0, 1].set_title('Processing Time Distribution')\n",
    "    \n",
    "    # 3. Confidence vs Processing Time\n",
    "    if not successful_df.empty:\n",
    "        scatter = axes[1, 0].scatter(\n",
    "            successful_df['processing_time'], \n",
    "            successful_df['extraction_confidence'],\n",
    "            c=successful_df['pages_processed'],\n",
    "            cmap='viridis',\n",
    "            alpha=0.7\n",
    "        )\n",
    "        axes[1, 0].set_xlabel('Processing Time (seconds)')\n",
    "        axes[1, 0].set_ylabel('Extraction Confidence (%)')\n",
    "        axes[1, 0].set_title('Confidence vs Time (color = pages)')\n",
    "        plt.colorbar(scatter, ax=axes[1, 0])\n",
    "    \n",
    "    # 4. Response length distribution\n",
    "    if not successful_df.empty and 'model_response_length' in successful_df.columns:\n",
    "        axes[1, 1].hist(successful_df['model_response_length'], bins=10, alpha=0.7, color='orange')\n",
    "        axes[1, 1].set_xlabel('Model Response Length (characters)')\n",
    "        axes[1, 1].set_ylabel('Number of Documents')\n",
    "        axes[1, 1].set_title('Response Length Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze the sample results\n",
    "analyze_deepseek_results(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-section",
   "metadata": {},
   "source": [
    "## 7. Export Results and Prompt Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_deepseek_results(df: pd.DataFrame, output_dir: str = \"../../data/intermediate_results\"):\n",
    "    \"\"\"Export DeepSeek results to various formats\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No results to export\")\n",
    "        return\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Export to CSV\n",
    "    csv_path = os.path.join(output_dir, \"deepseek_extraction_results.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"✓ Results exported to CSV: {csv_path}\")\n",
    "    \n",
    "    # Export to JSON\n",
    "    json_path = os.path.join(output_dir, \"deepseek_extraction_results.json\")\n",
    "    df.to_json(json_path, orient='records', indent=2)\n",
    "    print(f\"✓ Results exported to JSON: {json_path}\")\n",
    "    \n",
    "    # Export to Excel with multiple sheets\n",
    "    excel_path = os.path.join(output_dir, \"deepseek_extraction_results.xlsx\")\n",
    "    with pd.ExcelWriter(excel_path) as writer:\n",
    "        # All results\n",
    "        df.to_excel(writer, sheet_name='All_Results', index=False)\n",
    "        \n",
    "        # Successful extractions only\n",
    "        successful_df = df[df['status'] == 'success']\n",
    "        if not successful_df.empty:\n",
    "            successful_df.to_excel(writer, sheet_name='Successful_Extractions', index=False)\n",
    "        \n",
    "        # High confidence extractions\n",
    "        high_conf_df = df[df['extraction_confidence'] >= 90]\n",
    "        if not high_conf_df.empty:\n",
    "            high_conf_df.to_excel(writer, sheet_name='High_Confidence', index=False)\n",
    "        \n",
    "        # Summary statistics\n",
    "        summary_stats = create_deepseek_summary_stats(df)\n",
    "        summary_stats.to_excel(writer, sheet_name='Summary', index=True)\n",
    "    \n",
    "    print(f\"✓ Results exported to Excel: {excel_path}\")\n",
    "    \n",
    "    # Create processing report\n",
    "    report_path = os.path.join(output_dir, \"deepseek_processing_report.txt\")\n",
    "    create_deepseek_processing_report(df, report_path)\n",
    "    print(f\"✓ Processing report: {report_path}\")\n",
    "\n",
    "def create_deepseek_summary_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create summary statistics DataFrame for DeepSeek results\"\"\"\n",
    "    \n",
    "    stats = {\n",
    "        'Total Documents': len(df),\n",
    "        'Successful Extractions': (df['status'] == 'success').sum(),\n",
    "        'Failed Extractions': (df['status'] == 'failed').sum(),\n",
    "        'Success Rate (%)': ((df['status'] == 'success').sum() / len(df)) * 100,\n",
    "    }\n",
    "    \n",
    "    successful_df = df[df['status'] == 'success']\n",
    "    if not successful_df.empty:\n",
    "        stats.update({\n",
    "            'Average Processing Time (s)': successful_df['processing_time'].mean(),\n",
    "            'Average Confidence (%)': successful_df['extraction_confidence'].mean(),\n",
    "            'High Confidence Extractions (≥90%)': (successful_df['extraction_confidence'] >= 90).sum(),\n",
    "            'Total Pages Processed': successful_df['pages_processed'].sum(),\n",
    "            'Average Response Length': successful_df['model_response_length'].mean(),\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(list(stats.items()), columns=['Metric', 'Value'])\n",
    "\n",
    "def create_deepseek_processing_report(df: pd.DataFrame, output_path: str):\n",
    "    \"\"\"Create a detailed DeepSeek processing report\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"DEEPSEEK VISION CONTRACT PROCESSING REPORT\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        # Basic statistics\n",
    "        f.write(\"PROCESSING SUMMARY\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"Total documents processed: {len(df)}\\n\")\n",
    "        f.write(f\"Successful extractions: {(df['status'] == 'success').sum()}\\n\")\n",
    "        f.write(f\"Failed extractions: {(df['status'] == 'failed').sum()}\\n\")\n",
    "        f.write(f\"Success rate: {((df['status'] == 'success').sum() / len(df)) * 100:.1f}%\\n\\n\")\n",
    "        \n",
    "        # Performance metrics\n",
    "        successful_df = df[df['status'] == 'success']\n",
    "        if not successful_df.empty:\n",
    "            f.write(\"PERFORMANCE METRICS\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(f\"Average processing time: {successful_df['processing_time'].mean():.1f}s\\n\")\n",
    "            f.write(f\"Average confidence: {successful_df['extraction_confidence'].mean():.1f}%\\n\")\n",
    "            f.write(f\"High confidence extractions (≥90%): {(successful_df['extraction_confidence'] >= 90).sum()}\\n\")\n",
    "            f.write(f\"Average model response length: {successful_df['model_response_length'].mean():.0f} chars\\n\\n\")\n",
    "        \n",
    "        # DeepSeek-specific insights\n",
    "        f.write(\"DEEPSEEK VISION INSIGHTS\\n\")\n",
    "        f.write(\"-\" * 25 + \"\\n\")\n",
    "        f.write(\"• Vision-language model provides contextual understanding\\n\")\n",
    "        f.write(\"• Natural language prompts enable flexible extraction\\n\")\n",
    "        f.write(\"• Handles handwritten text and complex layouts\\n\")\n",
    "        f.write(\"• Can adapt to varying form structures automatically\\n\")\n",
    "        f.write(\"• Processing time trade-off for higher accuracy\\n\\n\")\n",
    "        \n",
    "        # Failed files\n",
    "        failed_df = df[df['status'] == 'failed']\n",
    "        if not failed_df.empty:\n",
    "            f.write(f\"FAILED EXTRACTIONS ({len(failed_df)} files)\\n\")\n",
    "            f.write(\"-\" * 30 + \"\\n\")\n",
    "            for _, row in failed_df.iterrows():\n",
    "                f.write(f\"File: {row['filename']}\\n\")\n",
    "                f.write(f\"Error: {row.get('error', 'Unknown error')}\\n\\n\")\n",
    "\n",
    "def generate_prompt_optimization_report(df: pd.DataFrame):\n",
    "    \"\"\"Generate insights for prompt optimization\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    print(\"🔧 PROMPT OPTIMIZATION INSIGHTS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    successful_df = df[df['status'] == 'success']\n",
    "    \n",
    "    if successful_df.empty:\n",
    "        print(\"No successful extractions to analyze\")\n",
    "        return\n",
    "    \n",
    "    # Analyze field extraction patterns\n",
    "    field_columns = [\n",
    "        'eds_number', 'date_prepared', 'account_number', 'total_amount_this_action',\n",
    "        'vendor_name', 'from_date', 'to_date', 'email_address', 'contracts_leases'\n",
    "    ]\n",
    "    \n",
    "    print(\"📊 Field Extraction Success Rates:\")\n",
    "    field_performance = {}\n",
    "    \n",
    "    for field in field_columns:\n",
    "        if field in successful_df.columns:\n",
    "            non_empty = successful_df[field].notna() & (successful_df[field] != '')\n",
    "            rate = (non_empty.sum() / len(successful_df)) * 100\n",
    "            field_performance[field] = rate\n",
    "            status = \"✓\" if rate >= 80 else \"⚠️\" if rate >= 60 else \"❌\"\n",
    "            print(f\"  {status} {field}: {rate:.1f}%\")\n",
    "    \n",
    "    # Prompt recommendations\n",
    "    print(\"\\n💡 Prompt Optimization Recommendations:\")\n",
    "    \n",
    "    low_performing_fields = [k for k, v in field_performance.items() if v < 70]\n",
    "    if low_performing_fields:\n",
    "        print(f\"• Focus on improving extraction for: {', '.join(low_performing_fields)}\")\n",
    "        print(\"• Consider adding more specific instructions for these fields\")\n",
    "        print(\"• Try providing examples in the prompt\")\n",
    "    \n",
    "    avg_confidence = successful_df['extraction_confidence'].mean()\n",
    "    if avg_confidence < 85:\n",
    "        print(\"• Overall confidence is below 85% - consider:\")\n",
    "        print(\"  - More detailed field descriptions\")\n",
    "        print(\"  - Breaking complex extractions into multiple prompts\")\n",
    "        print(\"  - Adding validation steps\")\n",
    "    \n",
    "    avg_time = successful_df['processing_time'].mean()\n",
    "    if avg_time > 180:  # 3 minutes\n",
    "        print(\"• Processing time is high - consider:\")\n",
    "        print(\"  - Shorter, more focused prompts\")\n",
    "        print(\"  - Processing fewer fields per prompt\")\n",
    "        print(\"  - Using smaller input images\")\n",
    "    \n",
    "    print(\"\\n📝 Suggested Prompt Improvements:\")\n",
    "    print(\"1. Add field-specific examples: 'EDS Number (e.g., C22-6-0060)'\")\n",
    "    print(\"2. Include format specifications: 'Dates in MM/DD/YYYY format'\")\n",
    "    print(\"3. Add validation instructions: 'Double-check extracted values'\")\n",
    "    print(\"4. Use step-by-step extraction: 'First find, then extract, then validate'\")\n",
    "\n",
    "# Export sample results\n",
    "export_deepseek_results(df_results)\n",
    "\n",
    "# Generate optimization insights\n",
    "generate_prompt_optimization_report(df_results)\n",
    "\n",
    "print(\"\\n✅ DEEPSEEK VISION PROCESSING PIPELINE COMPLETE!\")\n",
    "print(\"\\n📋 What This DeepSeek Notebook Provides:\")\n",
    "print(\"  ✓ Vision-language model for intelligent document understanding\")\n",
    "print(\"  ✓ Natural language prompts for flexible field extraction\")\n",
    "print(\"  ✓ Contextual reasoning and relationship understanding\")\n",
    "print(\"  ✓ Handles handwritten text and varying layouts\")\n",
    "print(\"  ✓ No training required - works out of the box\")\n",
    "print(\"  ✓ Customizable prompts for different extraction needs\")\n",
    "\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"1. Ensure sufficient GPU memory (8GB+ recommended)\")\n",
    "print(\"2. Update INPUT_DIRECTORY in Section 5\")\n",
    "print(\"3. Customize prompts for your specific use case\")\n",
    "print(\"4. Run processing and analyze results\")\n",
    "\n",
    "print(\"\\n💡 Advantages over Traditional OCR:\")\n",
    "print(\"• Understands context and relationships between fields\")\n",
    "print(\"• Handles complex layouts and handwritten text\")\n",
    "print(\"• Flexible prompting allows adaptation to new forms\")\n",
    "print(\"• Higher accuracy for structured data extraction\")\n",
    "print(\"• Can perform quality validation and error detection\")\n",
    "\n",
    "print(\"\\n⚡ Performance Trade-offs:\")\n",
    "print(\"• Higher accuracy vs longer processing time\")\n",
    "print(\"• More flexible vs higher computational requirements\")\n",
    "print(\"• Better understanding vs GPU memory needs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.5"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 5\n}