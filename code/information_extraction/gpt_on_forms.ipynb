{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca49287-40de-4527-9d05-dac0c3f6d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/admin-tascott/Documents/GitHub/openai_eis_key.txt', encoding=\"utf-8\") as f:\n",
    "    key = f.read()\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "#!pip install pypdf\n",
    "#!pip install faiss-cpu\n",
    "#!pip install langchain\n",
    "#### setup for query, feed in individual files\n",
    "#### note that future improvement would be to load docs as a library and query across library\n",
    "### presumably this would be much faster, for for now I was getting token warnings (to many)\n",
    "#### but single-file-at-a-time approach does work\n",
    "\n",
    "# if overwrite = T, then redo prior extractions\n",
    "overwrite = False\n",
    "import re\n",
    "import langchain.document_loaders\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import nltk\n",
    "### find the meeting files in these subdirectories\n",
    "import os, fnmatch\n",
    "file_list = []\n",
    "original_files = '../../data/raw/_firstjpeg/'\n",
    "files = fnmatch.filter(os.listdir(original_files), '*.jpeg')\n",
    "for f in files:\n",
    "    file_list.append(f)\n",
    "file_list.sort()\n",
    "import random\n",
    "#random.shuffle(file_list)\n",
    "savedir = '../../data/ocr_collected'\n",
    "if os.path.exists(savedir)==False:\n",
    "    os.mkdir(savedir)\n",
    "#!mkdir ../../data/intermediate_products\n",
    "tagged_pages = pd.read_csv('../../data/intermediate_products/zeroshot_form_contract.csv')\n",
    "data_form_files = tagged_pages[tagged_pages['prose in single column layout']<=0.5]\n",
    "contract_files = tagged_pages[tagged_pages['prose in single column layout']>0.5]\n",
    "\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "# Path to your image\n",
    "image_loc = \"../../data/raw/_firstjpeg/\"\n",
    "df_files = [f for f in data_form_files['file']]\n",
    "loc = '../../data/intermediate_products/json_forms/'\n",
    "df_need = set([re.sub('jpeg','json',f) for f in df_files]).difference(set(os.listdir(loc)))\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {key}\"\n",
    "}\n",
    "import requests\n",
    "import json\n",
    "prompt = \"\"\"This image is an Executive Document Summary form related to a contract with a state agency.\n",
    "Provide a detailed breakdown of the information in the form.\n",
    "For form elements that are a set of checkboxes, return the name of the checked box as the value.\n",
    "Provide the results as a json file\"\"\"\n",
    "\n",
    "for d in df_need:\n",
    "    # Getting the base64 string\n",
    "    jpeg_file = re.sub('json','jpeg',d)\n",
    "    image = '{}/{}'.format(image_loc,jpeg_file)\n",
    "    base64_image = encode_image(image)\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4o\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \"detail\": \"high\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 1000\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    jsonfile = d\n",
    "    with open('{}/{}'.format(loc,jsonfile), 'w', encoding='utf-8') as f:\n",
    "        json.dump(response.json(), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4714c2e-1423-46a2-ae9a-3351463889ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327dc21e-01fd-4544-b1e5-44e74467ddaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68773ddb-c3a7-4bf4-a9ae-2908f6b65614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3e0f4a-08b8-44d0-8905-915b99982110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3c010d-234f-41bb-9fef-48a090e2cfca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
