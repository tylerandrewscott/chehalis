{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e86fb7de-7dd5-4c92-a926-1d2c0dc4823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: loc: File exists\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/admin-tascott/Documents/GitHub/openai_eis_key.txt', encoding=\"utf-8\") as f:\n",
    "    key = f.read()\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "#!pip install pypdf\n",
    "#!pip install faiss-cpu\n",
    "#!pip install langchain\n",
    "#### setup for query, feed in individual files\n",
    "#### note that future improvement would be to load docs as a library and query across library\n",
    "### presumably this would be much faster, for for now I was getting token warnings (to many)\n",
    "#### but single-file-at-a-time approach does work\n",
    "\n",
    "# if overwrite = T, then redo prior extractions\n",
    "overwrite = False\n",
    "import re\n",
    "import langchain.document_loaders\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import nltk\n",
    "### find the meeting files in these subdirectories\n",
    "import os, fnmatch\n",
    "file_list = []\n",
    "original_files = '../../data/raw/_firstjpeg/'\n",
    "files = fnmatch.filter(os.listdir(original_files), '*.jpeg')\n",
    "for f in files:\n",
    "    file_list.append(f)\n",
    "file_list.sort()\n",
    "import random\n",
    "#random.shuffle(file_list)\n",
    "savedir = '../../data/ocr_collected'\n",
    "if os.path.exists(savedir)==False:\n",
    "    os.mkdir(savedir)\n",
    "#!mkdir ../../data/intermediate_products\n",
    "tagged_pages = pd.read_csv('../../data/intermediate_products/zeroshot_form_contract.csv')\n",
    "\n",
    "contract_files = tagged_pages[tagged_pages['prose in single column layout']>0.5]\n",
    "\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "# Path to your image\n",
    "image_loc = \"../../data/raw/_firstjpeg/\"\n",
    "df_files = [f for f in contract_files['file']]\n",
    "loc = '../../data/intermediate_products/json_contracts/'\n",
    "!mkdir loc\n",
    "df_need = set([re.sub('jpeg','json',f) for f in df_files]).difference(set(os.listdir(loc)))\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {key}\"\n",
    "}\n",
    "import requests\n",
    "import json\n",
    "prompt = \"\"\"This image is the first page of a contract with a stage agency. \n",
    "Record the type of agreement and whether it the agreement is new, an amendment, an extension, or a renewal.\n",
    "Itemize contract data such as the involved parties, amount, relevant dates, and whether the scope of work is reduced, expanded, or remains the same.\n",
    "Provide the results as a json file\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51cc3f61-0be6-433a-bfaf-d1cefc898707",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [d for d in df_need][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "17984302-82f7-4759-81f3-6d7051ec2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in test:\n",
    "#for d in df_need:\n",
    "    # Getting the base64 string\n",
    "    jpeg_file = re.sub('json','jpeg',d)\n",
    "    image = '{}/{}'.format(image_loc,jpeg_file)\n",
    "    base64_image = encode_image(image)\n",
    "    payload = {\n",
    "      \"model\": \"gpt-4o\",\n",
    "      \"messages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": [\n",
    "            {\n",
    "              \"type\": \"text\",\n",
    "              \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "              \"type\": \"image_url\",\n",
    "              \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \"detail\": \"high\"\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"max_tokens\": 1000\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    jsonfile = d\n",
    "    with open('{}/{}'.format(loc,jsonfile), 'w', encoding='utf-8') as f:\n",
    "        json.dump(response.json(), f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
